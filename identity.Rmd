# Knowing where but not what {#identity}

Consider what someone means when they say they are keeping track of something, for example their family. That likely would mean knowing where each of their siblings is, where their mother is, and where their father is. But the multiple object tracking task does not test peoples' knowledge of the different identities of targets. Rather, the targets are typically all identical to each other (and to the distractors) and people need only report where the targets are.

This section is about what you know about the objects you are tracking. The answer is: surprisingly little. We can break the question down into two parts. The first part is the extent to which the processes that mediate tracking use the targets' features to keep track of them, and the second is how much we are able to report about the targets' features.

Successful tracking of objects is sometimes important for computers as well as for humans. Tracking algorithms provide benefits both for detection of suspicious activity in CCTV security footage and also analyzing the movements of players of an opposing team's previous games. To solve the tracking problem, engineers have used a variety of solutions. They do not confine themselves to using only the locations and motions of objects - to assist matching they also use the appearance of those objects, for example their shapes and colors [@yilmazObjectTrackingSurvey2006a]. In some situations this allows tracking where location and motion alone would result in losing a target.  

The investigation of whether the human visual system uses feature similarity to facilitate motion correspondence began over a century ago. Gestalt psychologists such as Max Wertheimer found that apparent motion was equally strong whether the objects in successive frames were identical or different [@wertheimerExperimentelleStudienUber1912]. Later studies found some effect of similarity, but it was weak [@kolersFiguralChangeApparent1971; @burtTimeDistanceFeature1981]. However, when the successive presented frames of an object touch or overlap with each other rather than being presented in non-contiguous locations, the results can be different. The study of such displays, with a different object appearance (usually, shape) in two successive frames, is known as line motion or transformational apparent motion. These studies have found that feature similarity, especially contour continuity, but also color, can decide which tokens are matched [@faubertInfluenceTwoSpatially1995; @tseRoleParsingHighlevel1998]. Thus, feature similarity is involved in motion processing, even though in many situations motion correspondence is determined by spatiotemporal luminance relationships. An important characteristic of this process that does does not seem to have been studied, however, is whether these cues are processed in parallel. Short-range spatiotemporal luminance relationships ("motion energy") are known to be processed by local detectors, such that visual search happens in parallel for a target moving in an odd direction defined by small-displacement apparent motion [@horowitzAttentionApparentMotion1994]. I am not aware of any studies that have investigated this for transformational apparent motion, in a situation where the perceived motion direction is determined by feature similarity. Thus, the possibility remains that feature similarity has its influence through what I have called a C~1 process.

Whether features are used by processes involved in motion correspondence is a different question than whether they are available to conscious awareness. We are of course aware of object features when the only task we are engaged in is tracking a single target. In that situation, our limited-capacity processes can all be applied to that target. However, when we are tracking multiple targets, the evidence indicates that we have little ability to report the objects' features, other than their locations.

A common view of perception is that lack of awareness of the features of objects one is attending to could not happen. Indeed, many people seem to believe that we are simultaneously aware of the identities of all the objects in the central portion of our visual field, so unless an object actually disappears or hides behind something or someone, we should know where everything in the scene is at all times, and we should immediately detect any changes to these objects. For many, change blindness demonstrations are the first experience that disrupts this belief.

Experiments suggest that during change blindness, although people cannot monitor a large number of objects at once, they are able to monitor several, perhaps four or five [@rensinkVisualSearchChange2000]. They appear to do this by loading the objects into working memory and then, in the second frame, checking whether any are different than what is held in memory. A vast literature on visual working memory has confirmed that people can store several objects and rapidly compare these stored representations to the visual scene. However, loading into memory the features of objects for storage and subsequent comparison is not the same as maintaining awareness of the changing features of such objects. For one thing, it appears that hundreds of milliseconds are needed to encode several objects [@vogelTimeCourseConsolidation2006 @ngiamVisualWorkingMemory2019]. Second, it appears that when objects are in motion, updating of their features is particularly poor, as we will see in the next section.

## Not knowing which is which 

Subsequent evidence has indicated that during tracking, while the locations of targets are updated and available, other aspects of them may not be. In one experiment, targets were assigned distinct identities either by giving them names or by giving them distinct starting positions (the four corners of the screen) [@pylyshynPuzzlingFindingsMultiple2004]. At the end of a trial, participants were given the usual task of indicating which objects were targets and also were asked about the identity of the target. Accuracy at identifying the targets was very low, even when accuracy reporting their positions was high. <!-- target-target confusions could explain this --> In his visual indexing theory of tracking, @pylyshynRoleLocationIndexes1989 had conceived of each target as being referenced by its own discrete pointer with its own identity. But the discovery that one did not know which target is which undermined this idea. 

More evidence for a disconnect between success at MOT and knowledge of what one is tracking was found by @horowitzTrackingUniqueObjects2007, who had participants track targets that looked very different from each other - in one set of experiments, they were cartoon animals. At the end of a trial, all the targets moved behind occluders so that their identities were no longer visible. Participants were asked where a particular target (say, the rabbit) had gone - that is, which occluder it was hiding behind. Performance was better than chance, but was much worse than performance for reporting the target locations irrespective of which target it was. The effective number of objects tracked, as reflected in a standard MOT question, was about four, but when asked to locate an individual animal, capacity was closer to two objects.

These findings rebut Pylyshyn's theory that tracking reflects preattentive indices [@schollWhatHaveWe2008]

@pailianAgeSpeciesComparisons2020 devised a "shell game" that focused on the updating of the locations of a memorized array of colors, in a format that allowed testing how children and an African grey parrot as well as human adults.

![An African grey parrot participates in a shell game. CC-BY Pailian et al. (2020)](imagesForRmd/ParrotGriffinPepperbergShellGame.png){width=40%} 

The colored stimuli were woolen pompoms. Between one and four of the pompoms were shown to a participant and then covered by inverted plastic cups, after which different pairs of cups were swapped a variable number of times. As a probe, the participant was presented with one of the target colors, and the task was to point, or peck, to the cup containing the probed color. 

In a way, this might be expected to be much easier than a conventional MOT task, because only targets were presented, no distractors, and at any one time, only two objects were in motion. Moreover, the objects paused for a full second between swaps, presumably giving participants time to update their working memory of the locations of the colors.

When only two pompoms were presented, performance in all groups was high. The parrot did at least as well as the human adults. In the more difficult three-pompom condition, the parrot actually outperformed the adults, as well as the children. Evidently, the ability to remember and update small numbers of moving hidden objects to a high level of accuracy is present even in our distant cousins with much smaller brains.

With four pompoms, performance fell more substantially as the number of swaps increased, declining to below 80% correct both for the parrot and the adult humans.

<!--For instance, @schollRelationshipPropertyencodingObjectbased2001 found that when items stopped moving, observers were able to accurately report the previous direction and speed of targets but not of nontargets. However, when the shape or color of the items was masked, observers were unable to accurately report the premask features of either targets or nontargets.-->

The results from these studies strongly suggest that participants often cannot remember the identities of some of the moving objects that they are tracking. Trying to remember object identities may even interfere with the ability to track [@fougnieDistinctCapacityLimits2006]. However, in the studies reviewed above the objects were invisible, at least temporarily, so that memory was required to bridge a spatiotemporal gap. If the distinct appearances of the targets were made continuously visible, one might hope that one could better maintain a representation of their appearances, especially considering that the objects were continuously stimulating ones' retinas.

It is difficult to test participants on whether they know during tracking the characteristics of an object when, as soon as the question is asked, they can focus their attention on the probed object and encode its features for report. But some insight into this issue can  be gained by considering the studies conducted by @makovskiFeatureBindingAttentive2009.

In the @makovskiFeatureBindingAttentive2009 experiments, eight moving objects were presented. Each was distinct in color, distinct in another feature such as shape, or both features. Tracking performance was better than when the eight objects were identical. However, in another condition the eight objects were not all distinguishable based on a single feature and instead were distinguished only by their pairing of features (feature conjunction). To clarify, in this condition, each object has a unique pair of features, but shared its individual features with at least one other object. <!--create illustration maybe from diagrammeR--> In this conjunction condition, the results were quite different.  Performance was no better than if the objects were all identical.

CONTINUE EDITING HERE
@makovskiFeatureBindingAttentive2009 concluded that while differences among objects could benefit tracking, as if participants were using both object identity and location to distinguish objects, this was only the case if feature binding was not necessary. It is possible that global feature attention, utilized by activating the colors of the targets for instance, might account for the distinct identity advantage in the featural case.

In the early 1990s, it gradually became clear that the mind maintained fewer visual representations than researchers had assumed. Failures of trans-saccadic visual fusion and inability to detect changes that occurred during eye movements [@mcconkieRoleControlEye1979] led @oreganSolvingRealMysteries1992a to suggest that "the world is an outside memory" and to discover change blindness [@rensinkSeeNotSee1997]. The idea was that the impression that one has a rich representation of all the objects in the visual field is an illusion, and instead that one has only a more limited knowledge, but that this is quickly supplemented by attentional processing when one becomes interested in a particular location or object.

It appears that O'Regan's big idea goes further than he anticipated. While O'Regan suggested that only when objects  were attended would they be fully processed, he did not suggest that one might be able to track the changing locations of multiple targets without knowing what they are. 

@hudsonHemifieldEffectsMultiple2012 multiple identity tracking , found a hemifield advantage: " Contrary to expectations, a bilateral advantage was still observed, though it was not as strong as when observers were not required to remember the identities of the targets. This finding is inconsistent with the only model of multiple identity tracking (Oksama & Hyönä, 2008, Cognitive Psychology, 56, 237-283), so we present an alternative account."
<!-- E4 standard MOT design. Calculate hemifield independence = 
A weird thing is that there were no distractors in the same quadrant ,but E3 used the standard design and found the same result.
E1: colors of the targets continuously visible. Found substantial bilateral advantage.
E2: colors of targets only presented at beginning. Substantial bilateral advantage again.

<!--Tracking is important for representing objects still in view @tsubomiNeuralLimitsRepresenting2013-->


<!--
A second factor is that even when objects remain close enough to central vision to resolve their identities, a limited resource is required to bind their features together, including binding individual features with their location... 

A third factor is, of course, the limitations that result in imperfect performance even on tracking identical objects, reviewed in the previous sections..

You can track four objects without being able to identify stuff on the four objects. This could either be explained by attention needing to switch between locations, or alternatively that you just need less resource to track than to identify.

Because binding seems to require sustained attention, it’s unlikely it’s bound when serial attention isn’t there. But you might have a memory index of what is there - I need help on this from VWM people!-->


<!-- ## Configurations and 

Most models of tracking have assumed that people track only the targets, and track them without reference to the positions of any other objects. We know from other areas of research, however, that people rapidly extract that spatial layout or configuration of the objects in a scene. Some research has indicated that configural information is also used for tracking.


Because binding seems to require sustained attention, it’s unlikely it’s bound when serial attention isn’t there. But you might have a memory index of what is there - I need help on this from VWM people!

Linares et al. ()


Let's return to the classic shell game. In a shell game, an item is placed beneath one of three identical shells, making that shell the target. The viewer tries to keep track of which shell has the item underneath it. -->
 <!-- insert Conversation article text-->


@nummenmaaCorticalCircuitBinding2017 found temporal lobe activation

"erhaps most famously, these sorts of processes seem to be localized in anatomically distinct corti- cal streams (e.g., Livingstone and Hubel 1988), with the ventral pathway corresponding to identification, and the dorsal pathway corresponding to individuation. In addition, a variety of behavioral evidence supports this distinction. The surface features of objects (e.g., their colors and shapes), while obviously critical for many visual processes including object recogni- tion, seem to be largely discounted by many other processes (for a review, see Flombaum, Scholl, and Santos, in press). For example, surface features play little or no role in determining apparent motion correspondence (Burt and Sperling 1981), identity over time in the tunnel effect (Flombaum et al., 2004; Flombaum and Scholl 2006; Michotte, Thinès, and Crabbé 1964/1991), or object-specific priming (Mitroff and Alvarez 2007)." [@schollWhatHaveWe2008]

In sport, however, sometimes we are suprised to discover an opponent in the right place at the right time. "Where did he come from?" is a common complaint. This phenomenon can be partially understood in terms of the limit on the number of objects that can be tracked in MOT. It turns out, however, that this is only part of the story. The limitations on tracking are more profound than those we have reviewed so far.

The tracking research we have discussed so far has used targets and distractors that are all identical to each other (after the initial phase where the targets are indicated). In the real world, however, this is uncommon.

Visual short-term memory tasks typically find that people can perform reasonably well at storing at least four objects, allowing participants to detect whether an object changes during a short interval. This, together with the misconception discussed in section \@ref(bottlenecks) that tracking has a limit of four targets has led many researchers to suggest that a common limitation underlies both visual short-term memory and object tracking. This may be true in some sense, but certain possibilities have been ruled out by a dramatic finding.

Putting objects in motion can dissociate tracking and short-term memory capacities. @saikiMultipleobjectPermanenceTracking2002 asked participants to track four colored discs that periodically moved behind occluders and then re-appeared on the other side. There were no distractors. The task of participants was to detect whether any discs changed color. Contrary to what would be expected from object files theory [@kahnemanReviewingObjectFiles1992], for all but very slow speeds, performance was very low. However, because distractors were not included, there was no direct comparison to performance tracking solely the objects' locations (without knowing their colors). 





