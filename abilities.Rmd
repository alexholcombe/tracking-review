# Abilities, individual differences, dual-task interference

There are two basic approaches to understanding the abilities that underlie multiple object tracking. One is the classic experimental approach of dissociating the processes involved by manipulating different factors within participants. This has been the dominant approach and has led to our present understanding of the roles of spatial interference, temporal interference, and the duration that one can sustain attention. However, a small but growing literature has used the complementary individual-differences approach. In the individual-differences approach, the pattern of variation in scores on multiple tests is examined to see which abilities tend to go together. Those abilities that co-vary the most are thought to likely share more processes in common than those that don't.

## How many objects can people track?


This has been the dominant framing since the beginning of MOT research, when Pylyshyn suggested that tracking was limited by the number of discrete pointers or FINSTs that people have. But the underlying reason for variation in MOT performance may not be due to variation in number of FINSTs or some other such capacity, but rather due to variation in peoples' tracking speed limit, spatial interference, or temporal interference. This does not seem to have been properly investigated.

This question is a mistake. 

Working off the dominant framing, that each person does have a specific number of targets they can track which determines percent correct for each level of number of targets, some MOT researchers report what @schollWhatVisualObject2001 called the "effective number of items tracked". The associated formula, refined by @hullemanMathematicsMultipleObject2005a allows researchers to calculate the effective number of items tracked based on accuracy in an individual condition, given the number of targets and distractors in that condition. This does provide a useful summary of the data, but researchers should take more care to avoid taking it literally.

In the study by @meyerhoffIndividualDifferencesVisual2020, which used four targets and four distractors, the modal effective number of items tracked was around two, but a substantial proportion of participants's came in at three targets or one target, and a few scored close to zero effective items tracked. 

Unfortunately, in the data of @meyerhoffIndividualDifferencesVisual2020, like that of many others, there is no way to know how much of the variation between individuals is due to motivation rather than ability. Measuring motivation is not easy, but researchers should at least include what are sometimes called attention checks or catch trials to allow exclusion of participants who show clear evidence of not reading the instructions carefully or frequently not paying attention.


## Do people vary much in how many objects they can track?

For some cognitive tasks, individual differences are small, making an individual-differences approach problematic [@hedgeReliabilityParadoxWhy2018]. @oksamaMultipleObjectTracking2004 made the effort to test 201 participants on MOT, in an effort to examine variation in how many objects people can track with reasonable accuracy. They found what appeared to be a substantial variation in capacity, with some people able to track six objects, while many could track only two or even just one. However, no analyses were reported regarding the reliability of the MOT test. This left open the possibility that the tracking scores were very noisy, such that the variation in scores found between participants could also have been found if just one participant were tested repeatedly.

<!--One way to have assessed reliability would have been to test each participant two times, to exmaine whether individuals would achieve similar scores in the two instances. For any given test, it is possible that a test is instead very noisy, such that at an extreme the variation in scores found between participants would also be found if just one participant were tested repeatedly.  MOT, visuospatial short-term memory, verbal working memory, and attention switching, and calculated the correlation of performance for each pair of tasks.  For what it's worth, th-->

Although they did not vary the number of targets participants had to track, @huangMeasuringInterrelationsMultiple2012, @oksamaMultipleObjectTracking2004, and @trevinoBridgingCognitiveNeuropsychological all tested a large number of participants and calculated the correlation in participants' performance between one half of the trials they were tested in and the other. All three found a high correlation of >0.85.  Together with their other results and those of @oksamaMultipleObjectTracking2004, this indicates that people do vary substantially in their multiple object tracking ability. 

Variation in MOT performance is typically interpreted by researchers as variation simply in how many objects a person can track. 


## What tasks are most related to MOT? 

Partly to reveal what other sorts of tasks a high ability to track multiple objects indicates, @huangMeasuringInterrelationsMultiple2012 and @trevinoBridgingCognitiveNeuropsychological tested large numbers of participants on several tasks. @huangMeasuringInterrelationsMultiple2012 used a set of cognitive and attentional tasks that he termed conjunction search, configuration search, counting, feature access, spatial pattern, response selection, visual short-term memory, change blindness, Raven's test of intelligence, visual marking, attentional capture, consonance-driven orienting, inhibition of return, task switching, mental rotation, and Stroop. While many of these showed high reliability of over .9, the correlations with MOT were fairly low, with the highest being counting at 0.4, which required counting the number of white dots in a brief (400 ms) display. Change blindness, feature access, visual sworking memory, and visual marking were runner ups with correlations of around 0.3.
<!-- @huangMeasuringInterrelationsMultiple2012 "For each variable, reliability was estimated by calculating the split-half (odd-even) correlations and the Spearman-Brown formula was used for adjustment. All of the 17 paradigms met the minimum reliability of 0.7."  So I guess these are not raw correlations he reports from then on -->

@trevinoBridgingCognitiveNeuropsychological reported data from more than 400 participants tested online, and tested a set of cognitive, attentional, and common neuropsychological tasks: arithmetic word problems, the trial-making task, digit span, digit symbol coding, letter cancellation, spatial span, approximate number sense, flanker interference, gradual onset continuous performance, spatial configuration visual search, and visual working memory as well as MOT. MOT had among the highest reliabilities, at 0.92. MOT performance had  little correlation with performance on the task designed to measure sustained attention over an extended period (about five minutes, the gradual-onset continual performance task, [@fortenbaughSustainedAttentionLife2015]. This supports the tentative conclusion, already suggested in the "Duration that one can sustain attention" section of this Element, that the ability to sustain attention without lapses is not an important determinant of tracking performance (as was ).

The tasks with the highest correlations with MOT in the data of @trevinoBridgingCognitiveNeuropsychological were visual working memory, spatial span, letter cancellation, and digit symbol coding, all at around 0.5. The task that most resembled the counting task of @huangMeasuringInterrelationsMultiple2012 (which in their data had the highest correlation with MOT) also had a moderate correlation (0.3). It differed from that of @huangMeasuringInterrelationsMultiple2012 by not testing the subitizing range, which might help explain any discrepancy. In a more limited study, @eayrsEstablishingIndividualDifferences2018 found, using hierarchical regression, that subitizing made a contribution to predicting MOT performance that was somewhat separate to that of an estimation task using larger set sizes. <!-- change blindness, load-induced blindness and multiple object tracking, MOT split-half reliability of .87 -->

Overall, there is a decent level of agreement across studies. Of note is that visual working memory has a robust correlation with MOT performance, even though superficially MOT imposes little to no memory demand. That is, once multifocal attention is deployed to the targets, 

if tracking is done by keeping one's attention 

in principle, one merely needs to continuously keep one's attention

to date with the largest numbers of people tested 


subitizing by Lavie paper

There is some convergence here with the results of @huangMeasuringInterrelationsMultiple2012 in finding a relatively high correlation with visual memory, but a discrepancy in that the "counting" task of @huangMeasuringInterrelationsMultiple2012 showed the highest correlation with MOT, whereas the corresponding approximate number sense task of @trevinoBridgingCognitiveNeuropsychological correlated positively (0.3), but this value is not more than a number of the other tasks. A possible reason is that the @huangMeasuringInterrelationsMultiple2012 counting task included low, subitizable set sizes of three and four, whereas @trevinoBridgingCognitiveNeuropsychological did not.


@meyerhoffIndividualDifferencesVisual2020 tested fifty participants and for each one calculated 

@oksamaMultipleObjectTracking2004 made the effort to test 201 participants on 



" In Huang et al.’s study, the correlation between MOT and VWM was .30, the correlation between (configuration) search and MOT was .30, and the correlation between search and VWM was .23. In our data, however, MOT and VWM were much more closely correlated with each other (.51)"

" several studies have shown dissociations between MOT and visuo-spatial working memory [@bettencourtSharedFilteringProcesses2011] ( \O. L. Carter et al., 2005; O’Hearn et al., 2010). Furthermore, Trick et al. (2012) showed that visuospatial ability (including Corsi Blocks, a spatial span variant) but not working memory, predicts MOT."



Study of only 12 pro basketball players finding correlations with basketball metrics @mangineVisualTrackingSpeed2014a


"internal consistency"


It is  unsurprising when 
Almost any two tasks are typically correlated, <!-- discriminat validity . You also want to include tasks that you  -->
Cronbach & Meehl  MTMM mult-trait

 With the growth of online testing, we can expect this approach to  

## Dual-task


@howardVisualSpatialAttention2020 "for a purely spatial task, perceptual attention (TRACKING?) and working memory appear to recruit separate core capacity-limited processes."

@souzaContributionsVisualCentral2017 argued that VWM and MOT use different attentional resources." "Distracting visual attention, but not central attention, impaired MOT performance"


