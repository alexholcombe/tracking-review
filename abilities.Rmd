# Abilities, individual differences, dual-task interference {#abilities}

There are two basic approaches to understanding the abilities that underlie multiple object tracking. One is the classic experimental approach of dissociating the processes involved by manipulating different factors within participants. This has been the dominant approach and has led to our present understanding of the roles of spatial interference, temporal interference, and the duration that one can sustain attention. However, a small but growing literature has used the complementary individual-differences approach. In the individual-differences approach, the pattern of variation in scores on multiple tests is examined to see which abilities tend to go together. Those abilities that co-vary the most are thought to likely share more processes in common than those that don't.

## Do people vary much in how many objects they can track?

There are two very common pitfalls of individual-difference studies in this literature. These are in addition to the common mistake across all study types of not testing enough participants to have good statistical power - individual-difference studies can require more than ten times as many participants as a within-participants experimental design investigating a large effect [@schonbrodtWhatSampleSize2013]. 

@meyerhoffIndividualDifferencesVisual2020 tested fifty participants and for each one calculated the effective number of items tracked, for a display with four targets and four distractors, the modal effective number of items tracked was around two, but a substantial proportion of participants came in at three targets or one target tracked, and a few scored close to zero items tracked. It is tempting to conclude, as @meyerhoffIndividualDifferencesVisual2020 did, that some participants could only track one or zero targets, while others can track more. Unfortunately, in the data of @meyerhoffIndividualDifferencesVisual2020, like that of many others, there is no way to know how much of the variation between individuals is due to motivation rather than ability. Measuring motivation reliably is difficult or impossible, so this is not something that can easily be remedied. But researchers can include what are sometimes called attention checks or catch trials to allow exclusion of participants who show clear evidence of not reading the instructions carefully or frequently not paying attention. <!--also, they can design their study to look at the pattern of correlations--> This is the first pitfall, failing to include some sort of measure that checks whether each participant is blowing off the task.

@oksamaMultipleObjectTracking2004 were also interested in how many objects people can track with reasonable accuracy. They made the effort to test 201 participants, and like @meyerhoffIndividualDifferencesVisual2020 they found what appeared to be a substantial variation in capacity, with some people able to track six objects, while many could track only two or even just one. However, no analyses were reported regarding the reliability of the MOT test. Their participants, who were provided by an air pilot recruitment program, were made up entirely of those who scored in the top 11% on intelligence test scores from a larger group. This provides some confidence that the participants were motivated, although it is not clear that the intelligence tests were administered in the same session, so one cannot know whether the participants were motivated during this particular session. 

While we can be fairly confident that @oksamaMultipleObjectTracking2004 used motivated paticipants, the study suffers from what I refer to as the second pitfall - the failure to assess task reliability. On any test, a participant will tend to get somewhat different scores when tested on two different occasions, even if they did not learn anything from their first experience with the test. The extent to which participants' scores are similar when taking a test twice is known as test-retest reliability. Ideally, this is measured with two tests administered at very different times, but a more limited measure is provided by dividing a single session's trials into two groups and calculating the correlation between those two groups, which is known as split-half reliability. Knowing the reliability can allow us to calculate how much of the variation in scores between participants is expected based on the noisiness of the test. Without knowing the reliability, there remains the possibility that the extreme variation in scores, with some participants' data indicating that they could only track one target, could be due to limited reliability - extensive testing of these participants might reveal that their low score was merely a fluke. 

Subsequent studies, fortunately, have assessed reliability, albeit only with the split-half measure rather than on separate days. Still, the reliabilities they have found for MOT are extremely impressive - 0.96 [@huangMeasuringInterrelationsMultiple2012], 0.85 [@wilbiksIndividualDifferencesMultiple2020], 0.92 [@trevinoBridgingCognitiveNeuropsychological2021], and 0.87 [@eayrsEstablishingIndividualDifferences2018]. Most other attentional and cognitive tasks have lower reliablities, indeed many basic cognitive and attentional tasks have notoriously low reliabilities [@hedgeReliabilityParadoxWhy2018], and indeed, in these papers, MOT consistently scored near the top of the tests administered. Tasks with low reliabilities are not well suited for  individual-differences studies - as mentioned above, individual-difference studies are largely based on measuring the pattern of correlations between tasks to reveal the relationship among abilities. The lower the reliability of a task, the harder it is to reliably measure the correlation with another task.  

What do these high reliabilities mean for tracking? It suggests that the large individual differences observed by @oksamaMultipleObjectTracking2004 and others are actually real. It seems that some young, healthy, high-intelligence people can only track one target. Second, it means that individual-difference studies should be an excellent avenue for gaining new insights about tracking and its relation to other mental abilities.

Ageing is likely a major source of individual differences, as older participants perform much worse than younger participants [@trickAgerelatedDifferencesMultipleobject2005; @sekulerAgerelatedChangesAttentional2008; @roudaiaDifferentEffectsAging2017]. Using a task requiring participants to detect which of multiple objects had changed its trajectory, @kennedyEarlyAgerelatedDecline2009 found a steep decline between 30 and 60 years, where the effective numbers of tracked trajectories during Tripathy's multiple trajectory tracking task dropped by about 20% with each decade of aging, which could not be explained by a drop in visual acuity. This is interesting in itself, and is something that theories of aging and attention ought to explain, but I can't say more as I know very little about aging. This result must also color our interpretation of individual-difference studies using samples with a wide age range â€” some of the correlations with other tasks will likely be due to those abilities declining together rather than them being linked in people of the same age. That's still useful for drawing inferences, but slightly different inferences.

Researchers have taken what one might call a wide-angle approach to MOT individual difference studies. They've tested participants with a wide variety of tests, to see which mental abilities are linked. However, the first large-scale study concentrated on tasks typicaly thought of as attentional [@huangMeasuringInterrelationsMultiple2012]. Liqiang Huang and his colleagues used tests tof conjunction search, configuration search, counting, feature access, spatial pattern, response selection, visual short-term memory, change blindness, Raven's test of intelligence, visual marking, attentional capture, consonance-driven orienting, inhibition of return, task switching, mental rotation, and Stroop. Administered to a sample of Chinese university students (age not reported, but presumably mostly young adults), many of these tasks showed high reliabilities of over 0.9, meaning that there was a potential for high inter-task correlations (inter-task correlations are limited by the reliabilities of the two tasks involved). However, the highest correlation of a task with MOT was 0.4. The task was counting, which required judging whether the number of dots in a brief (400 ms) display were odd or even. Change blindness, feature access, visual working memory, and visual marking were runner ups with correlations of around 0.3. 
<!-- @huangMeasuringInterrelationsMultiple2012 "For each variable, reliability was estimated by calculating the split-half (odd-even) correlations and the Spearman-Brown formula was used for adjustment. All of the 17 paradigms met the minimum reliability of 0.7."  So I guess these are not raw correlations he reports from then on -->

That no task had a higher correlation is very interesting, but also disappointing. It's interesting because it suggests that MOT involves distinct abilities from several other tasks that on various grounds have been lumped together with MOT as all being "attentional". This is disappointing first because it suggests that our theoretical understanding of these tasks is sorely lacking. It's also disappointing because the low correlations mean that it's hard to discern the pattern of correlations, e.g. from most correlated to least correlated with MOT - when the highest correlations is 0.4, one needs very narrow confidence intervals to be confident of the ordering of the tasks.
<!--, although another possibility is that the way people are different from each other has little to do with the--> 

@trevinoBridgingCognitiveNeuropsychological2021 reported data from more than 400 participants tested online, an opportunity sample with a very wide range of ages, from 18 to 89. They tested a set of cognitive, attentional, and common neuropsychological tasks: arithmetic word problems, the trial-making task, digit span, digit symbol coding, letter cancellation, spatial span, approximate number sense, flanker interference, gradual onset continuous performance, spatial configuration visual search, and visual working memory as well as MOT. MOT had among the highest reliabilities, at 0.92. MOT performance had  little correlation with performance on the task designed to measure sustained attention over an extended period (about five minutes, the gradual-onset continual performance task [@fortenbaughSustainedAttentionLife2015]. This supports the tentative conclusion, already suggested in Chapter \@ref(whichAspects), that the ability to sustain attention without lapses is not an important determinant of tracking performance (as was ).

In the @trevinoBridgingCognitiveNeuropsychological2021 inventory, the task that most resembled the counting task of @huangMeasuringInterrelationsMultiple2012, which @huangMeasuringInterrelationsMultiple2012 found had a high correlation with MOT, was the approximate number sense task, with a moderate correlation of 0.3. It differed from the counting task of @huangMeasuringInterrelationsMultiple2012 by not testing the subitizing (less than 5 items) range, which might help explain any discrepancy. In a more limited study, @eayrsEstablishingIndividualDifferences2018 found, using hierarchical regression, that subitizing made a contribution to predicting MOT performance that was somewhat separate to that of an estimation task using larger set sizes. <!-- change blindness, load-induced blindness and multiple object tracking, MOT split-half reliability of .87 -->

The tasks with the highest correlations with MOT in the data of @trevinoBridgingCognitiveNeuropsychological2021 were visual working memory, spatial span, letter cancellation, and digit symbol coding, all at around 0.5. As the authors pointed out, the letter cancellation and digit symbol coding tasks are complex tasks developed in neuropsychology that are believed to reflect a number of abilities. This makes it hard to interpret their correlation with MOT. Spatial span and visual working memory are quite different from MOT, but similar to each other in that they both involve short-term memory for multiple visual stimuli.

Overall, there is a reasonable level of agreement across these individual-differences studies, as well as others not described here, such as @trickSpatialVisuospatialWorking2012. They agree that visual working memory has a robust correlation with MOT performance, which is particularly interesting because superficially, MOT imposes little to no memory demand. Most researchers conceive of tracking as involving allocating multifocal attention to multiple targets simultaneously, with a process autonomous to memory causing the foci of attention to move along with the moving targets.

From the consistently strong correlation of MOT performance with visual working memory, it is tempting to conclude that mechanistically the two tasks are tightly linked. However, it must be remembered that working memory tasks are among the best predictors of a wide range of tasks, including intelligence as well as the Stroop task, spatial cuing, and task switching [e.g. @redickWorkingMemoryCapacity2006].

## Going deeper

Variation in multiple object tracking is unlikely to be caused by just one ability. Thanks to three decades of work, we now understand that tracking performance can be limited by spatial interference and temporal interference, as well as less task-specific factors such as lapses of attention. And there may be other abilities that substantially contribute.

Unfortunately, no individual difference study to date seems to have attempted to partial out the possible components of MOT (e.g., spatial interference versus temporal interference) to see whether they show different patterns of correlations with other tasks. In the realm of spatial interference with static stimuli, even studies with small sample sizes have revealed substantial individual differences [@petrovAsymmetriesIdiosyncraticHot2011], such as larger crowding zones in some types of dyslexia [@jooOptimizingTextIndividual2018]. These differences may form a large part of inter-individual differences in MOT. There is also evidence that training with action video games can reduce spatial interference and improve reading ability [@bertoniExcessiveVisualCrowding2019], making it especially important to investigate spatial interference further.

With the growth of online testing, however, the sample sizes required for individual difference studies have become easier to obtain, and so individual differences are a promising future direction. However, researchers who are more familiar with the issues and analyses of within-subjects studies must be aware of the different issues that are important for individual-differences studies.

<!--@wilmerMultipleObjectTracking2016 Multiple object tracking predicts math potential-->


<!--In Huang et al.â€™s study, the correlation between MOT and VWM was .30, the correlation between (configuration) search and MOT was .30, and the correlation between search and VWM was .23. In our data, however, MOT and VWM were much more closely correlated with each other (.51)-->

