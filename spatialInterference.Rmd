# Spatial interference {#spatialInterference}

Details of the world that are much smaller than ourselves, like the fibers that make up paper, or the individual ink blotches laid down by a printer, are inaccessible to the naked eye. This is a familiar limit on our visual abilities, one that is measured when we go to the optometrist. Line segments or objects that are too close together are experienced as a single unit.

Even when two objects are spaced far apart enough that we perceive them as two objects rather than one, they are not processed entirely separately by the brain. Receptive fields grow larger and larger as visual signals ascend the visual hierarchy, and this can result in a degraded representation for objects that are near each other. This is an example of spatial interference.

<!--Decades before @franconeriHowManyLocations2007 conducted experiments on the selection of multiple locations with different densities, researchers had recognized the existence of spatial interference in dense displays-->
A large body of psychophysical work has investigated how spatial interference impairs object perception at high display densities [e.g., @wolfordPerturbationModelLetter1975; @korteUberGestaltauffassungIm1923; @strasburgerDancingLettersTicks2014].

```{r, echo=FALSE, fig.cap = "When one gazes at the central dot, the central letter to the left is not crowded, but the central letter to the right is."}
DiagrammeR::grViz("digraph {

graph [layout = dot, rankdir = LR]

# define the global styles of the nodes. We can override these in box if we wish
node [shape = rectangle, style = filled, color=White, fillcolor = White, fontsize = 40]

a [label = 'O']
fixation [label =  '', shape=circle, fillcolor=Black, width=.2, height=.2]
b [label = ' ']
c [label = ' ']
d [label = 'J']
e [label = ' ']
e2 [label = ' ']
e3 [label = 'S']

f [label = 'O']
g [label = 'R']
h [label = 'L']
i [label = 'H']
j [label = 'Y']
k [label = 'M']
l [label = 'S']

# edge definitions with the node IDs
edge [label='', penwidth=0, arrowsize=0]
a  -> b;
edge [label='', penwidth=0, arrowsize=0]
b -> c
edge [label='', penwidth=0, arrowsize=0]
c -> d
edge [label='', penwidth=0, arrowsize=0]
d -> e
edge [label='', penwidth=0, arrowsize=0]
e -> e2
edge [label='', penwidth=0, arrowsize=0]
e2 -> e3
edge [label='', penwidth=0, arrowsize=0]
e3 -> fixation

edge [label='', penwidth=0, arrowsize=0]
fixation -> f
edge [label='', penwidth=0, arrowsize=0]
f -> g
edge [label='', penwidth=0, arrowsize=0]
g -> h
edge [label='', penwidth=0, arrowsize=0]
h -> i
edge [label='', penwidth=0, arrowsize=0]
i -> j
edge [label='', penwidth=0, arrowsize=0]
j -> k
edge [label='', penwidth=0, arrowsize=0]
k -> l
}")
```

In the above display, if you gaze at the central dot, you likely will be able to perceive the middle letter to the left fairly easily as a 'J'. However, if while keeping your eyes fixed on the central dot you instead try to perceive the central letter to the right, the task is much more difficult. This spatial interference phenomenon is called "crowding" in the perception literature.

Most studies of crowding ask participants to identify a letter or other stationary target when flanking stimuli are placed at various separations from the target. The separation needed to avoid crowding varies depending on the display spatial arrangement, but on average is about half the eccentricity of the target; the interference diminishes rapidly as separation increases beyond that [@boumaInteractionEffectsParafoveal1970a; @gurnseyCrowdingSizeEccentricity2011]. In the display above, for example, the letters on the same side as the 'J' are separated from it by more than half the 'J's distance from the fixation point, so they have little to no effect on its identification. Setting the targets and distractors in motion has little effect [@bexShapeSizeCrowding2003].

When flankers are presented close to a target, they not only prevent identification of the target, they can also prevent the target from being individually selected by attention, and apparently also for multiple object tracking [@intriligatorSpatialResolutionVisual2001]. When a target and distractor are too close to be distinguished by tracking processes, the tracking process may end up tracking a distractor rather than the target.

Crowding happens frequently in the displays typically used by MOT researchers, in that in most experiments, objects are not prevented from entering the targets' crowding zones (as mentioned above, about half the stimulus' eccentricity). It is not surprising, then, that in typical MOT displays, greater proximity of targets and distractors is associated with poor performance [@shimSpatialSeparationTargets2008; @tombuAttentionalCostsMultipleobject2008].

## Spatial interference does not explain why tracking many targets is more difficult than tracking only a few

<!-- MOVE TO PREFACE TO SPATIAL AND TEMPORAL INTERFERENCE The errors in MOT occur largely when a target and a distractor come close to each other, in space or in time. During a close encounter between a target and a distractor, one may end up tracking the distractor rather than the target.
 @baeCloseEncountersDistracting2012 @drewSwappingDroppingElectrophysiological2012 -->

In 2008, Steven Franconeri and colleagues claimed that spatial interference is the *only* reason why performance is worse when more targets are to be tracked [@franconeriEvidenceSpeedLimit2008]. In the previous chapter, we introduced the idea of a resource that, divided among more targets, results in worse tracking performance, Franconeri suggested that this does not exist, or at least, for tracking the only thing that becomes depleted with more targets is the area of the visual field not undergoing inhibition; the inhibition stemming from the inhibitory surround that surrounds each tracked target [@franconeriEvidenceSpeedLimit2008; @franconeriFlexibleCognitiveResources2013; @franconeriTrackingMultipleObjects2010a]. The inhibitory surrounds of nearby targets interfere with each other. A provocative implication of their theory, they pointed out, was that "there is no limit on the number of trackers, and no limit per se on tracking capacity" (@franconeriTrackingMultipleObjects2010a, p.920); a very large number of targets could be tracked because as long as targets could be kept far from each other, they could be tracked. Joining Franconeri in making this claim was Zenon Pylyshyn himself as well as other senior visual cognition researchers including James Enns, George Alvarez, and Patrick Cavanagh, my PhD advisor.

In testing this theory, @franconeriTrackingMultipleObjects2010a unfortunately did not isolate the separation between objects from other display variables. MOT studies generally rarely control the retinal separation among the objects in a display, even when they require participants to fixate at the display center. @franconeriTrackingMultipleObjects2010a, for example, kept object trajectories nearly constant in their experiments but varied the total distance traveled by the objects (by varying both speed and trial length), on the basis that if close encounters were the only cause of errors, they should be proportional to the total distance traveled. The result was that performance did decrease with distance traveled, but there was little effect of the different object speeds and trial durations that they used. This was taken as strong support for the theory that only spatial proximity mattered. As @franconeriTrackingMultipleObjects2010a stated, their hypothesis that "barring object-spacing constraints, people could reliably track an unlimited number of objects as fast as they could track a single object" constituted a "simple and falsifiable hypothesis". 

To test Franconeri's simple and falsifiable hypothesis, in 2012 my student Wei-Ying Chen and I conducted several experiments. We kept the objects in a display widely separated to avoid the spatial interference that Franconeri claimed was the only factor that could prevent people from tracking many targets. In one experiment, we used an ordinary computer screen but created a wide-field display by having participants bring their noses quite close to it. This allowed us to keep targets and distractors dozens of degrees of visual angle from each other [@holcombeExhaustingAttentionalTracking2012]. The basic display configuration is shown in Figure \@ref(fig:HC2012BasicTrial).

```{r HC2012BasicTrial, echo=FALSE, out.width="100%", fig.cap="In experiments by Holcombe and Chen (2012), after the targets were highlighted in white, all the discs became red and revolved about the fixation point. During this interval, each pair of discs occasionally reversed their direction. After 3–3.8 s, the discs stop, one ring is indicated, and the participant clicks on one disc of that ring."}
knitr::include_graphics("imagesForRmd/HolcombeChen2012BasicTrial.png")
```

We found that even when all the objects in the display were extremely widely-spaced, speed thresholds declined dramatically with the number of targets. To us, this appeared to falsify the theory of @franconeriTrackingMultipleObjects2010a. For the 2011 Vision Sciences Society conference where we reported these findings, we entitled our poster "The resource theory of tracking is right! - at high speeds one may only be able to track a single target (even if no crowding occurs)". What we meant was that each target takes up some of a very limited processing capacity - a resource that was attentional in that it could be applied anywhere in the visual field, or at least anywhere within a hemifield (\@ref(twoBrains)). The amount of this resource applied to a target determines the fastest speed at which a target can be tracked.

Unconvinced by the findings of Wei-Ying Chen and I, Franconeri et al. (who did not say why) continued to push their spatial interference theory of tracking, and moreover they took the idea of spatial interference much further, suggesting that the same basic idea could also explain capacity limits on object recognition, visual working memory, and motor control, writing that "competitive interactions are the roots of capacity limits for tasks such as object recognition and multiple object tracking” (p.2) and that capacity limits arise only because "items interact destructively when they are close enough for their activity profiles to overlap" (p.2) [@franconeriFlexibleCognitiveResources2013]. Yet to explain the @holcombeExhaustingAttentionalTracking2012 results, the spatial interference posited by Franconeri would have to extend over a very long distance, farther than anything that had been reported in behavioral studies. Furthermore, if there were such long-range spatial gradients of interference present, they should have shown up in the results of @holcombeExhaustingAttentionalTracking2012 as worse performance for the intermediate spatial separations we tested than for the largest separations.

@franconeriResourceTheoryNot2013 addressed these problems with their theory in a reply to a letter I wrote in response to @franconeriFlexibleCognitiveResources2013. @franconeriResourceTheoryNot2013 pointed to neurophysiological recordings in the lateral intraparietal area (LIP) of rhesus macaque monkeys. A study by @falknerSurroundSuppressionSharpens2010, presented monkeys with a stimulus and the monkey was subsequently cued to execute a saccade to that stimulus by offset of the fixation point. In some trials another stimulus was flashed 50 ms prior to the offset of the fixation point. That flashed stimulus, which was positioned in the receptive field of an LIP cell the researchers were recording from, allowed researchers to show that the LIP cell's response was suppressed relative to trials with no saccade target. This was true even when the saccade target was very distant - statistically significant impairment was found for separations as large as 40 deg for some cells. There was a spatial gradient to this interference, but the data suggested it could be quite shallow, allowing @franconeriResourceTheoryNot2013 to write that "levels of surround suppression are strong at both distances, and thus no difference in performance is expected" for the separations tested by Holcombe and Chen (2012). @franconeriResourceTheoryNot2013 was published as an "online comment" at _Trends in Cognitive Sciences_, as a reply to my letter that the editor had also suggested I post as an online coment. Unfortunately, some time later both comments were lost by the publisher, Elsevier, when they migrated their system. In the case of my comment, I found an old draft on my computer, updated it slightly, and posted it at @holcombeCommentCapacityLimits2019.

The neural suppression documented by @falknerSurroundSuppressionSharpens2010 has one property that strongly suggests it is not one of the processes that limit our ability to track multiple objects. Specifically, @falknerSurroundSuppressionSharpens2010 found that nearly as often as not, the location in the visual field that yielded the most suppression was *not* in the same hemifield as the receptive field center. But as we will see in \@ref(twoBrains), the cost of additional targets in attentional tracking is largely independent in the two hemifields. Evidently, then, LIP suppression is not what causes worse performance when there are more targets. Instead, as @falknerSurroundSuppressionSharpens2010 themselves concluded, these LIP cells may help mediate a global (not hemifield-specific) salience computation for prioritizing saccade or attentional targets, wherever they are in the visual field.

In light of all the above, it seemed the evidence ruled against the idea that spatial interference was the sole reason that people perform worse with more targets. Moreover, to accommodate the results we reported in  @holcombeExhaustingAttentionalTracking2012, the spatial interference account advocated by @franconeriResourceTheoryNot2013 seemed to have been watered down until it was practically indistinguishable from a conventional resource theory – if spatial interference extended over an entire visual field (or hemifield) with no detectable diminution at large separations relative to small separations, then it no longer seemed appropriate to refer to it as "spatial" interference. Instead, finite processing capacity might be both a more parsimonious and straightforward description.

Having failed to find evidence for long-range spatial interference, I decided to investigate the form of spatial interference that I was confident actually existed: short-range interference. Previous studies of tracking did not provide much evidence about how far that interference extended - either they did not control eccentricity (e.g., @feriaSpeedHasEffect2013) or they only tested a few separations (e.g., @tombuTrackingPlanetsMoons2011). 

In experiments published in 2014, we assessed tracking performance for two targets using several configurations and separations between the targets' trajectories [@holcombeObjectTrackingAbsence2014]. Performance improved with separation, but only up to a distance of about half the target's eccentricity, similar to what was found in the literature on crowding  [@strasburgerDancingLettersTicks2014]. In a few of our experiments there was a trend for better performance even as separation increased beyond the crowding zone, but this effect was small and not statistically significant. These findings supported my suspicion that spatial interference is largely confined to the crowding range, and that the performance deficit when there are more targets to track is caused by a limited processing resource.

The experiments we reported in @holcombeObjectTrackingAbsence2014 did yield one finding that surprised us. In the one-target conditions, outside the crowding range we found that performance *decreased* with separation from the other pair of (untracked) objects. This unexpected cost of separation was only statistically significant in one experiment, but the trend was present in all four experiments that varied separation outside the crowding range. This might potentially be explained by the configural or group-based processing documented by @billHierarchicalStructureEmployed2020 and others, as grouping of distant elements is usually weaker than for nearby elements [e.g., @kubovyLawfulnessGroupingProximity1998].

## The mechanisms that cause spatial interference

As explained in the beginning of this chapter, one cause of short-range spatial interference is simply lack of spatial resolution by the processes that mediate tracking. If a process cannot distinguish between two locations, either because of a noisy representation of those locations or because the two locations are treated as one, then a target may often be lost when it comes too close to a distractor. This would be true of any imperfect mechanism, regardless of whether it is biological or man-made. The particular way that the human visual system is put together, however, may result in forms of spatial interference that do not occur in, for example, computer algorithms engineered for object tracking.

As described in \@ref(bottlenecks), our visual processing architecture has a pyramid-like structure, with processing at the retina being local and massively parallel, and then gradually converging such that neurons at higher stages have receptive fields responsive to large regions. At these higher stages processes critical to tasks like tracking or face recognition occur. Face-selective neurons, for example, are situated in temporal cortex and have very large receptive fields. For tracking, while the parietal cortex is thought to be more important than the temporal cortex, the neurons in these parietal areas again have large receptive fields.

A large receptive field is a problem when the task is to recognize an object in clutter or to track a moving target in the presence of nearby moving distractors. In the case of object recognition, without a mechanism to prevent processing of the other objects that share the receptive field, object recognition would have access to only a mishmash of the objects' features. Indeed, this indiscriminate combining of features is thought to be one reason for perceptual illusory conjunctions of features from different objects. Similarly, for object tracking, isolating the target is necessary to keep it distinguished from the distractors.

In principle, our visual systems might include attentional processes that when selecting a target can completely exclude distractors' visual signals from reaching the larger receptive fields. Actually implementing such a system using realistic biological mechanisms with our pyramid architecture, however, looks to be difficult [@tsotsosModelingVisualAttention1995]. Neural recordings reveal that while the signals from stimuli irrelevant to the current task are suppressed somewhat, they still have some effect on neural responses. The particular mechanism used by our visual system does appear to include active suppression of a region around a target, even if these effects are not large or spatially extensive enough to explain why we can only track a limited number of objects. The computer scientist John Tsotsos has long championed surround suppresssion as a practical way for high-level areas of the brain to isolate a stimulus in their large receptive fields. Such suppression likely involves descending connections from high-level areas and possibly recurrent processing [@tsotsosDifferentStagesVisual2008].

Note that on Tsotsos' account, it is only targets, not distractors, that have a region of suppression surrounding them. While the attempt of @franconeriTrackingMultipleObjects2010a to attribute all of the cost of tracking additional targets to surround suppression among targets appears to have been misguided, in @holcombeObjectTrackingAbsence2014 we did find some tentative evidence supporting a greater range of interference in the two-target condition compared to the one-target condition. Again, the effect was small relative to the total additional-target performance cost. It appears that overlapping surround suppression associated with targets may impair tracking, but the spatial range of this does not extend much beyond the classic crowding range.

<!-- p.11:"the effect of separation was not significantly greater in the two- target condition than the one-target condition, but the difference did approach significance. Experiment 2: F(1, 7) 1⁄4 3.52, p=0.103. Experiment 3: F(1, 9) 1⁄4 3.89, p=0.054. Such an interaction would be consistent with the proposal that attending to an object results in an inhibitory surround, as attention to the two targets could then inhibit each other. This interaction is small, however, relative to the size of the additional-target cost (see Figure 7), suggesting that crowding is not responsible for much of the additional-target cost."
--> 

<!--While the @franconeriTrackingMultipleObjects2010a spatial interference theory is still frequently cited uncritically, the evidence against it seems to be strong.-->

Crowding, the impairment of object identification by nearby objects, has been studied more extensively than the spatial interference associated with object tracking. Like for tracking, however, the possibility of a suppression zone specific to targets remains understudied, as very few studies of crowding have varied the number of targets. I have found one study of the identification of briefly-presented stimuli which found that attending to additional gratings within the crowding range of a first grating resulted in greater impairment for identifying a letter [@mareschalAttentionalModulationCrowding2010]. This is consistent with the existence of surround suppression around each target. <!--Unfortunately, however, the study did not investigate how much further, if at all, spatial interference extended when there are more targets.--> 

<!--As reviewed by @holcombeObjectTrackingAbsence2014, while dozens of MOT papers have manipulated spatial proximity, few have both required fixation and scaled separation with eccentricity such that the relationship of target load and the range of spatial interference could be directly assessed.-->

<!--@maki-marttunenDistinctNeuralMechanisms2019:"In both cohorts, increased load and close encounters (i.e., close spatial proximity) led to reduced accuracy in an additive manner. Load was associated with pupil dilations, whereas close encounters were not. Activity in dorsal attentional areas and frequency of saccades were proportionally larger both with higher levels of load and close encounters. Close encounters recruited additionally ventral attentional areas that may reflect orienting mechanisms. The activity in two brainstem nuclei, ventral tegmental area/substantia nigra and locus coeruleus, showed clearly dissociated patterns. Our results constitute convergent evidence indicating that different mechanisms underlie processing challenges due to load and object spacing."-->

<!--Distractors that pass closer to targets can experience more inhibition (as measured by probes on objects; @doranRoleVisualAttention2010)-->

<!--MENTION THAT HOLCOMBECHEN FOUND NO EVIDENCE FOR SPATIAL INTERFERENCE WITH 12 OBJECTS SHARING A CIRCULAR TRAJECTORY-->

As many MOT experiments involve targets and distractors coming very close to each other, spatial interference likely contributes to many of the errors. This may be mediated partly by surround suppression around targets, as well as the inherent ambiguity regarding which is a target and which is a distractor during close encounters for any system that has limited spatial resolution. When objects are kept widely separated, it appears that spatial interference plays little to no role in tracking. Some other factor or factors, such as some sort of attentional resource, is needed to explain the dramatic decline in tracking performance that can be found with more targets even in widely-spaced displays [@holcombeObjectTrackingAbsence2014; @holcombeExhaustingAttentionalTracking2012; @holcombeSplittingAttentionReduces2013].
<!--As will become clear in the next section, however, in such conditions, temporal interference can determine tracking performance. -->

<!--
## Spatial selection of multiple locations

While multiple object tracking seems to require maintaining selection of moving objects, one can also ask about the capacity to maintain selection of stationary objects. If one cannot select the objects when they are stationary, perhaps one has no chance of tracking them when they are moving. Actually, the differing motion direction of moving objects may facilitate distinguishing among them, which will be discussed in section \@ref(beyondLocation), but nevertheless the processes that allow selection of multiple stationary objects are very likely part and parcel of those that support tracking.

Is selection of static objects resource-limited? @franconeriHowManyLocations2007 investigated this with two concentric circular arrays of stationary dots that were centered on fixation. Between one and eight of the dots were briefly highlighted, and then each dot was replaced by either a small horizontal or a small vertical bar. The participants' task was to search for a vertical bar, which was guaranteed to appear in the previously-cued locations. The participants were to press one key if a vertical bar was present among the cued locations, and another key if none of those locations contained a vertical bar.

In a sparse display with twelve locations, @franconeriHowManyLocations2007 found that average performance dropped from 98% when two locations were cued to 91% when six locations were cued. This decrease is fairly small, suggesting that if the result were to generalize to typical MOT displays, spatial selection processes would contribute only a small portion of the performance decrease with greater set sizes. However, MOT studies frequently allow objects to come much closer to each other than the spacing that @franconeriHowManyLocations2007 used in their sparse condition. In the denser conditions tested by @franconeriHowManyLocations2007, performance again started at a very high level for two cued locations, but dropped much more, to 74% correct or less for six cued locations.

It is difficult to know how these results can be translated into MOT tasks. The selection demands in a typical MOT task may be less taxing than in the @franconeriHowManyLocations2007 experiments, because participants need only maintain their attention on the objects, not search through them. However, it remains unclear how much less demanding that is, so we still do not know how much of the target-load effect in typical MOT displays can be attributed to failures of selection that would occur even were the objects to remain stationary.

In practice, people make many more errors in a tracking task if the targets move than if they do not move (CITATION NEEDED). This observation is not enough, however, to conclude that the limits on spatial selection are not the cause of most errors in moving-object tracking. One reason is that visual working memory can greatly benefit performance with static locations, but memory for locations likely does not update very well in the presence of motion, as will be discussed in section \@ref(identity).
-->

<!-- In some experiments, the targets are initially stationary, but nevertheless typically are easily selected as they flicker or are shown in a different color to make them highly salient [@drewNeuralMeasuresIndividual2008; @franconeriHowManyLocations2007].  -->

