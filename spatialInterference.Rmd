# Spatial interference {#spatialInterference}

Details much smaller than ourselves, like the fibers of a sheet of paper, or the individual ink blotches laid down by a printer, are inaccessible to the eye. Visual stimuli that are very close together are experienced as a single unit.

Even when two objects are spaced far apart enough that we perceive them as two objects rather than one, they are not processed entirely separately by the brain. Receptive fields grow larger as signals ascend the visual hierarchy, and this can degrade the representation of objects that are near each other. Such spatial interference is evident in Figure \@ref(fig:crowdingDemo).

```{r crowdingDemo, echo=FALSE, fig.cap = "When one gazes at the central dot, the central letter to the left is not crowded, but the central letter to the right is."}
DiagrammeR::grViz("digraph {

graph [layout = dot, rankdir = LR]

# define the global styles of the nodes. We can override these in box if we wish
node [shape = rectangle, style = filled, color=White, fillcolor = White, fontsize = 40]

a [label = 'O']
fixation [label =  '', shape=circle, fillcolor=Black, width=.2, height=.2]
b [label = ' ']
c [label = ' ']
d [label = 'J']
e [label = ' ']
e2 [label = ' ']
e3 [label = 'S']

f [label = 'O']
g [label = 'R']
h [label = 'L']
i [label = 'H']
j [label = 'Y']
k [label = 'M']
l [label = 'S']

# edge definitions with the node IDs
edge [label='', penwidth=0, arrowsize=0]
a  -> b;
edge [label='', penwidth=0, arrowsize=0]
b -> c
edge [label='', penwidth=0, arrowsize=0]
c -> d
edge [label='', penwidth=0, arrowsize=0]
d -> e
edge [label='', penwidth=0, arrowsize=0]
e -> e2
edge [label='', penwidth=0, arrowsize=0]
e2 -> e3
edge [label='', penwidth=0, arrowsize=0]
e3 -> fixation

edge [label='', penwidth=0, arrowsize=0]
fixation -> f
edge [label='', penwidth=0, arrowsize=0]
f -> g
edge [label='', penwidth=0, arrowsize=0]
g -> h
edge [label='', penwidth=0, arrowsize=0]
h -> i
edge [label='', penwidth=0, arrowsize=0]
i -> j
edge [label='', penwidth=0, arrowsize=0]
j -> k
edge [label='', penwidth=0, arrowsize=0]
k -> l
}")
```

When gazing at the Figure's central dot, you likely can perceive the middle letter to the left fairly easily as a 'J'. However, if while still keeping your eyes fixed on the central dot, you instead try to perceive the central letter to the right, the task is much more difficult. This spatial interference phenomenon is called "crowding" in the perception literature [ @wolfordPerturbationModelLetter1975; @korteUberGestaltauffassungIm1923; @strasburgerDancingLettersTicks2014].

Most crowding studies ask participants to identify a letter or other stationary target when flanking stimuli are placed at various separations from the target. How separated the flankers must be to avoid impairment of target identification varies somewhat with the spatial arrangement, but is on average about half the eccentricity of the target, with little to no impairment for greater separations [@boumaInteractionEffectsParafoveal1970; @gurnseyCrowdingSizeEccentricity2011]. <!--In the display above, for example, the letters on the same side as the 'J' are separated from it by more than half the 'J's distance from the fixation point, so they have little to no effect on its identification.--> Setting the targets and distractors in motion has little effect [@bexShapeSizeCrowding2003], suggesting that these results generalize to tracking - indeed, close flankers not only prevent identification of the target, they can also prevent the target from being individually selected by attention, including for MOT [@intriligatorSpatialResolutionVisual2001]. 

Crowding happens frequently in typical MOT displays — in most published experiments, objects are not prevented from entering the targets' crowding zones (which as mentioned above, extend to about half the stimulus' eccentricity). It is not surprising, then, that in typical MOT displays, greater proximity of targets and distractors is associated with poor performance [@shimSpatialSeparationTargets2008; @tombuAttentionalCostsMultipleobject2008]. <!--Tracking may fail, or may end up tracking a distractor rather than the target [@baeCloseEncountersDistracting2012].-->

## Spatial interference does not explain why tracking many targets is more difficult than tracking only a few

<!-- MOVE TO PREFACE TO SPATIAL AND TEMPORAL INTERFERENCE The errors in MOT occur largely when a target and a distractor come close to each other, in space or in time. During a close encounter between a target and a distractor, one may end up tracking the distractor rather than the target.
 @baeCloseEncountersDistracting2012 @drewSwappingDroppingElectrophysiological2012 -->

In 2008, Steven Franconeri and colleagues suggested that spatial interference is the *only* reason why performance is worse when more targets are to be tracked [@franconeriEvidenceSpeedLimit2008]. In the previous chapter, we introduced the idea of a mental resource that, divided among more targets, results in worse tracking performance. Franconeri suggested that for tracking at least, the only thing that becomes depleted with more targets is the area of the visual field not undergoing inhibition; inhibition stemming from a inhibitory surround around each tracked target [@franconeriEvidenceSpeedLimit2008; @franconeriFlexibleCognitiveResources2013; @franconeriTrackingMultipleObjects2010]. In other words, overlap of the inhibitory surrounds of nearby targets is the only reason for worse performance with more targets, and "there is no limit on the number of trackers, and no limit per se on tracking capacity"; "barring object-spacing constraints, people could reliably track an unlimited number of objects as fast as they could track a single object". Joining Franconeri in making this claim was Zenon Pylyshyn himself as well as other visual cognition researchers including James Enns, George Alvarez, and Patrick Cavanagh, my PhD advisor (@franconeriTrackingMultipleObjects2010, p.920).

@franconeriTrackingMultipleObjects2010 tested their theory by keeping object trajectories nearly constant in their experiments but varying the total distance traveled by the objects (by varying both speed and trial length), on the basis that if close encounters were the only cause of errors, they should be proportional to the total distance traveled. As the theory predicted, performance did decrease with distance traveled, with little to no effect of the different object speeds and trial durations that they used. @franconeriTrackingMultipleObjects2010 took this as strong support for the theory that only spatial proximity mattered. However, note that they had varied the potential for spatial interference rather indirectly, by varying the total distance traveled by the objects, rather than simply spacing the objects further apart.

As a more direct test, in 2012 my student Wei-Ying Chen and I used displays in which we could keep the objects widely separated. In one experiment, we created a wide-field display with an ordinary computer screen by having participants bring their noses quite close to it. This allowed us to keep targets and distractors dozens of degrees of visual angle from each other [@holcombeExhaustingAttentionalTracking2012]. The basic display configuration is shown in Figure \@ref(fig:HC2012BasicTrial).

```{r HC2012BasicTrial, echo=FALSE, out.width="100%", fig.cap="In experiments by Holcombe and Chen (2012), after the targets were highlighted in white, all the discs became red and revolved about the fixation point. During this interval, each pair of discs occasionally reversed their direction. After 3–3.8 s, the discs stop, one ring is indicated, and the participant clicks on one disc of that ring."}
knitr::include_graphics("imagesForRmd/HolcombeChen2012BasicTrial.png")
```

Even when all the objects in the display were extremely widely-spaced, speed thresholds declined dramatically with the number of targets. To us, this appeared to falsify the theory of @franconeriTrackingMultipleObjects2010, that spatial interference was the only factor that prevented people from tracking many targets. In a 2011 poster presentation, entitled "The resource theory of tracking is right! - at high speeds one may only be able to track a single target (even if no crowding occurs)", we suggested that each target, regardless of its distance from other objects, uses up some of a limited processing capacity - a resource that was attentional in that it could be applied anywhere in the visual field, or at least anywhere within a hemifield (\@ref(twoBrains)). The amount of this resource that is applied to a target determines the fastest speed at which a target can be tracked.

Franconeri et al. did not say why they were unconvinced by the findings of Wei-Ying Chen and I, but they took their spatial interference idea much further, suggesting that it could explain the apparent capacity limits on not just tracking, but also on object recognition, visual working memory, and motor control, writing that in each case capacity limits arise only because "items interact destructively when they are close enough for their activity profiles to overlap" (p.2) [@franconeriFlexibleCognitiveResources2013].

To explain the @holcombeExhaustingAttentionalTracking2012 results, spatial interference would have to extend over a very long distance, farther than anything that had been reported in behavioral studies. If there were such long-range spatial gradients of interference present, it seemed to me that they should have shown up in the results of @holcombeExhaustingAttentionalTracking2012 as worse performance for the intermediate spatial separations tested than for the largest separations we tested. I made this point in @holcombeCommentCapacityLimits2019, and in reply, @franconeriResourceTheoryNot2013 pointed to a neurophysiological recording in the lateral intraparietal area (LIP) of rhesus macaque monkeys by @falknerSurroundSuppressionSharpens2010, who cued monkeys to execute a saccade to a visual stimulus. In some trials a second stimulus was flashed 50 ms prior to the saccade execution cue. That second stimulus was positioned in the receptive field of an LIP cell the researchers were recording from, allowing researchers to show that the LIP cell's response was suppressed relative to trials that did not include a saccade target. This suppression occurred even when the saccade target was very distant - a statistically significant impairment was found for separations as large as 40 deg for some cells.

The data of @falknerSurroundSuppressionSharpens2010 were consistent with the spatial gradient of this interference being quite shallow, allowing @franconeriResourceTheoryNot2013 to write that "levels of surround suppression are strong at both distances, and thus no difference in performance is expected" for the separations tested by Holcombe and Chen (2012). <!--@franconeriResourceTheoryNot2013 was published as an "online comment" at _Trends in Cognitive Sciences_, as a reply to my letter that the editor had also suggested I post as an online coment. Unfortunately, some time later both comments were lost by the publisher, Elsevier, when they migrated their system. In the case of my comment, I found an old draft on my computer, updated it slightly, and posted it at @holcombeCommentCapacityLimits2019.--> One property of the neural suppression documented by @falknerSurroundSuppressionSharpens2010 strongly suggests, however, that it is not one of the processes that limit our ability to track multiple objects. Specifically, @falknerSurroundSuppressionSharpens2010 found that nearly as often as not, the location in the visual field that yielded the most suppression was *not* in the same hemifield as the receptive field center. But as we will see in \@ref(twoBrains), the cost of additional targets for MOT is largely independent in the two hemifields. Evidently, then, the suppression observed in LIP is not what causes worse MOT performance when there are more targets. Instead, as @falknerSurroundSuppressionSharpens2010 themselves concluded, these LIP cells may mediate a global (not hemifield-specific) salience computation for prioritizing saccade or attentional targets.

<!--In light of all the above, it seemed the evidence ruled against the idea that spatial interference was the sole reason that people perform worse with more targets. Moreover, to accommodate the results we reported in  @holcombeExhaustingAttentionalTracking2012, the spatial interference account advocated by @franconeriResourceTheoryNot2013 seemed to have been watered down until it was practically indistinguishable from a conventional resource theory – if spatial interference extended over an entire visual field (or hemifield) with no detectable diminution at large separations relative to small separations, then it no longer seemed appropriate to refer to it as "spatial" interference. Instead, finite processing capacity might be both a more parsimonious and straightforward description.-->

Having failed to find behavioral evidence for long-range spatial interference, my lab decided to focus on the form of spatial interference that we were confident actually existed: short-range interference. Previous studies of tracking did not provide much evidence about how far that interference extended - either they did not control for eccentricity (e.g., @feriaSpeedHasEffect2013) or they only tested a few separations (e.g., @tombuTrackingPlanetsMoons2011).

In experiments published in 2014, we assessed tracking performance for two targets using spatial separations that ranged from within the interference distance documented in crowding studies through to very large separations. Our experiments validated that interference was confined to a short range [@holcombeObjectTrackingAbsence2014]. Specifically, performance improved with separation, but only up to a distance of about half the target's eccentricity, as is also found for crowding [@strasburgerDancingLettersTicks2014]. In a few experiments there was a trend for better performance as separation increased further, beyond the crowding zone, but this effect was small and not statistically significant. These findings were consistent with our supposition from our previous studies: spatial interference is largely confined to the crowding range. When objects are widely spaced, then, the deficit associated with tracking more targets is caused by a limited processing resource.

One result did surprise us: in the one-target conditions only, outside the crowding range, we found that performance *decreased* with separation from the other pair of (untracked) objects. This unexpected *cost* of separation was only statistically significant in one experiment, but the trend was present in all four experiments that varied separation outside the crowding range. This might be explained by configural or group-based processing (Section \@ref(grouping)), as grouping declines with distance [@kubovyLawfulnessGroupingProximity1998].

## The mechanisms that cause spatial interference

As explained in the beginning of this Section, one cause of short-range spatial interference is simply poor spatial resolution. If tracking cannot distinguish between two locations, either because of a noisy representation of those locations or because the two locations are treated as one, then a target may often be lost when it comes too close to a distractor. This would be true of any imperfect mechanism, biological or man-made. The particular way that the human visual system is put together, however, results in forms of spatial interference that do not occur in, for example, many computer algorithms engineered for object tracking.

Our visual processing architecture has a pyramid-like structure, with local, massively parallel processing at the retina, followed by a gradual convergence to neurons at higher stages with receptive fields responsive to large regions. Processes critical to tasks like tracking or face recognition rely on these higher stages. Face-selective neurons, for example, are situated in temporal cortex and have large receptive fields. For tracking, the parietal cortex is thought to be more important than the temporal cortex, but the neurons in these parietal areas also have large receptive fields.

A large receptive field can be a problem when the task is to recognize an object in clutter. Without a mechanism to prevent processing of the other objects that share the receptive field, object recognition would have access to only a mishmash of the objects' features. Indeed, this indiscriminate combining of features is thought to be one reason for the phenomenon of illusory perceptual conjunctions of features from different objects [@treismanIllusoryConjunctionsPerception1982]. For object tracking as well, isolating the target is necessary to keep it distinguished from the distractors.

In principle, our visual systems might include selection processes that when selecting a target can completely exclude distractors' visual signals from reaching the larger receptive fields. Implementing such a system using realistic biological mechanisms with our pyramid architecture, however, is difficult [@tsotsosModelingVisualAttention1995]. Indeed, while the signals from stimuli irrelevant to the current task are suppressed to some extent, neural recordings reveal that they still have an effect on responses. The computer scientist John Tsotsos has championed surround suppression as a practical way for high-level areas of the brain to isolate a target stimulus. Such suppression likely involves descending connections from high-level areas and possibly recurrent processing [@tsotsosDifferentStagesVisual2008]. However, the evidence I have reviewed suggests that these effects are not spatially extensive enough to explain why we can only track a limited number of objects. 

<!--Note that on Tsotsos' account, it is only targets, not distractors, that have a region of suppression surrounding them. While the attempt of @franconeriTrackingMultipleObjects2010 to attribute all of the cost of tracking additional targets to surround suppression among targets appears to have been misguided, in @holcombeObjectTrackingAbsence2014 we did find some tentative evidence supporting a greater range of interference in the two-target condition compared to the one-target condition. Again, the effect was small relative to the total additional-target performance cost. It appears that overlapping surround suppression associated with targets may impair tracking, but the spatial range of this does not extend much beyond the classic crowding range.-->

<!-- p.11:"the effect of separation was not significantly greater in the two- target condition than the one-target condition, but the difference did approach significance. Experiment 2: F(1, 7) 1⁄4 3.52, p=0.103. Experiment 3: F(1, 9) 1⁄4 3.89, p=0.054. Such an interaction would be consistent with the proposal that attending to an object results in an inhibitory surround, as attention to the two targets could then inhibit each other. This interaction is small, however, relative to the size of the additional-target cost (see Figure 7), suggesting that crowding is not responsible for much of the additional-target cost."
--> 

<!--While the @franconeriTrackingMultipleObjects2010 spatial interference theory is still frequently cited uncritically, the evidence against it seems to be strong.-->

The possibility of a suppression zone specific to targets remains understudied, as very few studies of crowding have varied the number of targets. I have found one relevant study, which found that attending to additional gratings within the crowding range of a first grating resulted in greater impairment for identifying a letter [@mareschalAttentionalModulationCrowding2010]. This is consistent with the existence of surround suppression around each target. Unfortunately, however, the study did not investigate how much further, if at all, spatial interference extended when there are more targets.

<!--As reviewed by @holcombeObjectTrackingAbsence2014, while dozens of MOT papers have manipulated spatial proximity, few have both required fixation and scaled separation with eccentricity such that the relationship of target load and the range of spatial interference could be directly assessed.-->

<!--@maki-marttunenDistinctNeuralMechanisms2019:"In both cohorts, increased load and close encounters (i.e., close spatial proximity) led to reduced accuracy in an additive manner. Load was associated with pupil dilations, whereas close encounters were not. Activity in dorsal attentional areas and frequency of saccades were proportionally larger both with higher levels of load and close encounters. Close encounters recruited additionally ventral attentional areas that may reflect orienting mechanisms. The activity in two brainstem nuclei, ventral tegmental area/substantia nigra and locus coeruleus, showed clearly dissociated patterns. Our results constitute convergent evidence indicating that different mechanisms underlie processing challenges due to load and object spacing."-->

<!--Distractors that pass closer to targets can experience more inhibition (as measured by probes on objects; @doranRoleVisualAttention2010)-->

<!--MENTION THAT HOLCOMBECHEN FOUND NO EVIDENCE FOR SPATIAL INTERFERENCE WITH 12 OBJECTS SHARING A CIRCULAR TRAJECTORY-->

Although spatial interference in MOT does not extend very far, many MOT experiments involve targets and distractors coming very close to each other, so spatial interference likely contributes to many of the errors in a typical MOT experiment. As we have seen in this chapter, that may be largely a data limitation - something that occurs regardless of the number of targets, as a result of the inherent ambiguity regarding which is a target and which is a distractor during close encounters for any system with limited spatial resolution; when objects are kept widely separated, it appears that spatial interference plays little to no role in tracking. <!--This may be mediated partly by surround suppression around targets, as well as the inherent ambiguity regarding which is a target and which is a distractor during close encounters for any system that has limited spatial resolution.--> 

Rather than spatial interference, then, something else is needed to explain the dramatic decline in tracking performance that can be found with more targets even in widely-spaced displays [@holcombeObjectTrackingAbsence2014; @holcombeExhaustingAttentionalTracking2012; @holcombeSplittingAttentionReduces2013]. The processes underlying this capacity limitation can be described as "an attentional resource", but that doesn't tell us anything about how they work. To gain insight into the tracking processes, we would like to know what specific aspect(s) of  tracking become impaired with higher target load. A major clue was provided by @holcombeSplittingAttentionReduces2013, whose experiments revealed that *temporal* interference from distractors becomes much worse when there are more targets.

Temporal interference occurs when a target's location is not sufficiently separated in time from a distractor visiting that location. That is, if distractors visit a location too soon before and after a target has visited that location, people are unable to track. The temporal separation needed increases steeply with the number of targets tracked, approximately linearly according to the evidence so far [@holcombeSplittingAttentionReduces2013; @roudaiaDifferentEffectsAging2017]. This is easiest to explain by serial switching models (see @holcombeObjectSeparationTime2022 for a review). In summary, spatial resolution is not affected much, if at all, by target load, but temporal resolution is. This is our fourth main conclusion about tracking, as was previewed in Section \@ref(summary).

<!--
## Spatial selection of multiple locations

While multiple object tracking seems to require maintaining selection of moving objects, one can also ask about the capacity to maintain selection of stationary objects. If one cannot select the objects when they are stationary, perhaps one has no chance of tracking them when they are moving. Actually, the differing motion direction of moving objects may facilitate distinguishing among them, which will be discussed in section \@ref(beyondLocation), but nevertheless the processes that allow selection of multiple stationary objects are very likely part and parcel of those that support tracking.

Is selection of static objects resource-limited? @franconeriHowManyLocations2007 investigated this with two concentric circular arrays of stationary dots that were centered on fixation. Between one and eight of the dots were briefly highlighted, and then each dot was replaced by either a small horizontal or a small vertical bar. The participants' task was to search for a vertical bar, which was guaranteed to appear in the previously-cued locations. The participants were to press one key if a vertical bar was present among the cued locations, and another key if none of those locations contained a vertical bar.

In a sparse display with twelve locations, @franconeriHowManyLocations2007 found that average performance dropped from 98% when two locations were cued to 91% when six locations were cued. This decrease is fairly small, suggesting that if the result were to generalize to typical MOT displays, spatial selection processes would contribute only a small portion of the performance decrease with greater set sizes. However, MOT studies frequently allow objects to come much closer to each other than the spacing that @franconeriHowManyLocations2007 used in their sparse condition. In the denser conditions tested by @franconeriHowManyLocations2007, performance again started at a very high level for two cued locations, but dropped much more, to 74% correct or less for six cued locations.

It is difficult to know how these results can be translated into MOT tasks. The selection demands in a typical MOT task may be less taxing than in the @franconeriHowManyLocations2007 experiments, because participants need only maintain their attention on the objects, not search through them. However, it remains unclear how much less demanding that is, so we still do not know how much of the target-load effect in typical MOT displays can be attributed to failures of selection that would occur even were the objects to remain stationary.

In practice, people make many more errors in a tracking task if the targets move than if they do not move (CITATION NEEDED). This observation is not enough, however, to conclude that the limits on spatial selection are not the cause of most errors in moving-object tracking. One reason is that visual working memory can greatly benefit performance with static locations, but memory for locations likely does not update very well in the presence of motion, as will be discussed in section \@ref(identity).
-->

<!-- In some experiments, the targets are initially stationary, but nevertheless typically are easily selected as they flicker or are shown in a different color to make them highly salient [@drewNeuralMeasuresIndividual2008; @franconeriHowManyLocations2007].  -->

