# Which aspect(s) of tracking determine performance? {#whichAspects}

Certain brain processes can only operate on a limited number of visual representations. The term "limited resource" is often used for this, because we can choose to some extent, with visual attention, which visual representations are processed. Contrary to what Pylyshyn theorized early on, tracking processes do seem to be utilized like a continuous resource, wherein applying more resource to a target can reduce the deleterious influence of object speed or other factors. I will say more about this in a later chapter, but first want to explain the resource concept more, and make an important distinction.

To understand why we can track several objects in some circumstances, but only a few in others, we must distinguish between display factors that impose data limitations on tracking, and display factors that impose resource limitations. <!--We've already covered C=1 processing, grouping, and the nature of the objects themselves, in Chapters \@ref(objects) and \@ref(grouping).-->

The "data" in data limitation refers to sensory data [@normanDatalimitedResourcelimitedProcesses1975]. If a target moving on an unpredictable trajectory moves outside the edge of our visual field, it is a lack of data that prevents it from being tracked. No amount of mental resources can overcome a dearth of data about an unpredictable stimulus. Data limitations may also occur when sensory signals are impoverished, even if not entirely absent. For example, an object traveling at a rate faster than our neurons can register cannot be tracked due to a data limitation. So, the data being referred to here are not the pattern of light falling on the retina, but rather that light after it has been processed by the retina and after additional preattentive sensory processing.

People with poor visual acuity may perform less well on a task than people with high visual acuity, again due to differences in the sensory data that they have to work with. Thus, some individual differences are almost certainly due to data limitations rather than variation in tracking processes between people. when performance is data-limited, bringing more mental resources to bear may provide little to no benefit. The classic way that this is investigated is by varying the number of stimuli one needs to process. @normanDatalimitedResourcelimitedProcesses1975 illustrate this with a visual search study. If the number of stimuli one must evaluate does not affect how well a person can perform a task, this suggests that the task is data-limited rather than resource-limited, because performance is the same regardless of the proportion of the putative resource can be devoted to it. <!-- More reflections on the relation of the resource concept to underlying mechanisms is in Chapter \@ref(spatialInterference). -->

When a process is resource-limited, that typically is more interesting for those interested in visual attention and the capacity limits on mental processing. When response time or error rate increases with the number of distractors presented in a visual search task, that was classically interpreted as meaning that a resource-limited process is required for success at the task. As they say, however, science is hard. An elevation in e.g. error rate will also occur even if there is no resource limitation, but each additional distractor has a non-zero probability of being mistaken for a distractor, then there will be more errors with more distractors even if the probability of successfully evaluating each individual stimulus remains unchanged [@palmerAttentionVisualSearch1995]. 

The particular number of objects that can be tracked with reasonable accuracy is thus highly dependent on stimulus conditions, and some of these conditions may reflect data limitations rather than a resource limitation. Still, even in ideal conditions it seems clear that the number of objects that can be tracked is much less than the number of objects that are simultaneously processed by early stages of the visual system. There is a resource limitation, and we'd like to know which factors consume the resource. Another way to think of this is with the term that I prefer, "resource-intensive". If a deleterious stimulus factor that worsens performance is resource-intensive, this means that increasing the amount of resource devoted the stimulus can compensate for that stimulus factor.

One example is object speed. An increase in object speed can hinder performance, but reducing the number of targets, which provides more resource to the remaining targets, can make up for that. Speed, then, is resource-intensive (although as we will see in chapter \@ref(speedAndTime), there is more going on with speed than most believe). Of course, speed also can result in a data-limitation, at very high speeds, but long before such speeds are reached, speed is resource-intensive.

<!--When we discover a stimulus factor that affects multiple object tracking performance, it is worthwhile to ask whether that factor is taxing a resource-limited process or a data-limited process. That is, will increasing the number of targets exacerbate the effect of that factor?-->

In summary, to say that tracking is capacity-limited is important but not very illuminating. We want to know more about why people perform more poorly with more targets. Tracking is a complex task, and we would like to know which aspect(s) of it exactly are most capacity-limited, or "resource-intensive".

## Which factors

A top priority among tracking reseachers is understanding the reasons that tracking performance falls with the number of targets to track. Several ideas have been advanced in the literature. Perhaps spreading the tracking resource among more targets results in

* Less frequent sampling of each target.
* More noise in the representation of the spatial location of each target.
* Poorer predictions of where the targets are going, which then hinders tracking.
<!-- * Fewer neurons devoted to solving the correspondence problem. (the correspondence problem will be explained later)-->

Progress on these issues has been slow. One approach in the literature has been computational modeling. Multiple researchers have proposed models, compared their performance on human data, and declared their model a success. Rarely, however, have they quantitatively compared their model to that of another group of researchers, making it difficult to know whose model is best or whether the data simply doesn't strongly favor one model over another.

An approach that I favor is to start with a task analysis with some conjectures regarding what aspects of MOT trajectories might lead to errors, based on what we know about visual processing, and then manipulate the incidence of those aspects to test those conjectures. Once an aspect seems to be isolated (or nearly isolated) by a particular manipulation, one can measure how resource-intensive that aspect's errors are.

Here I will list a few factors that studies suggest are important.

<!--1. Spatial selection of multiple locations (even static ones)-->
1. Spatial interference
1. Temporal interference
1. Object speed <!--limit of attention-following-->
1. Use of motion direction


<!-- Each of these processes could be resource-limited or not resource-limited. That is, some of these effects may be bigger when one is attending to more targets. This helps fractionate tracking into different kinds of constituent processes -->

<!-- 
## Spatial selection of multiple locations

## Spatial interference

## Temporal interference

Temporal interference is analogous to spatial interference, just in time rather than in space. Spatial interference refers to a processing impairment when one object comes closer than a certain spatial distance to a second object, at one time. In contrast, temporal interference refers to when an object comes closer than a certain temporal distance of another, at one point in space.

The objects in typical MOT displays often travel over locations formerly occupied by another moving object. That is, after one object passes over a location, another will pass over the same location, some amount of time later. If temporal interference is a factor in object tracking, then if the amount of time that separates the two objects occupying a location is short enough, tracking will be impaired.

If objects are moving fast enough, they are perceived to blur together, because some parts of the visual system integrate over several dozen milliseconds [e.g., @hogbenPerceptualIntegrationPerceptual1974]. A more interesting question is whether temporal interference occurs on a longer timescale, more relevant to the speeds and spacings typically used in MOT tasks.

## Speed limit of attention-following

-->

In the coming chapters I will explain at length what these factors are. Of particular interest is whether each factor is resource-intensive. The table below provides an oversimplified summary of what I think we know. The degree to which each factor is hemifield specific is also included in the table, because as we will see in Chapter \@ref(twoBrains), knowing that is very important. The literature has not done a good job at determining how resource-intensive some of these factors are, hence some question marks are included in the table. 


```{r table-limits, tidy=F, echo=F}
#Create a table with column indicating how resource-intensive each factor is thought to be and how much of the load effect is borne by a hemisphere-specific effect.
library('tibble')
tt<- tibble(factor=c("spatial interference","temporal interference","speed limit","use of motion direction"),
            `resource intensiveness` = c("low?","high","unknown","C=1 only?"),
            `hemifield specificity` = c("medium","high?","unknown","unknown"),
            `contribution to standard MOT` = c("medium to high","unknown","low?","low"),            
            )
  
knitr::kable(
  tt, booktabs = TRUE,
  caption = 'Factors that affect MOT performance'
)
# https://bookdown.org/yihui/bookdown/tables.html
```

By "contribution to standard MOT", the fourth column of the table, I mean the degree to which the factor determines performance in a task with the relatively unconstrained trajectories that most researchers use.

Before going on to address each of these factors, I would also like to address a factor that is somewhat different in kind.

## Duration that one can sustain attention

Tracking may be, in part, a test of how long one can sustain attention. If a participant gets distracted or starts day-dreaming, that participant might completely stop tracking and, when their attention returns, not know the last locations of the targets. Lapses of attention are a problem in most other laboratory tasks as well, of course, but they are often thought to be particularly important for tracking because tracking requires a longer continuous engagement with the stimuli than for other common laboratory tasks. This is because the trials last for several seconds, typically, and the stimuli are continuously moving, so shifting one's attention away from the display can mean losing the targets.

This greater vulnerability to attentional lapses means that tracking may be more affected by motivation than many other tasks involving visual judgments. Introspectively, it does feel that way to me, relative to many perceptual tasks where I feel I only need to attend for the split-second when the stimuli are presented, and the percept I need to report jumps out at me. The possibility that variability in motivation drives a lot of variability in tracking performance is unfortunate, because we don't study tracking because we're interested in motivation.

It is also possible that the ability to continuously sustain attention may be distinct from general motivation and may cause a lot of variation in tracking. Like motivation, this could hinder efforts to get at the mechanisms specific to tracking that are not simply sustained attention. On the other hand, sustained attention and the limited resource that allows one to track a certain number of targets may be linked. That is, having to track more targets may reduce the amount of time that one can sustain attention on the task. Fortunately, the results of @wolfeMultipleObjectJuggling2007 suggest that this may not be the case.

In Experiment 3 of @wolfeMultipleObjectJuggling2007, participants were required to track four targets for a period of ten minutes. Every ten seconds or so, one object was highlighted and participants had to indicate whether it was one of the targets. In a no-feedback condition, participants were not told whether their individual responses were correct. In that situation, performance was substantially worse in the last few minutes of the trial than in the first few minutes (78% correct vs. 65% correct). However, in the feedback condition wherein participants were told immediately after each judgment whether they were correct, performance did not appear to decline over time. These results suggest that if participants are adequately motivated by feedback, they have considerable ability to track for several minutes with no appreciable loss. The comparison between the feedback and no-feedback conditions is not perfect as the feedback does provide a cue that can increase performance (when participants get the probe wrong, they can increase subsequent performance somewhat by switching to another target), but this confound does not seem to be able to explain the lack of almost any performance loss in the feedback condition.

The circumstances used by @wolfeMultipleObjectJuggling2007 were quite different from a prototypical MOT task, not least because of the extended durations of the trials. Most researchers use trial durations of less than ten seconds, which likely means that a decrease in performance with time due to waning attentino is less of an issue. It seems likely that motivated participants can attend for several seconds before their attention wanes substantially. @oksamaMultipleObjectTracking2004 did find a substantial decrease in performance for trials of 13 s compared to trials of 5 s. With four targets, for example, performance fell from 91% correct to 74% correct, and this decrease was somewhat greater for larger numbers of targets than for fewer targets. Byrne & Holcombe (unpublished data) did not find any significant decrease over a comparable interval, and the explanation for these discrepancies is uncertain, although it may again be related to participants' motivation.

The reason for the reduction in performance with greater time observed by @oksamaMultipleObjectTracking2004 may easily be due to another factor rather than an increase in lapses of attention. In the MOT tasks used by all of these researchers, with longer trials there is likely to be more instances of potential spatial interference, temporal interference, and running afoul of any tracking speed limit. Thus, if any of those factors matter, they could explain the decrease in performance with time. However, the @wolfeMultipleObjectJuggling2007 does seem to provide a kind of existence proof that lapses of attention need not be the limiting factor. Granting that that may be the case, an additional question is why, if other factors are in operation, there was *no* evidence of a performance decrease over time in @wolfeMultipleObjectJuggling2007? Well, @wolfeMultipleObjectJuggling2007 averaged performance over approximately the first third of the ten-minute interval and compared it to the last third. In the feedback condition, it is possible that all the worst possible events (such as close approaches, causing greater spatial interference) had already occurred by the end of the first third, so whatever level of performance participants were left with at that point already reflected their capacity to track through the most difficult events, which they were then able to continue to do until the end of the trial. Over a shorter time range such as that used by @oksamaMultipleObjectTracking2004, this may not have been the case.

I know of no studies of what display characteristics make tracking performance more vulnerable to attentional lapses. It stands to reason that if objects are moving very slowly, a lapse may be less detrimental because if after the lapse, one still remembers the last-monitored locations, the targets may still be near them. @fencsikRoleLocationMotion2007 showed that people can reacquire targets after a 300 millisecond disappearance, and @alvarezMultielementVisualTracking2005 showed that people can do this after being interrupted by a second task, although these interruptions are obviously different than an attentional lapse, during which it's not clear how often people forget the target locations.

Vigilance tasks such as the gradual-onset continual performance task are expressly designed to assess sustained attention and lapses over an extended interval, and an individual-differences study by @trevinoBridgingCognitiveNeuropsychological2021 found that MOT performance had little correlation with a five-minute gradual-onset continual performance task. This is somewhat reassuring as it, like some of the other evidence I have mentioned, suggests that lapses are not a major determinant of MOT performance.
