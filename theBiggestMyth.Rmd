# The biggest myth of object tracking {#biggestMyth}

@doranRoleVisualAttention2010 claim that "the main finding" from the object tracking literature "is that observers can accurately track approximately four objects and that once this limit is exceeded, accuracy declines precipitously." Similarly, writing about the "object tracking system", @piazzaNeurocognitiveStartupTools2010 wrote that "One of the defining properties of this system is that it is limited in capacity to three to four individuals at a time". This is a myth.

Two claims are often involved in the myth, but some papers only refer to one of these claims. The first claim is that there is a constant limit of around four objects. The second is that accuracy declines precipitously when the limit is reached. Typically authors do not distinguish between these two claims, instead they make a vague statement that might be taken to refer to either or to both. Here are some examples:
"People’s ability to attentively track a number of randomly moving objects among like distractors is limited to four or five items"  <!--cites Pylyshyn Storm 1989--> [@fougnieDistinctCapacityLimits2006],  <!-- which cites Scholl's objects paper which makes the claim of 4 FINSTs but backs it up only with STM etc. type studies -->, "researchers have consistently found that approximately 4 objects can be tracked"  @alvarezHowManyObjects2007, "people typically can track four or five items" @chesneyEvidenceSharedMechanism2011 <!--cites Pylyshyn 1989-->, "participants can track about four objects simultaneously" @vanderburgChangesNotDifferences2019 <!-- (see Cavanagh & Alvarez, 2005, for a review; Pylyshyn & Storm, 1988)-->. In each of these cases, I have checked the evidence provided, and the papers cited, as well as the papers those cited papers cite. Each paper  provides no evidence supporting the claim that performance decreases very rapidly once the number of targets is increased above some value. Those with relevant evidence find only a gradual decrease in performance as number of targets is increased, with no discontinuity; not even a conspicuous inflection point. For example, @oksamaMultipleObjectTracking2004, which is sometimes cited, designated between two and six objects as targets, among twelve identical objects in total. After the objects moved around randomly for five seconds, one object was flashed repeatedly and participants hit a key to indicate whether they thought it was one of the targets. The proportion of trials in which participants were wrong increased steadily with target size, from 3% incorrect with two targets, to 16% incorrect with six targets. Note that even with six targets, participants were performing substantially better than would be expected if they could only track one or two and had to guess on the others.

@pylyshynTrackingMultipleIndependent1988 seems to be the paper most frequently invoked when a limit of four objects is claimed. But @pylyshynTrackingMultipleIndependent1988 found a quite gradual decrease in performance (their Figure 1) as the number of targets was increased from one to five, and five was the most targets that they tested. In their discussion as well, they did not state that there is a hard or precipitous limit. In 1994 however, Pylyshyn and others did write that it is "possible to track about four randomly moving objects", even though earlier in that paper they contradict this somewhat by writing "at least four"  [@pylyshynMultipleParallelAccess1994]. I suspect that some cases of this sort of slide toward backing a hard limit reflects a desire for a simple story. It may also stem from an unconscious oversimplification of one's own data, as well as the theoretical commitment of Pylyshyn to the idea that tracking is limited by a set of discrete mental pointers.

Recall that the myth is associated with two claims, not just that there is a "limit" after which performance decreases rapidly, but also that this limit is consistently found to be about four. Because the published evidence indicates that the first claim is incorrect, let's put that aside and consider a softer version of the second claim. Specifically, is it the case that tracking performance falls, even if not rapidly, to some particular level, such as 75% correct, at about four targets? Instead of a percent correct criterion, one might alternatively use a criterion like the halfway point from ceiling to chance performance, or the "effective number of items tracked", which is calculated by applying a formula to percent correct together with the number of targets and distractors [@schollWhatVisualObject2001]. Charitably, this may be what @alvarezHowManyObjects2007 meant when they wrote: "researchers have consistently found that approximately 4 objects can be tracked (Intriligator & Cavanagh, 2001; Pylyshyn & Storm, 1988; Yantis, 1992)." To be fair, the cited early studies are arguably compatible with this statement. <!-- Alvarez & Franconeri (2007)  "researchers have consistently found that approximately 4 objects can be tracked (Intriligator & Cavanagh, 2001; Pylyshyn & Storm, 1988; Yantis, 1992). The similarity of these estimates, combined with the frequency with which 4-item limits arise in other attention tasks, suggests the possibility that there is a “magical number 4” in visual attention (Cowan, 2001; Pylyshyn, 1989)."  neither said any such thing, it seems from my reading of those papers, e.g.  Pylyshyn & Storm 1988 only went up to 5 out of 10 and there was gradual decrease in performance all the way through. --> <!-- Papers I have checked for the 4-object claim: Cowan, 2001 claimed it for MOT, citing Pylyshyn et al. 1994, which does say "experiments showing that observers can simultaneously track some three to five identical target items" but then when he describes the studies he doesn't say they show that, even though in the discussion he says "One is that it is possible to track about four randomly moving objects" -->
<!-- In some cases the problem stems from Scholl Pylyshyn Feldman paper that devised the effective tracking capacity measure assuming 100% accuracy for one object and delivering a single number, often 4, for effective number tracked--> However, work published over the last fifteen years has revealed this to be an artifact of researchers using similar display and task characteristics. One of the most salient of these characteristics is object speed.

@alvarezHowManyObjects2007 tested participants with a display of sixteen discs wandering about the screen. They found that the fewer the number of discs they designated as targets, the faster the participants could track each target. In other words, with few targets, participants could track them even when they moved at high speeds. This trend continued as the discs' speed was increased, such that at very high speeds, participants could track only one object with reasonable accuracy. This indicated that the truth of the idea that participants can track four objects is entirely dependent on the speed of those objects. Supporting evidence for this was found by my lab [@holcombeExhaustingAttentionalTracking2012].

Soon, other display parameters that affect the number of objects that can be tracked were discovered, in particular object spacing [@franconeriEvidenceSpeedLimit2008; @holcombeObjectTrackingAbsence2014]. As we will be discussed extensively in section \@ref(twoBrains), one aspect of spacing is that tracking performance can depend greatly on whether the targets are distributed between the left and right hemifields or instead are confined to one hemifield.

In summary, it is incorrect to say that people can track about four moving objects, or even that once some number of targets is reached, performance declines very rapidly with additional targets. The number that can be tracked is quite specific to the display arrangement, object spacing, and object speeds. If a researcher is tempted to write that "people can track about four objects", the immediate context ought to stipulate that this refers to certain tasks, display characteristics, and performance measures, something that I have almost never seen in the literature.

Almost exactly this issue also arose in a different research area.  A diverse set of two dozen working memory researchers attended a workshop in 2013 with the express purpose of "developing benchmarks for models of working memory". They grappled with, among other issues, how to characterize the limit on how many items people can remember. In a paper that stemmed from the discussions at the workshop, the researchers pointed out that "observed item limits vary substantially between materials and testing procedures" [@oberauerBenchmarksModelsShortterm2018]. However, they suggested that much of this variability could be explained by humans' ability to store groups of items as "chunks" and thus the group endorsed a statement that there is a limit of "three to four chunks" [@cowanMagicalNumberShortterm2001a]. These researchers believed they could explain the observed variability in experiments' results by a common underlying limit of three to four chunks that manifests as different observed item limits depending on circumstances, in particular the opportunity for chunking.

In the case of MOT, it remains possible that researchers will be able to identify a set of circumstances that consistently yield a mean tracking limit of three or four targets (if "limit" is defined as performance falling to a particular level on some performance metric). Perhaps these circumstances will simply be certain spacings, speeds, object trajectories, and number of objects in a display. Ideally, however, some underlying construct (the counterpart of chunks for memory) would be identified to explain how performance changes when other circumstances are used. That would constitute real progress in theory development. However, I don't see anything like that in the literature currently.

<!-- At this point,  to defend the claim that people can track "about four objects" is to suggest that the studies that have found four targets to be the number that can be tracked . Is there something special about  these speeds. Nobodh justified them with ecological analysis-->

## Different tasks, same limit?

Even with the idea that there is a particular number of objects one can track discarded, there remains a related claim, one common in the literature, that conceivably could still be viable. This claim is frequently tangled up in the myth reviewed above, for example it may be stated as the idea that there is a "magical number four". After discarding the attachment to a particular number, the essential notion is that very different tasks have the same number-of-objects limit. For example, @bettencourtSharedFilteringProcesses2011 stated that "both processes [visual short-term memory and MOT] showing an equivalent four-object limit", and @piazzaNeurocognitiveStartupTools2010 similarly claimed that visuo-spatial short-term memory, ultra-rapid counting (subitizing), and multiple object tracking all share a limit of "three or four items".

For more than a hundred years, it has been claimed that there is a discrete limit on the number of objects that can be, at a glance, counted [@jevonsPowerNumericalDiscrimination1871]. This "subitizing" or numerosity perception ability has been extensively investigated, and some consider the idea of a sudden decrease in accuracy when the number of objects shown goes from less than four to more than four as well-supported [@revkinDoesSubitizingReflect2008]. Four objects and fewer is frequently referred to as the "subitizing range", with performance approximately as good for rapidly counting four objects as it is for two or one. Note that this is very different than in tracking, for which speed thresholds decline rapidly from one to two targets, as well as to three and four. For visual working memory, which as we mentioned several experts have characterized as being limited to three or four chunks, whether there is a discontinuity after four objects or at any point remains highly debated [e.g. @robinsonThereCapacityAssessing2020].

At the level of a common limit in terms of number, then, it remains unclear whether tasks such as object tracking, visual working memory, and subitizing can be said to have a common limit. Ideally this could be confirmed by measuring the limits for all three tasks using the same stimuli, but it is unclear how to equate the information available across tasks. Especially difficult is comparing performance with the briefly-presented static stimuli used in subitizing and working memory tasks to the extended exposures of moving stimuli needed to assess object tracking. A modeling approach could make progress on this issue, although it would require making assumptions that might need novel empirical support. Another approach is to determine which tasks' limits co-vary between individuals. This is reviewed in section \@ref(abilities).

<!-- https://psyc2016.whatanimalssee.com/bottlenecks.html#a-bottleneck-for-object-judgments -->

<!--Working off the dominant framing, that each person does have a specific number of targets they can track which determines percent correct for each level of number of targets, some MOT researchers report what @schollWhatVisualObject2001 called the "effective number of items tracked". The associated formula, refined by @hullemanMathematicsMultipleObject2005a allows researchers to calculate the effective number of items tracked based on accuracy in an individual condition, given the number of targets and distractors in that condition. This does provide a useful summary of the data, but researchers should take more care to avoid taking it literally.--> <!--Still, it does seem that the number four pops up more than would be expected if these abilities were unrelated. -->

To summarize this chapter, there are three common misconceptions about what has been shown about object tracking. The one that we have just discussed is that different tasks show the same limit. This may well be true, but I know of no research that have used the same display and task settings to adequately back this up. In the previous section of this chapter, we saw that it is not justified to say that as the number of targets is increased to about four, performance falls to a certain criterion level. One must specify particular display and task characteristics in order to make that statement true. A final misconception is that performance falls very rapidly when one increases the number of targets past a particular number (the "limit").

Given that tracking performance does depend greatly on circumstances and falls gradually rather than displaying a discontinuity at a particular target number, what are the implications for how tracking works? Briefly, these characteristics of tracking are consistent with resource theories, which are discussed in section \@ref(whichAspects).
