# Two brains or one? {#twoBrains}

A human brain can be thought of as made up of two brains, a left and a right, just as we have two legs and two hands. 
<!--While an industry of education consultants and "brain training" companies exploits  common left brain, right brain misconceptions,  
We all have a "left brain" and a "right brain", which have different learning styles, and they should be trained both separately and in a way that gets them communicating with each other. Or so many would have you believe. The anatomical division of the hemispheres has been hyped into a supposed plethora of implications for behavior and learning. A veritable industry of education consultants and "brain training" providers have peddled these ideas, selling programs they refer to as, for example, "left brain versus right brain" training [@kroezeBrainGymPseudoscientific2016].--> Much of sensory and perceptual processing is very specific to the two halves of the cortex, but more cognitive functions such as declarative memory benefit from a very tight integration. Indeed, this integration is extensive enough that the comparison of our two hemispheres to our two hands is misleading.

Our conscious experience, too, is highly unified. We experience no discontinuity when the movement of our eyes, or of an object, cause an object to shift from one hemifield, where it is processed predominantly by one hemisphere, to the other hemifield. Communication between the two hemispheres happens rapidly and continuously, and there is no good evidence that exercises designed to insure both hemispheres process stimuli have any benefit for learning. 

In "split-brain" patients, many of the connections between the hemispheres have been lost. Despite the loss of these connections, such patients can still perform visual search in both hemifields, indicating that both hemispheres have the capacity to do that task. Indeed, when split-brain patients are asked to search for a target among many distractor objects, spreading the load by distributing the distractors across the two hemifields can yield a large benefit, suggesting that the two hemispheres in these patients carry out their searches independently [@luckIndependentAttentionalScanning1994a]. For intact individuals, no such advantage is seen, suggesting that the processes that evaluate each stimulus for whether it is the target are integrated across the hemispheres into a single attentional focus [@luckIndependentHemisphericAttentional1989].

While performance in search and other behaviors typically shows a tight inter-hemispheric integration, the two hemispheres do specialize for certain functions. The left hemisphere specializes in language functions such as reading, while the right hemisphere is better at recognizing faces. A behavioral consequence of this is that response times for a face recognition task are slightly faster when the stimulus is presented wholly in the left hemifield (to the right hemisphere) than when it is presented wholly in the right hemifield, whereas the opposite is found for word reading [@rizzolattiOppositeSuperioritiesRight1971]. However, with extended time to process a stimulus, such behavioral asymmetries can disappear as the information from one hemisphere is communicated to the other.

In the performance of most perceptual and attentional tasks, then, in humans with an intact brain there is little sign that that brain is divided into two halves. Multiple object tracking, however, constitutes a major exception to this. This tells us that the limited resource that determines how many objects one can keep track of resides largely with a process that operates independently in the two hemispheres.

## The extraordinary hemifield independence of object tracking

```{r, include=F}

#Correct for guessing. Based on 1, the chance rate for getting the task of identifying the targets correct.
# And 2, the observed percent correct.
# Use a high-threshold equation that assumes you either know it or you don't.

#What is the true rate, t, at which people know the answer not from guessing, where guessing rate = c
# accuracy = t + (1-t)c
# t = accuracy - (1-t)c
# t = accuracy - c + tc
# t - tc = accuracy - c
# (1-c)t = accuracy - c
# t = (accuracy - c)/(1-c)

#Try deriving it again to make sure I'm right:
# a = t*1 + (1-t)*c
# a = t + c -tc
# t - tc = a - c
# t(1-c) = a - c
# t = (a - c)/(1 - c)

correctForChance <- function(x,chance) {
  #(x-chance)/chance
  (x-chance)/(1-chance)
}
#correctForChance(.89,chance)


# Alvarez and Cavanagh arrayed 2 pinwheels either unilaterally or bilaterally, and in each case designated either one or both as targets
# Unilateral 1 target, Unilateral 2 target, Bilateral 1 target, Bilateral 2 target
# 
#alvarezCavanagh2005E1 <- c(.89,.63,.93,.90)
#chance<- 0.5

library(dplyr)
#1:10 %>% purrr::map(rnorm, n=10)

#accCorrected <- alvarezCavanagh2005E1 %>% purrr::map(correctForChance,chance) %>% 
#  purrr::map_dbl(mean) #have to call map_dbl to simplify output from nested list to simple vector
#accCorrected

calculateIndependenceAlvarezCavanagh <- function(accuracies,chance) {
  corrected <- accuracies %>% purrr::map(correctForChance,chance) %>%
        purrr::map_dbl(mean) #have to call map_dbl to simplify output from nested list to simple vector

  costOfSecondTargetUnilateral <- corrected[1] - corrected[2]
  # 1 - cost of second target bilateral / costOfSecondTargetUnilateral
  hemifieldIndependence <- 1 - (corrected[3]-corrected[4]) / costOfSecondTargetUnilateral
  return (hemifieldIndependence)
}

# The HudsonHoweLittle2012 design compares accuracy with 3 targets to with 6 targets
# Instead of having two different baseline (3-targets in their case) conditions like Alvarez & Cavanagh, they have just one, where
# the three targets are confined to a single quadrant and for the 6-target conditions, the 3 additional targets are added to either the other hemifield (bilateral)
# or the same hemifield but other quadrant (unilateral)

calculateIndependenceOnlyOneBaselineConfiguration <- function(accuracies,chance) {
  corrected <- accuracies %>% purrr::map(correctForChance,chance) %>%
        purrr::map_dbl(mean) #have to call map_dbl to simplify output from nested list to simple vector

  costOfAdditionalTargetsUnilateral <- corrected[1] - corrected[2]
  costOfAdditionalTargetsBilateral <- corrected[1] - corrected[3]
  # 1 - cost of second target bilateral / costOfSecondTargetUnilateral
  hemifieldIndependence <- 1 - costOfAdditionalTargetsBilateral / costOfAdditionalTargetsUnilateral
  return (hemifieldIndependence)
}

```

In 2005, George Alvarez & Patrick Cavanagh reported a stunning finding. In an MOT task, they used objects that resembled spinning pinwheels. An individual bar of each object could be designated as a target. Performance in a two-target (one bar of each of two different pinwheels) condition was contrasted with that  for a one-target condition [@alvarezIndependentResourcesAttentional2005].  When the second target was positioned in the same hemifield as the first target, accuracy in the two-target condition was much worse (89% vs. 63%). Remarkably, however, when the second target belonged to a pinwheel located in the opposite hemifield, there was very little performance decrement - accuracy was 93% in the one-target condition, and 90% correct in the two-target condition. This suggests that the processes that limit successful tracking in this task are largely specific to each hemifield. 

It was already known that sensory processing and quite a lot of perceptual processing occurs independently in each hemisphere. What is surprising is that a highly limited-capacity processing ability would be hemisphere-independent. Such capacities were traditionally thought to be among the processes that are tightly integrated across the two hemispheres, forming a single resource "pool", not two independent limits. We will get back to this point, first we'll examine more extensively the evidence for hemispheric independence of object tracking.

## Quantitative estimates of independence

```{r, include=F}
#E1: Unilateral 89% 1 target -> 63% 2 target.  Bilateral: 93% 1 target -> 90% 2 target. (26-3)/26= 88%. E3: Unilateral 2targets:93%, 4targets:67%. Bilateral 2targets:90%, 4targets:87%. (26-3)/26=88%
# Unilateral 1 target, Unilateral 2 target, Bilateral 1 target, Bilateral 2 target
alvarezCavanagh2005E1 <- c(.89,.63,.93,.90)
alvarezCavanagh2005E3 <- c(.93,.67,.90,.88)
chance<- 0.5

alvarezCavanaghE1Independence <- calculateIndependenceAlvarezCavanagh(alvarezCavanagh2005E1,0.5)
alvarezCavanaghE1Independence

alvarezCavanaghE3Independence <- calculateIndependenceAlvarezCavanagh(alvarezCavanagh2005E3,0.5)
```

```{r HudsonHoweLittle, include=F}
# Baseline unilateral 3 targets, Unilateral 6 targets, Bilateral 6 targets
HudHoweLittleE1 <- c(.77,.54,.61)
#Two yes/no questions were asked per trial "Was this color target at this position?" and both had to be answered correctly
chance<- 0.25

HudHoweLittleE1b <- c(.72,.51,.57) #Replication of E1 with eyetracker
#In E1 and E1b the colors were continuously visible.
#E2 the colors were only briefly shown at the beginning of the trial
HudHoweLittleE2 <- c(.75,.52,.58)

#Used same num targets and distractors as Alvarez & Cavanagh: 2 targets and 2 distractors
HudHoweLittleE3 <- c(.77,.47,.58)

#In E4 they used an MOT task
HudHoweLittleMOT <- c(.72,.36,.595)
HudHoweLittleMOTindependence<- calculateIndependenceOnlyOneBaselineConfiguration(HudHoweLittleMOT, chance)

HudHoweLittleE1Independence <- calculateIndependenceOnlyOneBaselineConfiguration(HudHoweLittleE1, chance)
HudHoweLittleE1bIndependence <- calculateIndependenceOnlyOneBaselineConfiguration(HudHoweLittleE1b, chance)
HudHoweLittleE2Independence <- calculateIndependenceOnlyOneBaselineConfiguration(HudHoweLittleE2, chance)
HudHoweLittleE3Independence <- calculateIndependenceOnlyOneBaselineConfiguration(HudHoweLittleE3, chance)
HudHoweLittleMITindependence<- c(HudHoweLittleE1Independence,HudHoweLittleE1bIndependence,HudHoweLittleE2Independence,HudHoweLittleE3Independence)
```

The hemispheric independence of a task can be quantified. Imagine that adding a second stimulus to a hemifield reduces performance by 20 percentage points, but adding that stimulus to the other hemifield reduces performance by only 5 percentage points. One can quantify the hemispheric independence, then, as (20-5) / 20 = 75% hemifield independence. Ideally, however, one would not use raw accuracy but instead would correct for the accuracy one can achieve by guessing. When [applying such a calculation](https://github.com/alexholcombe/tracking-review/blob/main/twoBrainsOrOne.Rmd) to the @alvarezIndependentResourcesAttentional2005 results, the estimated level of independence is very high: `r round(100*alvarezCavanaghE1Independence)`% independence in one of their experiments, and `r round(100*alvarezCavanaghE3Independence)`% in the other. 

@alvarezIndependentResourcesAttentional2005 themselves, like most others who have investigated this question, did not do these calculations. @alvarezIndependentResourcesAttentional2005 calculated expected performance if the hemifields are in fact completely independent, and reported that performance was not statistically significantly worse than that figure. They then suggested that there was complete independence, but this is based on the common fallacy of concluding a null hypothesis is true when the evidence does not reject it at a p<.05 level [@aczelQuantifyingSupportNull2018]. That is, for the null hypothesis they started with their conclusion of complete independence, and then affirmed this conclusion on the basis of not finding much evidence against it. Nevertheless, their data do suggest hemispheric independence of approximately 90%. In a study with similar methods, @hudsonHemifieldEffectsMultiple2012 found `r round(100*HudHoweLittleMOTindependence)`% independence (they did not calculate a number, so this is [my calculation](https://github.com/alexholcombe/tracking-review/blob/main/twoBrainsOrOne.Rmd)).

Some of the follow-up studies in this area have not included enough conditions to quantify the degree of independence, or confounded distribution of the targets to two hemifields with greater distance among them, such that any benefit might have been due to less spatial crowding interference, a phenomenon discussed in section \@ref(spatialInterference).

@holcombeExhaustingAttentionalTracking2012 and @chenResourceDemandsObject2013 found similar results with a slightly different approach based on speed thresholds, which are discussed in section \@ref(speedAndTime). The findings were compatible with approximately 100% hemifield independence or a bit less. @shimNumberAttentionalFoci2010<!--Figure 1--> and @stormerWithinhemifieldCompetitionEarly2014 also found evidence for a substantial bilateral advantage compared to adding a target in the same hemifield. 

These findings of hemispheric independence has not replicated in all circumstances [e.g., @shimSpatialSeparationTargets2008] <!--performance in all the conditions involved in their comparison were greater than 85% correct, including many low speeds where performance was near ceiling -->  <!--For most of these tasks, but not @shimNumberAttentionalFoci2010, more targets was confounded with having to make more responses and remember said responses at the end of the trial, so some of the residual cost could be due to that being unitary rather than hemifield-specific.-->, but the successful replications strongly suggest that at least in some circumstances, tracking does occur mostly independently in the two hemispheres. I say "mostly independently" rather than suggesting complete independence because each individual study has too much statistical uncertainty to rule out a figure such as 75% independence, even when its mean suggests a higher degree of independence.

@shimSpatialSeparationTargets2008 suggested that the reason they did not find evidence for hemifield independence is that they used only two targets, whereas according to them the original @alvarezIndependentResourcesAttentional2005 report of hemifield independence used four targets. This is unlikely to be the reason for the discrepancy, however, because in their E1 and E2 @alvarezIndependentResourcesAttentional2005 did find evidence for hemifield independence using just two targets, as did @holcombeExhaustingAttentionalTracking2012 and @stormerWithinhemifieldCompetitionEarly2014. The @shimSpatialSeparationTargets2008 data may have been afflicted by a ceiling effect, as accuracy was over 85% correct in all conditions in their experiment. 

<!-- Shim, Alvarez, & Jiang (2008) found no advantage for targets in different hemifields. Why? Not sure, but the objects weren’t spaced far enough part to not crowd each other across the hemifield boundaries. In contrast, Shim et al. and Bello et al. suggest it was because hemifield limit doesn’t apply when just two targets. Holcombe & Chen found it did, but Bello suggests the reason is that we used circular trajectories that are somehow different, they say you can extrapolate more with them, whereas it may be that you can extrapolate less.   The target-target distance effect in Shim et al. is huge! How do I explain that? One possible explanation is Carlson’s quadrantic deficit.-->

A limitation of deriving hemispheric independence from accuracy is that they depend on the assumption that if a person can only track one target, if one then adds a second target, the person will succeed just as often in tracking one of them. But my introspective experience indicates that in some circumstances, if one tries to track both targets, one will fail at both, and thus one is better off only trying to track one. The reason for this may be that a certain amount of resource is needed to track a target, and so if neither target is allocated that much resource, tracking will fail for both. Evidence for this was provided by @chenResourceDemandsObject2013. In the terminology introduced by @normanDatalimitedResourcelimitedProcesses1975, the resource function that relates the proportion of attentional resource to accuracy falls below a straight line. This means that quantitative estimates of hemispheric independence will be overestimates, particularly in circumstances where the participants do not realize they may be better off focusing their efforts on tracking fewer targets than the number they have been told to track.

@carlsonQuadranticDeficitReveals2007 found evidence not only for hemifield independence but also quadrant-level independence, which they attributed to the partial separation of the retinotopic quadrant representations in areas V2 and V3. @shimSpatialSeparationTargets2008 did not replicate this finding, however they had less evidence, so more work on this topic should be done.

## Some tracking resources are NOT hemifield-specific

A previous section introduced the idea of C=1 cognitive processes that can support tracking of a single target but perhaps not multiple targets. Such processing likely is not hemisphere-specific. <!--We easily attend to objects in any part of the visual field, left or right.-->  Feature attention, for example attention to color, is a case in point. When a participant is told to look for a red target, they are able to use feature attention to enhance all red objects, no matter where they are in the visual field [@whiteFeaturebasedAttentionInvoluntarily2011]. The decision to look for red originates with cognitive processes and remains hemifield-unified rather than hemifield-specific even at the level of visual cortex [@saenzGlobalEffectsFeaturebased2002]. Indeed, people seem to be unable to confine the enhancement of red objects to one hemifield [@loHowWeSelect2014].

@chenResourceDemandsObject2013 found evidence for both hemifield-specific processes and processes not specific to a hemifield in the same MOT task. Two targets that sometimes had different speeds were used. When a slow-moving target was paired with a speedier target, accuracy was lower for the slow-moving target than if it was paired with a target that was slower. This suggests that participants allocate more tracking resources to the faster of two targets, presumably because slower targets do not require much resource to track well. This trade-off was most pronounced when the two targets were in the same hemifield, but seemed to occur to some degree even when the two targets were in different hemifields, implicating a cross-hemifield resource that plays a small role. This cross-hemifield resource may be a C=1 process. Most cognitive tasks are unlikely to be independently mediated by the two hemispheres, with one set of processes in each hemisphere.

Finally, as discussed in the next section, perturbing one parietal lobe can affect performance in both hemifields, which suggests that each hemisphere can in some circumstances mediate tracking in either hemifield.

## The underlying mechanisms

The evidence reviewed above for hemifield independence suggests that hemisphere-specific processes determine how many targets one can track. This raises the question of what sort of processes those are, and how they interact with the cognitive processes that are more integrated across the hemispheres.

Steve Franconeri and colleagues have championed the idea that the hemisphere independence stems from spatial interference processes, by suggesting that these processes occur largely within a hemisphere [@franconeriNatureStatusVisual2013]. The idea is that when when an object is tracked, the neurons representing that target in retinotopic cortical areas activate inhibitory connections to nearby neurons in the cortical map, suppressing the responses to neighboring objects [@carlsonQuadranticDeficitReveals2007. To explain the findings of hemifield specificity, what's been added to this account is the idea that the inhibitory neural connections do not extend from one hemisphere's retinotopic map to another [@franconeriFlexibleCognitiveResources2013]. The evidence that as manifest in classic crowding tasks, spatial interference does show a discontinuity across the left- and right-visual field boundary lends some plausibility to this idea [@liuReductionCrowdingEffect2009]. However, @holcombeObjectTrackingAbsence2014 found evidence against spatial interference extending any further than the classic crowding range , which is only half the eccentricity of an object - for example, an object placed six degrees of visual angle from where the point the eyes are looking at would be interfered with only by other objects closer to it than three degrees of visual angle [@boumaInteractionEffectsParafoveal1970a]. This is a far cry from the nearly 90 degrees of an entire hemifield, or even of a quadrant. The more viable theory, then, is those that align more with the concept of a neural resource that spans the hemifield.

A number of studies have found that the activity of some parietal and frontal areas of cortex increase steadily with the number of targets in MOT [@culhamAttentionResponseFunctions2001; @howeUsingFMRIDistinguish2009; @jovicichBrainAreasSpecific2001; @alnaesPupilSizeSignals2014], consistent with the importance of a pool of attentional resources. These studies did not focus, however, on the extent to which these activations are specific to the hemifield-specific nature of target load. The only imaging study I am aware of that investigated the issue is @shimNumberAttentionalFoci2010 who found an activation difference when the objects designated as targets were in opposite hemifields compared to when they were in the same hemifield. This was found for the superior parietal lobule and transverse parieto-occipital area, but not the anterior intraparietal sulcus. 
<!--"In behavioral performance, participants tracked with higher accuracy when the 2 target pinwheels fell in opposite hemifields than in the same hemifield. A corresponding difference in brain activity was observed in the SPL (P < 0.05) and TrPO (P < 0.005), where activity was higher for track-2 unilateral than track-2 bilateral. The visual field arrangement did not affect activity in aIPS, however (P > 0.10), revealing a possible further dissociation in the PPC between the anterior and posterior" -->

The neural correlates of the hemifield-specific resource was investigated by @stormerWithinhemifieldCompetitionEarly2014 using EEG. They found that the SSVEP activation for targets was higher than that for distractors when the two targets, especially when the two targets were positioned in different (left and right) hemifields. In contrast, an ERP component known as the P3 thought to reflect more cognitive identification and decision processes was similar in the two conditions. This is consistent with the theory that tracking depends on both hemisphere-specific attentive processing followed by some involvement of higher-order processes that are not hemisphere-specific.

@battelliRoleParietalLobe2009 found they could disrupt MOT performance in a hemifield by stimulating the contralateral intraparietal sulcus (IPS) using repetitive transcranial magnetic stimulation. Importantly, however, this only occurred when the moving targets were present in both hemifields. When the targets were all in the left or all in the right hemifield, TMS to the left or to the right IPS had no effect on tracking accuracy, and this was replicated in a second experiment. These findings bring to mind the competition between the two hemifields that is evident in the "extinction" symptom observed in parietal neglect patients. In extinction, responding to stimuli in the hemifield contralateral to parietal injury only shows significant impairment if there are also stimuli presented to the ipsilateral hemifield. This inspired Battelli to explain their findings with two propositions. The first is that the IPS in each hemisphere can mediate the tracking of targets in *either* visual hemifield. The second is that under normal conditions, inhibitory processes reduce the amount of ipsilateral processing by each IPS, causing tracking capacity to effectively be hemifield-specific in many circumstances.

The complex relationship of the hemispheres is further illustrated by evidence from patients. @battelliUnilateralRightParietal2001 found that in patients with damage to their right parietal lobe, MOT performance only in the left visual field was impaired relative to control participants. Evidently the right parietal lobe does not normally mediate tracking in the right visual field, so losing it did not hurt right visual field tracking performance. But for another task, these right parietal patients had substantial impairments in *both* hemifields. Impairment on that task, an apparent motion task, is believed to be a result of a deficit for registering the relative timing of visual events. The involvement of the right parietal lobe, but not the left parietal lobe, in judging the temporal order of stimuli in both hemifields was further supported in an additional study with both patients and with TMS [@agostaPivotalRoleRight2017].

In summary, while there is evidence that each parietal lobe is involved in field-wide processing for some tasks, it also likely mediates the hemifield independence evident in some circumstances. Using ERP, @drewSoftHandoffAttention2014 fund evidence that when a target crosses the vertical midline, say from the left to the right hemifield, the left hemisphere becomes involved shortly before the target reaches the right hemifield, and the right hemisphere remains involved for a short time after the crossing. Because this was modulated by predictability of the motion, it did not appear to be wholly mediated by the well-known overlap of the two hemispheres' receptive fields at the midline. This phenomenon may reflect the normally-inhibited ipsilateral representation of the visual field by parietal cortices highlighted by @battelliRoleParietalLobe2009, although the location the ERP signals originated from was not clear so this remains uncertain.

Both @strongHemifieldspecificControlSpatial2020 and @minamiHemifieldCrossingsMultiple2019 found evidence for a tracking performance cost when a target in MOT crossed the vertical midline. Evidently the handoff of control from one hemisphere to another is not completely efficient. @strongHemifieldspecificControlSpatial2020 also found no cost when targets moved between quadrants within a hemifield, an important finding given that other work raised the prospect of quadrant-specific resources [@carlsonQuadranticDeficitReveals2007]. 

In summary, areas of the parietal cortex may subserve both the hemifield-specific tracking resource that dominates most MOT tasks and the more limited resource that is not specific to a hemifield. More work must be done however to determine the role of frontal lobe regions. Such regions could potentially play a role in the hemifield-specific resource, the hemifield-independent resource, or both.

## What else are hemifield-specific resources used for?

Multiple object tracking is closely associated with spatial selection, which is an important process for many other visual tasks. Given the hemifield specificity of spatial attentional selection suggested by MOT, then, one might expect to find strong hemifield-specificity of other visual cognition tasks in addition to MOT. 

Many researchers have examined tasks involving two simultaneously-presented stimuli and compared performance when the two stimuli are presented in the same hemifield to performance when they are presented in different hemifields. For example, @dimondUseTwoCerebral1971 found that the reporting of two briefly-presented digits is more accurate when the digits are presented in different hemifields than in the same hemifield. However, this study and many others did not include a single-stimulus condition, so when performance is higher in the split condition, we don't know how close that is to the one-target level of performance and thus the degree of hemifield-specificity cannot be quantified. Other studies use response time as a measure, which is also difficult to interpret [@awhEvidenceSplitAttentional2000; @serenoDiscriminationHemifieldsNew1991; @dimondUseTwoCerebral1971]. 

<!-- A' is no good https://sites.google.com/a/mtu.edu/whynotaprime/ -->
@delvenneCapacityVisualShortterm2005 used both dual-target and single-target conditions in a visual working memory task. For spatial working memory, he estimated 40% hemifield independence, although unfortunately he used the discredited A' measure of performance [@zhangNoteROCAnalysis2005] and did not space the stimuli widely enough to reduce the possibility of spatial interference. Nevertheless, the advantage appears to be large and did not occur for color working memory [@delvenneVisualShorttermMemory2012]. More generally, only tasks with spatial demands seem to show much hemifield specificity [@holtBilateralAdvantageMaintaining2015; @umemotoBilateralAdvantageStorage2010]

@alvarezAnatomicalConstraintsAttention2012a studied visual search, with the items to search through arrayed bilaterally or unilaterally. In standard visual search, they found only a small advantage of the vertical meridian split. However, in a subset search task where participants knew the target would be located in one of several locations designated by a pre-trial cue, they found a large bilateral advantage. However, when the relevant locations were prominently indicated by a color difference, this advantage largely disappeared. These results, and those in the rest of the literature, suggest that hemifield advantages are strongest when spatial selection is critical.

@strongHemifieldspecificControlSpatial2020 investigated working memory for stimuli that moved either within a hemifield or between hemifields. For between-hemifield movement, they found a substantial decrease in accuracy for the spatial task of remembering which positions of a 2x2 grid contained dots at the beginning of the trial, before the (empty) grid moved - 79% correct for between-hemifield movement, and 85% correct for within-hemifield movement. No such cost was found for color or identity memory tasks. This between-hemifield cost for spatial memory was similar to the cost they found for MOT itself.

This association between spatial tasks and hemifield specificity may reflect a large-scale difference in how the brain processes spatial versus identity information. Famously, the dorsal stream that leads to the parietal cortices are more concerned with spatial information than is the ventral stream that is more involved in object recognition [@goodaleSeparateVisualPathways1992]. Neural responses in the dorsal pathway to parietal cortex are largely contralateral [@serenoMappingContralateralSpace2001], although as we have seen . This is also true of other brain areas thought to contribute to a "saliency map" [@fecteauSalienceRelevanceFiring2006], such as the frontal eye fields [@haglerjrSpatialMapsFrontal2006], the superior colliculus [@schneiderVisualResponsesHuman2005], and the pulvinar [@cottonContralateralVisualHemifield2007a]. In contrast, identity-related processing seems to involve more bilateral neural responses and connectivity between hemispheres [@cohenUsingNeuronalPopulations2011; @hemondPreferenceContralateralStimuli2007].

Multiple identity tracking, which is discussed further in section \@ref(identity), combines the location-updating aspect of multiple object tracking with an additional requirement: maintaining knowledge of what features belong to each of the objects. Across four experiments, @hudsonHemifieldEffectsMultiple2012 consistently found partial hemifield independence, ranging from 26 to 37% ([my calculation](https://github.com/alexholcombe/tracking-review/blob/main/twoBrainsOrOne.Rmd)) with a paradigm that yielded `r round(100*HudHoweLittleMOTindependence)`% independence for MOT. This is consistent with the suggestion of the findings listed above that a spatial selection and/or location updating processes are much more hemisphere-specific than processes that require maintenance of non-spatial features.

<!--
@delvenneBilateralFieldAdvantage2011 showed a bilateral advantage for subitizing.  Subitizng and enumeration. Bilateral advantage shown for enumeration. None for subitizing, although that's hard to interpret because ceiling effect 

@delvenneVisualShorttermMemory2012 review article: "Those data reveal that a BFA can be found in spatial short-term memory, namely when the task requires holding spatial information. However, no BFA has been found in object short-term memory (i.e., when the task is to hold detailed visual properties of the objects), unless attentional selective processes are dominantly engaged in the task, s"

@umemotoBilateralAdvantageStorage2010 found bilateral advantage even with sequential so must be storage, althoguh used orientation, so could be spatial still
used mixture model, but  might have assessed capacity quantitatively Mixture model suggests only a modest increase, from perhaps capacity of 2 . 0.5*4, Figure 11 . to capacity of 2.3 .575*4, Figure11

Kingstone, 2004; Corballis & Gratton, 2003; Hughes & Zimba, 1987

RT study, always used 2 targets.  Davis, R., & Schmit, V. (1971). Timing the transfer of information between hemispheres in man. Acta Psychologica, 35(5), 335–346. https://doi.org/10.1016/0001-6918(71)90008-4
-->

## Hemispheric differences

Neural differences between the left and right hemispheres can be attenuated at the behavioral level by the cross-hemisphere integration that typically occurs prior to a behavioral response. The functional independence of the two hemispheres for multiple object tracking, then, provides a greater potential to show hemifield differences in performance. As it turns out, differences are observed, but these differences do not seem to be large.

In four experiments conducted by @holcombeObjectTrackingAbsence2014, we reported either a trend for or statistically significant advantage for targets in the right hemifield (Figure A2). <!--Interestingly, there was some non-significant evidence that this was greater in their one-target condition than in their two-target condition.    Figure 4 of @battelliUnilateralRightParietal2001 like Holcombe et al. (2014) finds (non-significant) better tracking performance in RVF than the left only when tracking one rather than more than one--> A right hemifield advantage might potentially be explained by the theory that stimuli presented to the right hemifield are processed by both hemispheres to a greater degree than are stimuli presented to the left hemifield, which is also thought to explain why left neglect is more common than right neglect. Specifically, it is thought that the right hemisphere mediates attention to *both* hemifields [@mesulamSpatialAttentionNeglect1999], such that the right hemifield is doubly represented. However, while @strongHemifieldspecificControlSpatial2020 confirmed a right hemifield advantage in their MOT experiments, they instead find a left visual field advantage for spatial working memory experiments, even though spatial working memory is also though to be mediated by parietal cortex. Most strikingly, @matthewsLeftVisualField2015 found a large advantage for temporal order judgments and simultaneity judgments for stimuli presented to the left hemifield. Neuropsychological evidence suggests that the left hemifield advantage for timing tasks reflects a specialization for timing in the right parietal cortex [@battelliBilateralDeficitsTransient2003], even though human specialization for language, which is thought to be in part an enhancement of timing and sequencing abilities, has occurred more in the left hemisphere.

The situation becomes even more complex once one considers that there subtle interactions between the two hemispheres seem to affect attention in each hemifield, as highlighted in the "the underlying mechanisms" section above. One illustration of this is a recent finding by @edwardsBehavioralGainFollowing2021. They had participants perform MOT in either hemifield for a 30 min session, and afterwards found that performance in the *untrained* hemifield improved significantly. The reason for this is not clear, but could reflect "fatigue" by the hemisphere contralateral to the trained hemifield causing it to reduce its inhibition of the other hemisphere. Alternatively, the mechanism could be potentiation of the untrained hemisphere as a result of the deprivation, which may be the reason why depriving one *eye* results in increased cortical activity when that eye is stimulated later [@lunghiBriefPeriodsMonocular2011].





