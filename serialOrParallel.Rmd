# A serial position sampler {#serialOrParallel}

Brains have a massively parallel architecture. Yet as we have seen, tracking performance drops steeply with target load, indicating that tracking is highly capacity-limited. Even with a capacity limitation, however, processing might remain completely parallel. In that scenario, lots of stimuli could still be simultaneously processed, but with a large time or accuracy cost. However, in worlds like this one, animals have priorities and time is at a premium. To out-compete others, one needs to distinguish rapidly between friend and foe. As a practical matter, then, limited-capacity processes are unlikely to be spread thinly across dozens of stimuli. Instead, they are likely to be allocated in serial, processing small subsets of targeted stimuli, one small group after another. These subsets may consist of just one stimulus, with processing happening one-by-one.

<!--Of the processes that underlie tracking, even those with the smallest capacity might still process the objects in small sets, but sets of greater than one.
 
One can certainly walk and chew gum at the same time, and even simultaneously use one hand to rub one's belly and the other to tap one's head, although it may take a bit of practice for some of us. However, when it comes to making a keypress based on the identity of a visual stimulus with one hand and based on the identity of a sound with the other hand, the evidence suggests that one particular component of these two tasks simply cannot be done simultaneously @pashlerDualtaskInterferenceSimple1994. Specifically, the pattern of response times indicates that while a choice is being made in response to the visual stimulus, choice processing for the auditory stimulus cannot commence.-->

Whether the processes that underlie MOT involve a serial component has been one of the chief concerns of researchers since the very first paper on the topic by @pylyshynTrackingMultipleIndependent1988. For mentation more broadly, this has been a major preoccupation of the field more generally too.  Many researchers have been influenced by Anne Treisman's theory that certain forms of feature binding and other judgments require a serial one-by-one process. But over forty years after Treisman sparked a large literature on the topic, whether various mental processes occur one-by-one or not remains unresolved - although my money is on one-by-one for certain forms of feature binding, and possibly other processes.

## Spatial relationships - a case study of serial processing 

After 40 years of work, the evidence is fairly strong that at least a few forms of binding, in particular judgments of arbitrary spatial relationships, involve a one-by-one process. The evidence comes from at least five different approaches. In their redundant-target paradigm, David Gilden and colleagues improved on the inferential power of the visual search approach of Treisman [@thorntonParallelSerialProcesses2007]. The results indicated that discriminating many spatial relations, such as discriminating the two symbols below <!--in \@ref(fig:venusSymbols) -->, requires a serial process [@gildenSerialProcessVisual2010].

```{r venusSymbols, echo=FALSE, out.width="30%", fig.cap=" "}
knitr::include_graphics("imagesForRmd/spatialRelations/ThorntonVenusSymbols.png")
```

Daniel Linares, Maryam Vaziri-Pashkam, and I presented colored discs rapidly moving in a circular trajectory about the fixation point. When the discs moved too rapidly to track even a single one of them, participants were unable to report which discs were adjacent to each other, even when they were presented for multiple seconds. This suggested that attention, in particular that deployed when tracking, is necessary for judging spatial relationships. An additional result suggested that the spatial relationship is mediated by an attentional shift. When the discs were moving slow enough that participants could often do the task, but sometimes made errors, the errors had a systematic pattern. The task was to report which disc was aligned with a target disc. Participants tended to err by reporting the trailing disc next to the target rather than the aligned disc, consistent with them making a time-consuming shift of attention from the target, which sometimes landed on the trailing disc because the aligned disc had moved on by the time the attention shift landed [@holcombePerceivingSpatialRelations2011]. Based on EEG signals and also eye movement data when the eyes were unconstrained, @franconeriFlexibleVisualProcessing2012 found evidence for an attentional shift when judging the spatial relationship between static stimuli. In a dual-task design, @leeAttentionalCapacityUndifferentiated1999 showed that while several judgments could be made concurrently with an attention-demanding task at the fovea, judgments of the spatial relationship between two stimuli (whether a bisected disk had red on the left or on the right) could not. Finally, using a visual working memory paradigm in which they investigated the effect of set size, exposure duration, and simultaneous versus serial presentation, @smithAttentionweightedSamplesizeModel2016 also found evidence consistent with discrimination of spatial relations involving serial attention.

Because in any one paradigm, serial and parallel processes can yield similar or identical data, a number of experimental manipulations was needed to provide convincing evidence of serial processing for spatial relationships. For example, while visual search results led Treisman to conclude that conjoining two spatially superposed features, such as red with leftward tilted, required a serial process of focused attention  [@treismanFeatureIntegrationTheory1980], such results are explainable by limited-capacity parallel processing [@palmerAttentionVisualSearch1995], and the redundant-target paradigm of @thorntonParallelSerialProcesses2007 suggested that no serial process is involved.


## A case for serial position sampling

## Spatial relationships - a case study of serial processing 

<!-- MAKE EVERYTHING ABOVE INTO A REVIEW ARTICLE, THEN FIX THE WIKIPEDIA PAGE FOR FEATURE BINDING -->

Like for other visual tasks, for object tracking we should demand diverse lines of evidence before concluding that tracking involves a serial one-by-one process. Unfortunately, there are some difficulties involved in adapting the paradigms developed for judgments involving static stimuli, as we shall see.

Let's clarify exactly what we are interested in here. The question is whether *any* serial process is involved in tracking, because we can already be highly confident that parallel processes are involved. The front end of visual processing, from the retina to primary visual cortex, registering the basic elements of color, form, and motion, clearly operate in massively parallel fashion. The question, then, is whether any process involved in tracking is serial. By "any process", I don't mean processes during the response phase, such as clicking on the objects one think are targets, or the daydreaming that may occur while one is also doing the task. Instead, I'm referring to processes that are ordinarily necessary for tracking to be accomplished during the tracking phase of the task.

<!--A major ambition is to create a unified theory that explains properties of both tracking and other tasks such as visual search and dual-task performance.-->

<!--A serial account of tracking is that a process must switch from target to target to update targets' positions, one-by-one.--> 

While the nature of MOT closes off some options for investigating the serial/parallel issue, it does provide a new kind of evidence for serial processing. In particular, after a few assumptions are made, serial sampling makes a specific prediction for the temporal limits on tracking. The most basic assumption is that after a moving target's position is sampled, if its position is not re-sampled before another object takes its place, it will be lost. This is a consequence of the visual system assuming that the objects nearest to the last-recorded positions of the targets are, in fact, the targets. Related to this assumption is that the system does not use motion direction and speed reliably. The evidence that speaks to this is discussed in section \@ref(beyondLocation), but even if it is false, note that violations of this assumption would simply reduce the the size of the effects predicted by the serial account. 
 
For circular trajectories such as those used by @holcombeSplittingAttentionReduces2013, the product of the speed (in revolutions per second) and number of objects determines how often sampling must be done to avoid losing a target. In an MOT trial with two targets, after one target is sampled, a one-by-one serial process would switch to the other target. If the distractor trailing the target arrives near the first target's former location before the serial process switches back, then we can expect tracking to fail.

Increases in the number of targets reduces how often each individual target is sampled. As a result, the serial switching account predicts a linear relationship between the number of targets and the temporal limit on tracking. In Figure \@ref(fig:serialModelFit) below, the predictions are plotted if tracking samples position and switches to another object every 60 ms and every 90 ms.

<!--
If one object is sampled every 100 ms, then if it is replaced every 200ms, you have 100% ambiguity in the correspondence problem. So to get sampling time from temporal limit, divide by 2. HolcombeChen & RoudaiaFaubert observed about 140 ms for young men, meaning 70 ms.
-->

```{r loadSomePackages, echo=F, include=F, warning=F, messages=F}
#This is in a separate code chunk where I am happy to set messages to FALSE so I can avoid package loading messages
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(forcats) #for fct_relevel

```

```{r serialModelFit, echo=F, warning=F, fig.cap="The predictions of 60 and 90 ms sampling time are plotted as dashed lines, together with data from Holcombe & Chen (2013) and Roudaia & Faubert (2017). The data symbols are horizontally offset to avoid overlap."}


E1HolcombeChen13 <- tibble(experiment="Holcombe & Chen E1", targets=seq(1,2),   temporalLimit= c(1000/6.93, 1000/4.45) )
E2HolcombeChen13 <- tibble(experiment="Holcombe & Chen E2", targets=seq(2,3),   temporalLimit= c(1000/4.05, 1000/2.7) )
RoudaiaFaubert<- tibble(experiment="Roudaia & Faubert young men", targets=seq(1,3), temporalLimit=c(1000/6.4,1000/4,1000/2.8))
RoudaiaFaubert2<- tibble(experiment="Roudaia & Faubert young women", targets=seq(1,3), temporalLimit=c(1000/4.9,1000/3,1000/1.8))
#Add MARINOVIC 7.2 Hz and also in the similar version of this Figure in SpeedandTime
versCavLabianca8cyclesEachParticipant<- c(4.2,4.4,5.7,6,6,7)

versCavLabianca<- tibble( experiment="Verstraten et al.", targets=1, temporalLimit =
                            1000/mean(versCavLabianca8cyclesEachParticipant) )

temporalLimsData<- rbind(E1HolcombeChen13,E2HolcombeChen13,RoudaiaFaubert,RoudaiaFaubert2,versCavLabianca)
temporalLimsData$experiment <- as.factor(temporalLimsData$experiment)

critInterval <- function(targets, samplingInterval) {
 samplingInterval*targets*2
}

valuesForComputing<- expand_grid(
  targets = c(1, 2, 2.6, 3, 4), # including 2.4 because that's where I want to put the text labels
  samplingInterval = c(60, 90),
  experiment = "zpredicted" #when it starts with z, it will be at end in legend when ggplot creates factor ordering on fly
)
tibl <- valuesForComputing  %>% mutate(temporalLimit = critInterval(targets,samplingInterval))

predictions <- tibl %>% filter(targets != 2.4) #to plot lines

#male/female samples https://github.com/kmiddleton/rexamples/blob/master/ggplot2%20male-female%20symbols.R
#unicode character list (look at ) https://www.ssec.wisc.edu/~tomw/java/unicode.html
gg<-ggplot(temporalLimsData, aes(x=targets,y=temporalLimit, shape=experiment)) +
    geom_point(position=position_dodge(width=.2), size=5) +
    geom_line(data=predictions, aes(x=targets, y=temporalLimit, color=factor(samplingInterval)),
               linetype="dashed", inherit.aes=F) + #model predictions
    scale_shape_manual(values = c("\u25A1", "\u25CB", "\u2642", "\u2640", "\u25AB",   "\u1111")) +
    scale_x_continuous(breaks=1:3, limits=c(.9,4)) + #so that model lines extend all the way to symbols
    scale_y_continuous(breaks=seq(0,700,100), limits=c(0,NA)) +
    ylab('temporal limit (ms)') + labs(color='sampling interval (ms)', shape='study') + 
    theme_bw() +
    theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          panel.background = element_blank())

ylims<- layer_scales(gg)$y$get_limits()
xlims<- layer_scales(gg)$x$get_limits()
graphAspectRatio <- diff(ylims)/diff(xlims)

#Create the string label, e.g. "90 ms"
lineLabels <-  tibl %>% filter(targets == 2.6)
lineLabels$label <- paste0(lineLabels$samplingInterval," ms")

#Calculate the angle of the label to make it have the same angle as the line
lineLabels<- lineLabels %>% mutate(slop = samplingInterval * 2)
lineLabels<- lineLabels %>% mutate(slope = slop / graphAspectRatio)
lineLabels<- lineLabels %>% mutate(angleIfAxesSameScale = atan(slope)*180/pi)
lineLabels<- lineLabels %>% mutate(angle = angleIfAxesSameScale)
lineLabels<- lineLabels %>% mutate(temporalLimit = temporalLimit + 10) #to raise it off the line

gg<-gg +  geom_text(data=lineLabels, aes(label = label, angle=angle, color=factor(samplingInterval)), vjust="bottom") +
          guides(colour=FALSE) #don't show sampling interval legend
show(gg)
```

With every unit increase in the number of targets, the interval between successive samples of that target increases by the sampling time. This is under an optimistic assumption of orderly sampling (the sampling process sampling first one target, then the second target, then the third target, and back to the first target, rather than sampling the second target or third target again); otherwise the predicted slope should be even steeper.

Because a particular sampling time specifies the temporal limits for all target sizes, no parameters needed to be fit here. That is, the dashed lines in Figure \@ref(fig:serialModelFit) are not best-fitting regression lines. Their slope and intercept are determined by the sampling time indicated. The lines fit the data fairly well. But how impressed should we be by this? One limitation is that only three target loads were tested, so we should have little confidence that the relationship is truly linear in the way that the model predicts.

An additional issue for interpreting the relationship is that in principle, the temporal limit for covertly tracking a *single* target could be set by a different process than the serial switching hypothesized to set the limit for two and three targets, because with a single target, there is no need to switch attention around. Suprisingly, however, evidence from other paradigms suggests that even when only a single static location is relevant for attention, performance oscillates over time, a pattern which has been dubbed the "blinking spotlight of attention" [@vanrullenBlinkingSpotlightAttention2007; @fiebelkornReportRhythmicSampling2013].

Thus, we should not really expect the temporal limit for one target to fall on the same line as that for two and for three targets. Yet in the plotted data (Figure \@ref(fig:serialModelFit)), it can be seen that the one-target limit may actually fall on the same line. It's as if the sampling interval of attention for a single static location also sets the inter-object sampling interval. While the data are consistent with this, they support this proposition only weakly, because there is considerable statistical uncertainty associated with the data points.

The means for the male and predominantly-male datasets, which are the lower clusters, imply temporal limits, when tracking one target, between `r ms<- round( (temporalLimsData %>% filter(targets==1))$temporalLimit ,-1); ms[1]` and `r ms[3]` ms. Recall that because the target must be sampled at twice the temporal limit to avoid confusion with the trailing distractor, one could infer sampling rates from this between `r round(ms[1]/2)` and `r round(ms[3]/2)` ms. This assumes near-perfect linking of a target's last-sampled position with the nearest neighbor in the new sample. The example dashed lines represent the predictions if sampling occurred at 60 ms (red) and 90 ms (blue) and switching occurred systematically rather than visiting one target twice before sampling the third.

How do these numbers compare to sampling intervals inferred with other paradigms? @macdonaldAttentionalSamplingMultiple2013 studied the continuous wagon-wheel illusion, in which a rotating spoked circle is sometimes perceived to rotate backwards, for which a leading explanation is intermittent sampling []. Asking participants to report reversals when they viewed multiple spoked circles, they inferred a sampling interval of `r round(1000/13.3)` ms<!--13.3 Hz-->, which assumes, among other things, that perceived reverse motion is strongest when the wheel travels three-quarters of the inter-spoke angle between samples, yielding a one-quarter backwards rotation with each sample. Their `r round(1000/13.3)` ms figure is similar to what we inferred from tracking. However, @arnoldIllusoryMotionReversals2014 found that the peak frequency for perception of illusory backwards rotation differed for equiluminant motion (5 Hz) and luminance-defined motion (10 Hz in their test), suggesting that results from such experiments cannot be interpreted as providing a constant simple sampling rate for high-level vision. <!--also for moving objects, although the rate is harder to interpret. MacDonald & Vanrullen assume motion signal is strongest at 1/4 of cycle, but I seem to remember that was argued by Nakayama but can't remember it's sure -->

Studies that use other behavioral paradigms in an attempt to investigate visual sampling suggest sampling intervals longer than 100 ms: `r round(1000/7,-1)` ms [@reFeatureBasedAttentionSamples2019]<!--They claimed 8 Hz in their paper but the figure shows the peak at 7 Hz-->, 142 ms [@vanrullenBlinkingSpotlightAttention2007], `r round(1000/7.5,-1)` ms <!--claimed 8 Hz but had equal power at 7 and 8-->[@fiebelkornReportRhythmicSampling2013], and `r round(1000/7.14,-1)` ms [@dugueAttentionSearchesNonuniformly2015]<!--said ~7 Hz but sampling was very coarse, one peak at 7.14--><!--For the @reFeatureBasedAttentionSamples2019 paper, they wrote in their conclusion that sampling occurred at 8 Hz, but their figure shows a peak at 7 Hz, so I have used 7 Hz or `r round(1000/7,-1)` ms.-->, although the statistics used in some of these studies may have led to spurious findings [@brookshireReevaluatingRhythmicAttentional2021]. A visual search study that recorded from neurons in monkeys suggested a 44 ms sampling interval [@buschmanSerialCovertShifts2009]. These other studies all used stationary objects or multiple locations that the participant was told to monitor, which conceivably could explain the slower sampling intervals found in some, but there also remains ample reason otherwise for uncertainty.

Despite the sizable and growing neurophysiological and neuroimaging literature on oscillations and intermittent sampling, I have not found a study that tests whether the sampling operates independently in the two hemifields. This is unfortunate because a hallmark of tracking is its hemifield independence, as reviewed in \@ref(twoBrains). <!--Is the spotlight oscillation hemisphere-specific? Finding of 7 Hz for feature attention by @reFeatureBasedAttentionSamples2019 suggests global.)-->

It might turn out that even after researchers regularly assess whether the sampling they are measuring is hemifield-independent, there will continue to be a large range of rates found. If so, perhaps different tasks result in different sampling rates, and the sampling process can occur more quickly for tracking as it requires sampling position only. Another possibility is that the assumptions underlying the calculations in behavioral studies such as object tracking are wrong. If, for example, motion direction is used to guide the next position sampled, tracking could succeed with a slower sampling interval more similar to those documented in most of the neural studies cited above (but see section \@ref(beyondLocation)).

A few studies, while finding evidence for oscillations in some conditions, do not find it to be tied to cued locations in the same way as other papers cited above suggest [@werfNoEvidenceRhythmic2021; @petersObjectbasedAttentionPrioritizes2020]. The fact that psychology and neuroscience researchers admit to substantial rates of publication bias and p-hacking [@jenningsPublicationBiasNeuroimaging2012; @johnMeasuringPrevalenceQuestionable2012; @rabeloQuestionableResearchPractices2020] raises the spectre of further, unpublished, evidence that is inconsistent with the prevailing narrative of regular oscillations that correspond to an attentional sampling rate.

In summary, despite a wealth of neuroscientific evidence that serial sampling occurs for attentional tasks, which might account nicely for the existence of a coarse temporal limit on tracking, and for its dramatic worsening with target load, more evidence would be needed for this to be strongly supported. And serial sampling is not the only possible explanation of the steep decrease of temporal limit with target load. Conceivably, a parallel process of evidence accumulation with limited capacity could fit the data. Under this account, when attention is split among multiple targets, this greatly slows the rate that of accumulation of evidence for some process that is critical to tracking. This process could be linking successive position samples, if samples do not occur less often with more targets because the visual system takes global snapshots; however, the evidence from other paradigms rules against global snapshots [e.g. @klineIllusoryMotionReversal2004]. For a parallel theory without intermittent sampling, the matching process wouldn't be operating no discrete positions, but rather the spatiotemporal blur streaks described in the next section. 

<!--@jiaSequentialSamplingVisual2017 No: Moreover, the 2 disc stimuli in all 3 experiments were presented in the left and right visual fields, and therefore, the observed attentional switching could have been solely caused by interhemispheric competition [32]. To address this issue, we ran a control experiment (N = 13) in which the 2 discs were presented in the upper and lower visual fields within the same visual hemifield (S4 Fig). The same alpha-band alternating pattern was observed, thus arguing against the interpretation of interhemispheric competitio-->

<!-- @macdonaldAttentionalSamplingMultiple2013 finds less dramatic decrease in time with number of wagon wheels - instead of 8.7, 5, 3.3, 2.5 Hz, they found 8.7,6.6,6.5,6.2-->
<!--@davidsonAttentionPeriodicallySamples2018 found evidence for 8 Hz sampling during binocular rivalry-->

<!--This could all be compatible with limited-capacity parallel. All targets are simultaneously processed but processing becomes much much slower when attention is spread among more targets, such that with three targets. processing two-by-two, and that remains a possibility
-->

<!-- If there's 2 targets and attention is  samplimg one every 50 ms, then each is sampled every 100 ms, so to solve the correspondence problem they need to go at 5 Hz (200 ms) or slower, so that they only move halfway to the next location. For 3 targets, each is sampled every 150 ms so they need to not get to the next one's location for 300 ms (3.33) hertz.
criticalTemporalInterval = samplingTime*targets*2
385 = samplingTime*3*2; samplingTime = 64
64*2*2= 256 against 238.
blinking spotlight means 64*1*2 = 128 against 143.
-->

## Evidence for parallel processing

@howeDistinguishingParallelSerial2010 applied the simultaneous-sequential presentation technique developed by @shiffrinVisualProcessingCapacity1972 to investigate the nature of parallel or serial processing involved in MOT. The technique was developed for tasks involving stationary stimuli and was originally conceived as investigating whether several stimuli could be processed in parallel without being affected by any capacity limit. The stimuli are presented either all at once (simultaneously) or in succession (sequentially) during a trial, half the stimuli presented in the first interval, and the other half in the second interval. To equate the total amount of time each stimulus is presented in the simultaneous and successive conditions, a trial in the simultaneous condition is only half as long as that of the successive condition. The technique has been applied extensively to the detection of a particular alphanumeric character among other alphanumeric characters, and researchers have found that processing in the simultaneous condition is equal to or better than the sequential condition [@shiffrinVisualProcessingCapacity1972; @hungSimultaneousBetterSequential1995], suggesting that multiple alphanumeric characters can be recognized in parallel, with no capacity limitation, or at least a capacity that is not taxed by up to the four stimuli typically used. An alternative possibility is that attention for some reason did not select the locations of the presented stimuli during the two intervals of the sequential condition. For example, if attention got "stuck" on the locations of the first half of stimuli, it would fail to show the advantage expected for a limited-capacity process that could devote all its resources to each of the two subsets of the stimuli during their respective presentation intervals.

@howeDistinguishingParallelSerial2010 adapted this technique to MOT by, in a "sequential" condition, periodically freezing half of the moving targets while the other half continued to move. In the simultaneous condition, *all* of the targets were periodically frozen. The idea, then, is that any parallel processes will be distributed equally among both moving and any temporarily-stationary targets, whereas a serial process must be reallocated away from the stationary targets during the interval that they are stationary. Such a serial process would then result in higher performance in the condition where targets occasionally pause relative to an "all pause" condition where all targets are temporarily-stationary at the same time.

Across eight experiments, they found that performance was equal or better in the simultaneous condition than in the sequential condition. They interpreted this result as ruling against a serial model whereby tracking is accomplished by switching a process important for tracking from one (or a few) targets to the others. One assumption of this interpretation is that a serial process should be able to efficiently switch away from targets when they are stationary to selectively process the moving targets. As @howeDistinguishingParallelSerial2010 pointed out, there is good evidence from other MOT experiments that participants can prioritize the most important targets or those perceived to be more difficult to track, for example in virtue of them moving faster [@chenResourceDemandsObject2013; @croweGoaldirectedUnequalAttention2019]. A concern with the @howeDistinguishingParallelSerial2010 experiments, however, is that the longest non-movement (freeze) interval used in the experiments was half a second, and in most of the experiments, the non-movement interval was only a few hundred milliseconds. It is possible that at that rate, a serial process was unable or ineffective at switching from the stationary targets to the moving targets and back again. In addition, the locations of the targets had to be remembered while they were frozen (to distinguish them from the stationary distractors) so that the serial tracking process could switch back to them. These task requirements for non-moving stimuli is quite different from what was involved in traditional applications of the simultaneous-sequential technique (e.g. @shiffrinVisualProcessingCapacity1972), where the task was to detect just a single target from among stationary candidate locations.

Regarding the uncertainty around the assumption that a serial process could effectively switch away from the targets when they were stationary during the brief stationary interval, @howeDistinguishingParallelSerial2010 did conduct one experiment that used a longer, 1.5 s interval, for the movement and non-movement phases. However, this study was deliberately designed to favor serial processing, as a kind of sanity check to establish that the technique worked. They presented only two targets and predictably alternated which of them was moving and which was stationary. In contrast to all of their other experiments they found an advantage for the sequential condition, and they concluded that the 1.5 s interval "was more than sufficient for observers to transfer their attention from one target to another". But this again raises the question of whether the intervals in the other experiments were simply too short for the serial process to reallocate appropriately. It may be that as one increases the pause interval toward 1.5 s, at some point the sequential condition will show an advantage over the simultaneous condition. What is the criterion for saying what interval is so long that a sequential advantage there no longer speaks to tracking processes? Another issue with this experiment is that because only two targets were used, it likely taps the C≈1 processes more than the previous experiments that used more targets. And, of course,  C≈1 processes have a capacity of approximately one, and thus have to process two targets serially.

Returning to the difficult issue of how long of an alternation interval should be used in the simultaneous-sequential design, in a study of word recognition, @scharffExtendingSimultaneoussequentialParadigm2011 used the sequential-simultaneous technique to investigate contrast discrimination and visual word recognition. The contrast discrimination task was to judge which of an array of low-contrast discs had a higher contrast than all the rest (which were all identical in contrast), while the word recognition task was to locate the one word, in a display of words, that belonged to a particular category. For example, in one case the target category was "animals", and the word "dog" (the target) was present in addition to the words ‘car,’ ‘belt,’ and ‘poet’. @scharffExtendingSimultaneoussequentialParadigm2011 found no advantage of the sequential condition for judging which of an array of low-contrast discs had a higher contrast, which they interpreted as consistent with parallel, unlimited-capacity processing. In the word recognition task, in contrast, they found a large sequential advantage, which they took as evidence of serial processing. The alternation interval they used was 1.1 seconds, again raising the possibility that @howeDistinguishingParallelSerial2010 might have found a different result with longer intervals, as the longest interval used by @howeDistinguishingParallelSerial2010, save for in the control experiment, was half a second. In sum, while the @howeDistinguishingParallelSerial2010 evidence might have provided evidence for serial processing and yet did not, a strong possibility remains that in conventional MOT tasks, a serial process rapidly switches among the targets.

## Objects moving every which way

In the behavioral studies that revealed the temporal limits on tracking, a target and its distractors all shared the same circular trajectory. But in most studies of MOT, the distractors near a target move in many different different directions relative to the target. That is, typical displays have low trajectory among targets and distractors' trajectories.

Accounting for tracking entirely with serial sampling has not been successful with low-overlap trajectories [@liModelMultipleIdentity2019], although early efforts were based on the likely-false assumption that attention shift times increase with shift distance [@pylyshynTrackingMultipleIndependent1988; @yantisMultielementVisualTracking1992], so more attempts should be made.

All recent models of MOT rely largely on a parallel process for updating of target positions (a serial process is used in some models for other features, which is discussed in \@ref(identity)) [@oksamaPositionTrackingIdentity2016; @lovettSelectionEnablesEnhancement2019; @liModelMultipleIdentity2019; @oksamaDynamicBindingIdentity2008a; @srivastavaAttentionDynamicsMultiple2015; @kazanovichOscillatoryNeuralModel2006]. These parallel theories do not seem able to account for the basic temporal limit discovered with circular trajectories and showcased in \@ref(speedAndTime), nor for the temporal limit's dramatic decrease with target load. Most model authors do not mention this issue, and it does not appear that their model can explain the phenomenon [@srivastavaAttentionDynamicsMultiple2015; @vulExplainingHumanMultiple2010; @maNoCapacityLimit2009; ]. Not only do none of these models predict an increase in temporal interference with target load, most of them never even consider the possibilty of temporal interference.

I am aware of two groups of researchers that have addressed the temporal interference results. @lovettSelectionEnablesEnhancement2019 have a hybrid parallel-serial model of multiple object tracking. Target positions are updated in parallel, but this parallel updating process occurs concurrently with a serial process that, by visiting a target, can utilise the target's features and compute its motion history. By "motion history", these researchers seem to mean that the motion direction of the target is processed, which can then be used to predict future positions, which helps disambiguate which is the target and which distractor when objects overlap or come close to overlapping. This helps explain the evidence that localization of targets in such situations can actually be better than targets that are not near distractors [@srivastavaAttentionModulatesSpatial2016]. This serial process can thus explain why predictability of motion trajectories yields an advantage when there are only a few targets, but no detectable advantage when there are more [@howeMotionInformationSometimes2012; @luuExtrapolationOccursMultiple2015].

To explain the temporal resolution and load results of @holcombeSplittingAttentionReduces2013, @lovettSelectionEnablesEnhancement2019 deploy their model's serial process in a surprising way. <!--"when objects move along the same trajectories (e.g., Holcombe & Chen, 2013) and/or are close to each other, high resolution information is required for discriminating the objects. Thus, tracking becomes more serial, and observers are inclined to switch attention and eye gaze from one object to another (Li, Oksama, & Hyönä, 2018a, 2018b; Meyerhoff et al., 2018)."--> Their idea is that when targets and distractors share circular trajectories as in @holcombeSplittingAttentionReduces2013, participants shift from parallel tracking to serial tracking, and this results in the decline in temporal frequency limit with load and also the 2 rps speed limit. But unlike for some of their other claims, they never validate this against data by running the model on these trajectories. Moreover, they don't explain how the parallel process contributes to performance during the task. The serial process is needed for circular trajectories, they say, to prevent targets from becoming confused with the trailing distractors that soon occupy the targets' former positions. The model's serial process allows it to predict future positions and was in fact postulated to address overlap situations. This makes some sense, and the serial process is a natural for explaining the approximately-linear decline in temporal limit with load. But presumably the parallel position updating process is still in operation, as it is in other displays that they say involve serial processing, so why would the pattern of performance (a declining temporal limit) be so determined by the serial process?

For a serial process to determine performance in a model where parallel processing ordinarily plays the dominant role in updating target positions, it seems that the parallel process must somehow be disabled. In other words, in conditions where the serial process determines the performance limit, the parallel process' updating of positions must be so inferior that it does not substantially contribute to the pattern of performance. Another way of saying this is that the serial process is the performance-limiting process. This type of reasoning based on the pattern of performance thresholds has long been used in psychophysics [e.g., @victorTemporalPhaseDiscrimination2002].

Assuming that the limiting process is indeed serial sampling, we can then infer a characteristic of the parallel updating process. The parallel updating process must be effectively updating targets' positions more infrequently than about every 180 milliseconds. That is, if it's true that temporal limit worsens linearly with target load and the serial process determines this performance pattern, implying that the parallel process isn't contributing much, then the parallel process's contribution must be worse than that of the serial process. The 3 Hz limit with 3 targets [@holcombeSplittingAttentionReduces2013; @roudaiaDifferentEffectsAging2017], then, places an upper bound on the parallel process' functioning. <!--PREDICTION FUTUREEXPERIMENT--> It is important, then, to measure the temporal limit with 4 targets. This could further delimit the upper bound on the parallel process. And independent of any particular theoretical reasoning, it would be quite remarkable to see the temporal limit on tracking decrease even further to worse than 3 Hz, indeed to close to 2 Hz if the linear trend continued.

@liModelMultipleIdentity2019 have also addressed the effect of load on the temporal limit. Their latest model, MOMIT 2.0, updates the position of targets with a parallel process. To address the temporal limit, @liModelMultipleIdentity2019 wrote that "when objects move along the same trajectories (e.g., Holcombe & Chen, 2013) and/or are close to each other, high resolution information is required for discriminating the objects. Thus, tracking becomes more serial". However, he objects in the Holcombe & Chen (2013) studies were not close to each other, and I haven't been able to find anything in the description of MOMIT 2.0 that should be hindered by objects sharing a trajectory.

(CORRESPONDENCE PROBLEM at all. IT DOESN'T FEEL ANY LESS PARALLEL THAN TRACKING TASKS THEY CLAIM ARE PARALLEL. In contrast, in serial visual search , it does feel like you are moving your atttention around. Never been tested because I didn't think anyone would come up with that.

Given that these models can't account for the temporal limits on tracking, why have they been fairly successful in mimicking human performance with the typical MOT displays not designed to probe the temporal limit? Well, for typical MOT displays, it remains unclear how much temporal interference we should expect - no one has bothered to calculate the distribution of the intervals between targets and distractors visiting a given location. Second, it is not clear how identifiable the models are from the human data. That is, a number of different models, with a large range of possible parameters, might equally explain the data. One reason is that potential spatial interference and for temporal interference are confounded in typical MOT displays. That is, trials in which the moving objects come close to each other in space also tend to be trials in which moving objects visit approximately the same location in a short span of time. As a result, a model that embodies spatial interference only may explain the data about as well as one that includes temporal interference. 

## REsolution

The parallel location updating element of their theory can be saved, however, by positing that trajectory information is available to a parallel process thanks to motion traces in sensory memory, as we will see in section \@ref(beyondLocation). That process would indeed be hampered by objects sharing a trajectory, on the assumption that trajectories are used not for extrapolation, but for solving the correspondence problem.

Multiple lines of evidence present problems for the story of parallel location processing and serial updating of identities and object features. In section \@ref(serialOrParallel), we saw that the temporal resolution of object tracking declines with the number of targets in a manner that is difficult to explain without resort to a serial account of location updating. 



Give credit to Srimant for re-upping serial accounts @tripathyMultipleTrajectoryTracking2012 @tripathyMultipleObjectTrackingSerial2011







The circular trajectories that were used to reveal the temporal limits on tracking and the less-constrained trajectories of typical MOT experiments differ in one way that we have not yet discussed. This arises from the fact that the objects in typical MOT experiments do not share their trajectory with other objects. Srimant Tripathy and his collaborators have suggested that a moving object leaves an extended trace that lingers in sensory memory and that tracking processes operate on that representation rather than objects' instantaneous positions  [@tripathyMultipleObjectTrackingSerial2011; @howardMultipleTrajectoryTracking2012]. If so, targets and distractors can be disambiguated as a result of their differing motion directions (which manifests as different orientations of the sensory memories) in addition to their positions. This could mean that temporal interference is less of a factor in typical MOT displays. However, the evidence is that motion direction information is not used much when there are more than two targets, as reviewed in the next section ( \@ref(beyondLocation)), which casts some doubt on Tripathy's suggestion.

