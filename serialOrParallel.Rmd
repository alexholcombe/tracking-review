# A serial sampler {#serialOrParallel}

Brains have a massively parallel architecture. Yet as we have seen, tracking performance drops steeply with target load, indicating that tracking is highly capacity-limited. This could still be explained by a parallel model, however, and given the brain's predilection for parallel processing, one should arguably be skeptical of a serial, one-by-one model.

<!--Of the processes that underlie tracking, even those with the smallest capacity might still process the objects in small sets, but sets of greater than one.
 
One can certainly walk and chew gum at the same time, and even simultaneously use one hand to rub one's belly and the other to tap one's head, although it may take a bit of practice for some of us. However, when it comes to making a keypress based on the identity of a visual stimulus with one hand and based on the identity of a sound with the other hand, the evidence suggests that one particular component of these two tasks simply cannot be done simultaneously @pashlerDualtaskInterferenceSimple1994. Specifically, the pattern of response times indicates that while a choice is being made in response to the visual stimulus, choice processing for the auditory stimulus cannot commence.-->

Whether the processes that underlie MOT involve a serial component has been one of the chief concerns of researchers since the very first paper on the topic [@pylyshynTrackingMultipleIndependent1988]. One reason the issue is of interest is that if tracking does include a serial component, that component must switch among the targets, much like is thought to occur in certain visual searches and other tasks requiring focused attention. Thus, tracking could be modeled together with some other voluminous sets of results, leading to insights about a variety of tasks. In addition, as we will see, likely it would be related to the neural oscillations that have become heavily investigated in recent years.

<!--A serial account of tracking is that a process must switch from target to target to update targets' positions, one-by-one.--> 

## The case for serial position sampling

The serial sampling account makes a specific prediction for the temporal limits on tracking, after a few basic assumptions are made.

After a target is sampled, it continues moving and if its position is not re-sampled before another object takes its place, it will be lost. This assumes that either its motion direction and speed are not reliable guides to its future positions, or that motion direction and speed are not used. The evidence that speaks to this is discussed in section \@ref(beyondLocation), but for now note that violations of this assumption would ameliorate the effect, reducing the size of the effects predicted by the serial account. 
 
For circular trajectories such as those used by @holcombeSplittingAttentionReduces2013, the product of the speed and number of objects determines how often sampling must be done to avoid losing a target. In an MOT trial with two targets, after one target is sampled, the serial process switches to the other target. If the distractor trailing the target arrives near the first target's former location before the serial process switches back, then we can expect tracking to fail.

Increases in the number of targets reduce how often any individual target is sampled. As a result, the serial switching account predicts a linear relationship between the number of targets and the temporal limit on tracking. In Figure  \@ref(fig:serialModelFit) below, the predictions are plotted if tracking samples position and switches to another object every 60 ms and every 90 ms.

<!--
If one object is sampled every 100 ms, then if it is replaced every 200ms, you have 100% ambiguity in the correspondence problem. So to get sampling time from temporal limit, divide by 2. HolcombeChen & RoudaiaFaubert observed about 140 ms for young men, meaning 70 ms.
-->

```{r serialModelFit, echo=F, warning=F, fig.cap="The predictions of 60 and 90 ms sampling time are plotted as dashed lines, together with data from Holcombe & Chen (2013) and Roudaia & Faubert (2017). The data symbols are horizontally offset to avoid overlap."}
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(forcats) #for fct_relevel

E1HolcombeChen13 <- tibble(experiment="Holcombe & Chen E1", targets=seq(1,2),   temporalLimit= c(1000/6.93, 1000/4.45) )
E2HolcombeChen13 <- tibble(experiment="Holcombe & Chen E2", targets=seq(2,3),   temporalLimit= c(1000/4.05, 1000/2.7) )
RoudaiaFaubert<- tibble(experiment="Roudaia & Faubert young men", targets=seq(1,3), temporalLimit=c(1000/6.4,1000/4,1000/2.8))
RoudaiaFaubert2<- tibble(experiment="Roudaia & Faubert young women", targets=seq(1,3), temporalLimit=c(1000/4.9,1000/3,1000/1.8))

versCavLabianca8cyclesEachParticipant<- c(4.2,4.4,5.7,6,6,7)

versCavLabianca<- tibble( experiment="Verstraten et al.", targets=1, temporalLimit =
                            1000/mean(versCavLabianca8cyclesEachParticipant) )

temporalLimsData<- rbind(E1HolcombeChen13,E2HolcombeChen13,RoudaiaFaubert,RoudaiaFaubert2,versCavLabianca)
temporalLimsData$experiment <- as.factor(temporalLimsData$experiment)

critInterval <- function(targets, samplingInterval) {
 samplingInterval*targets*2
}

valuesForComputing<- expand_grid(
  targets = c(1, 2, 2.6, 3, 4), # including 2.4 because that's where I want to put the text labels
  samplingInterval = c(60, 90),
  experiment = "zpredicted" #when it starts with z, it will be at end in legend when ggplot creates factor ordering on fly
)
tibl <- valuesForComputing  %>% mutate(temporalLimit = critInterval(targets,samplingInterval))

predictions <- tibl %>% filter(targets != 2.4) #to plot lines

#male/female samples https://github.com/kmiddleton/rexamples/blob/master/ggplot2%20male-female%20symbols.R
#unicode character list (look at ) https://www.ssec.wisc.edu/~tomw/java/unicode.html
gg<-ggplot(temporalLimsData, aes(x=targets,y=temporalLimit, shape=experiment)) +
    geom_point(position=position_dodge(width=.2), size=5) +
    geom_line(data=predictions, aes(x=targets, y=temporalLimit, color=factor(samplingInterval)),
               linetype="dashed", inherit.aes=F) + #model predictions
    scale_shape_manual(values = c("\u25A1", "\u25CB", "\u2642", "\u2640", "\u25AB",   "\u1111")) +
    scale_x_continuous(breaks=1:3, limits=c(.9,4)) + #so that model lines extend all the way to symbols
    scale_y_continuous(breaks=seq(0,700,100), limits=c(0,NA)) +
    ylab('temporal limit (ms)') + labs(color='sampling interval (ms)', shape='study') + 
    theme_bw() +
    theme( panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          panel.background = element_blank())

ylims<- layer_scales(gg)$y$get_limits()
xlims<- layer_scales(gg)$x$get_limits()
graphAspectRatio <- diff(ylims)/diff(xlims)

#Create the string label, e.g. "90 ms"
lineLabels <-  tibl %>% filter(targets == 2.6)
lineLabels$label <- paste0(lineLabels$samplingInterval," ms")

#Calculate the angle of the label to make it have the same angle as the line
lineLabels<- lineLabels %>% mutate(slop = samplingInterval * 2)
lineLabels<- lineLabels %>% mutate(slope = slop / graphAspectRatio)
lineLabels<- lineLabels %>% mutate(angleIfAxesSameScale = atan(slope)*180/pi)
lineLabels<- lineLabels %>% mutate(angle = angleIfAxesSameScale)
lineLabels<- lineLabels %>% mutate(temporalLimit = temporalLimit + 10) #to raise it off the line

gg<-gg +  geom_text(data=lineLabels, aes(label = label, angle=angle, color=factor(samplingInterval)), vjust="bottom") +
          guides(colour=FALSE) #don't show sampling interval legend
show(gg)
```

With every unit increase in the number of targets, the interval between successive samples of that target increases by the sampling time. This is under an optimistic assumption of orderly sampling (the sampling process sampling first one target, then the second target, then the third target, and back to the first target, rather than sampling the second target or third target again); otherwise the predicted slope should be even steeper.

Because a particular sampling time specifies the temporal limits for all target sizes, no parameters needed to be fit here. That is, the dashed lines in Figure \@ref(fig:serialModelFit) are not  best-fitting regression lines. Their slope and intercept are determined by the sampling time indicated.

The lines fit the data fairly well. But how impressed should we be by this? Only three target loads were tested, for example, so we should have little confidence that the relationship is truly linear as the model predicts.

A particularly interesting issue is the temporal limit for covertly tracking a single object. In that situation, there is no need to switch the position sampler to another object, and thus no need, it would seem, to have intermittent rather than continuous sampling. Evidence from other paradigms suggests that even when attends to a single location, performance oscillates as if there is a "blinking spotlight" of attention [@vanrullenBlinkingSpotlightAttention2007; @fiebelkornReportRhythmicSampling2013]. Here, that the limit is consistent with the other data points suggests that even when only one target is present, it still is intermittently sampled, perhaps every 60 ms in the young male dataset.

The tracking studies plotted above imply temporal limits, when tracking one target, of `r ms<- round( (temporalLimsData %>% filter(targets==1))$temporalLimit ,-1); ms[1]`, `r ms[2]`, and `r ms[3]` ms. Recall that because the target must be sampled at twice the temporal limit to avoid confusion with the trailing distractor, we the sampling rates inferred are `r round(ms[1]/2)`, `r round(ms[2]/2)`, and `r round(ms[3]/2)` ms.

@macdonaldAttentionalSamplingMultiple2013 probed the putative serial sampling rate by presenting multiple rotating wheels that are sometimes seen to rotate backwards, which can be explained by serial sampling. They inferred a sampling interval of `r round(1000/13.3)` ms <!--13.3 Hz-->. This result converges well with the findings from tracking. <!--also for moving objects, although the rate is harder to interpret. MacDonald & Vanrullen assume motion signal is strongest at 1/4 of cycle, but I seem to remember that was argued by Nakayama but can't remember it's sure --> Other studies, however tend to find much slower sampling intervals:  `r round(1000/7,-1)` ms [@reFeatureBasedAttentionSamples2019]<!--They claimed 8 Hz in their paper but the figure shows the peak at 7 Hz-->, 142 ms [@vanrullenBlinkingSpotlightAttention2007], `r round(1000/7.5,-1)` ms <!--claimed 8 Hz but had equal power at 7 and 8-->[@fiebelkornReportRhythmicSampling2013], and `r round(1000/7.14,-1)` ms [@dugueAttentionSearchesNonuniformly2015]<!--said ~7 Hz but sampling was very coarse, one peak at 7.14--> <!--For the @reFeatureBasedAttentionSamples2019 paper, they wrote in their conclusion that sampling occurred at 8 Hz, but their figure shows a peak at 7 Hz, so I have used 7 Hz or `r round(1000/7,-1)` ms.-->, although the statistics used in some of these studies may have led to spurious findings [@brookshireReevaluatingRhythmicAttentional2021]. A visual search study using neurophysiology in monkeys suggested a 44 ms sampling interval [@buschmanSerialCovertShifts2009]. These other studies all used stationary objects or multiple locations that the participant was told to monitor, which conceivably could explain the slower sampling intervals found in some.

Despite the sizable and growing neurophysiological and neuroimaging literature on oscillations and intermittent sampling, I have not found a study that reveals whether the sampling operates  independently in the two hemifields. This is unfortunate because a hallmark of tracking is its hemifield independence, as reviewed in \@ref(twoBrains). <!--Is the spotlight oscillation hemisphere-specific? Finding of 7 Hz for feature attention by @reFeatureBasedAttentionSamples2019 suggests global.)-->

It might turn out that even after researchers regularly assess whether the sampling they are measuring is hemifield-independent, there will continue to be a large range of rates found. If so, perhaps different tasks result in different sampling rates, and the sampling process can occur more quickly for tracking as it requires sampling position only. Another possibility is that the assumptions underlying the calculations in behavioral studies such as object tracking are wrong. If, for example, motion direction is used to guide the next position sampled, tracking could succeed with a slower sampling interval more similar to those documented in most of the neural studies cited above (but see section \@ref(beyondLocation)).

A few studies, while finding evidence for oscillations in some conditions, do not find it to be tied to cued locations in the same way as some of the literature cited above [@werfNoEvidenceRhythmic2021; @petersObjectbasedAttentionPrioritizes2020]. That psychology and neuroscience researchers admit to substantial rates of publication bias and p-hacking [@jenningsPublicationBiasNeuroimaging2012; @johnMeasuringPrevalenceQuestionable2012; @rabeloQuestionableResearchPractices2020] raises the spectre of the existence of more such evidence that is inconsistent with the prevailing narrative.

Thus, despite a wealth of neuroscientific evidence that serial sampling occurs for attentional tasks, which might account nicely for the existence of a coarse temporal limit on tracking, and for its dramatic worsening with target load, such a link is not yet strongly supported.

<!--@jiaSequentialSamplingVisual2017 No: Moreover, the 2 disc stimuli in all 3 experiments were presented in the left and right visual fields, and therefore, the observed attentional switching could have been solely caused by interhemispheric competition [32]. To address this issue, we ran a control experiment (N = 13) in which the 2 discs were presented in the upper and lower visual fields within the same visual hemifield (S4 Fig). The same alpha-band alternating pattern was observed, thus arguing against the interpretation of interhemispheric competitio-->

<!-- @macdonaldAttentionalSamplingMultiple2013 finds less dramatic decrease in time with number of wagon wheels - instead of 8.7, 5, 3.3, 2.5 Hz, they found 8.7,6.6,6.5,6.2-->
<!--@davidsonAttentionPeriodicallySamples2018 found evidence for 8 Hz sampling during binocular rivalry-->

<!--This could all be compatible with limited-capacity parallel. All targets are simultaneously processed but processing becomes much much slower when attention is spread among more targets, such that with three targets. processing two-by-two, and that remains a possibility
-->

<!-- If there's 2 targets and attention is  samplimg one every 50 ms, then each is sampled every 100 ms, so to solve the correspondence problem they need to go at 5 Hz (200 ms) or slower, so that they only move halfway to the next location. For 3 targets, each is sampled every 150 ms so they need to not get to the next one's location for 300 ms (3.33) hertz.
criticalTemporalInterval = samplingTime*targets*2
385 = samplingTime*3*2; samplingTime = 64
64*2*2= 256 against 238.
blinking spotlight means 64*1*2 = 128 against 143.
-->

## Objects moving every which way

In the behavioral studies that revealed the temporal limits on tracking, a target and its distractors all shared the same circular trajectory. But in most studies of MOT, the distractors near a target are often moving at many different angles, or even in the opposite direction, to the target.

Accounting for tracking entirely with serial sampling process has not been successful with such trajectories [@pylyshynTrackingMultipleIndependent1988; @yantisMultielementVisualTracking1992]. As a result, models of MOT today rely largely on parallel updating of target positions (a serial process is used in some models for other features, which is discussed in \@ref(identity)) [@oksamaPositionTrackingIdentity2016; @lovettSelectionEnablesEnhancement2019; @liModelMultipleIdentity2019; @oksamaDynamicBindingIdentity2008a; @srivastavaAttentionDynamicsMultiple2015]. These parallel theories do not seem able to account for the basic temporal limit discovered with circular trajectories and showcased in \@ref(speedAndTime), nor for the temporal limit's dramatic decrease with target load. 

Given that these models can't account for the temporal limits on tracking, why have they been fairly successful in mimicking human performance with the typical MOT displays not designed to probe the temporal limit? Well, for typical MOT displays, it remains unclear how much temporal interference we should expect - no one has bothered to calculate the distribution of the intervals between targets and distractors visiting a given location. Second, it is not clear how identifiable the models are from the human data. That is, a number of different models, with a large range of possible parameters, might equally explain the data. One reason is that potential spatial interference and for temporal interference are confounded in typical MOT displays. That is, trials in which the moving objects come close to each other in space also tend to be trials in which moving objects visit approximately the same location in a short span of time. As a result, a model that embodies spatial interference only may explain the data about as well as one that includes temporal interference. 

Two strategies to improve the constraints on models present themselves. One is to fix the individual components of the models based on the results of experiments designed to isolate those component, such as the experiments by [@verstratenLimitsAttentiveTracking2000; @holcombeSplittingAttentionReduces2013; @roudaiaDifferentEffectsAging2017] for identifying temporal limits and that of @holcombeObjectTrackingAbsence2014 to identify the range of spatial crowding. Another strategy is to model much larger sets of data, at an individual trial level; previous efforts seem to have modelled data from at most two different MOT experiments.

The circular trajectories that were used to reveal the temporal limits on tracking and the less-constrained trajectories of typical MOT experiments differ in one way that we have not yet discussed. This arises from the fact that the objects in typical MOT experiments do not share their trajectory with other objects. Srimant Tripathy and his collaborators have suggested that a moving object leaves an extended trace that lingers in sensory memory and that tracking processes operate on that representation rather than objects' instantaneous positions  [@tripathyMultipleObjectTrackingSerial2011; @howardMultipleTrajectoryTracking2012]. If so, targets and distractors can be disambiguated as a result of their differing motion directions (which manifests as different orientations of the sensory memories) in addition to their positions. This could mean that temporal interference is less of a factor in typical MOT displays. However, the evidence is that motion direction information is not used much when there are more than two targets, as reviewed in the next section ( \@ref(beyondLocation)), which casts some doubt on Tripathy's suggestion.

