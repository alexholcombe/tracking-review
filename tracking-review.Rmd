--- 
title: "Attending to moving objects"
author: "Alex O. Holcombe"
date: "`r paste0('Updated on ',Sys.Date())`"
site: bookdown::bookdown_site
# The weird thing is that including only the gitbook command below is enough to create the PDF and ePub as well as the html 
output: 
  #gitbook renders html
  bookdown::gitbook:
      lib_dir: assets
  #pdfbook includes images but not DiagrammeR output, like for peripheral vision demos
  bookdown::pdf_book:
    includes:
      in_header: preamble.tex
    latex_engine: xelatex
    citation_package: natbib
    number_sections: FALSE
    keep_tex: yes
    toc_depth: 1
    lof: yes
  bookdown::epub_book: default
  #bookdown::word_document2
documentclass: book
always_allow_html: true
bibliography: [bibliography/CambridgeElementNewestAdditions.bib,  bibliography/packages.bib]  
#bibliography/CambridgeElement.bib, 
biblio-style: "apalike"
#csl: apa7-single-spaced.csl
link-citations: yes
url: 'https\://tracking.whatanimalssee.com/'
github-repo: alexholcombe/tracking-review
twitter-handle: ceptional
#For the order of chapters, see _bookdown.yml, where they are manually specified
description: "This is an opinionated book that reviews some of the literature on multiple object tracking by humans."
#cover-image: "imagesForRmd/threeWiseMonkeys/Three_Wise_Monkeys_640px.jpeg"
---
<!--other titles: Tracking moving objects, How humans track objects, Attending to a moving world -->

# Preface {-}

Cite this as:

Holcombe, A.O. (to appear). Attending to moving objects. Cambridge University Press.

This book, posted with chapter hyperlinks, cross-references, and embedded movies at [tracking.whatanimalssee.com](tracking.whatanimalssee.com),
reviews some of what we know about multiple object tracking by humans. A revised version is expected to be published by Cambridge University Press in their [Cambridge Element series](https://www.cambridge.org/core/what-we-publish/elements/elements-in-perception).
<!--https://mc.manuscriptcentral.com/hsselements1?URL_MASK=8f1bd56d44104a8b82eafbb42c3bdb84-->

This is a highly abridged version of an earlier draft, which greatly exceeded the publisher's word limit. I am  re-purposing the deleted chapters on temporal limits and on serial versus parallel processing into a separate manuscript. Let me know if you're interested in seeing that material. 

<!--You can read this [here on the web](https://tracking.whatanimalssee.com/index.html), as a [PDF file](bookdown-demo.pdf), or as an [e-book](bookdown-demo.epub), which you can import into your Kindle or other e-book reader.--> 

Contact me (he/him) with any comments via [twitter](https://twitter.com/ceptional) or email - alex.holcombe@sydney.edu.au

```{r AlexPhoto, echo=FALSE, out.width="25%"}
knitr::include_graphics("imagesForRmd/corellaOnShoulder2020croppedBlurredByAdobeOnline.jpg")
```

I thank Hrag Pailian, Brian Scholl, and Lorella Battelli for helpful comments, and also thank Hrag Pailian and Brian Scholl for providing images and movies of their work.

© Alex O. Holcombe 2022

<!--Reviewers: Hyona/Pailian/Saiki for identity chapter; Piers Howe / John Palmer/Daniel Little for serial/parallel; Srimant Tripathy for sensory memory ; Scott Brown at Newcastle for drift diffusion models
-->

<!-- To launch CANVAS VIDEOS, I tried looking at the private hyperlink within the Canvas page and used
https://www.url-encode-decode.com to unescape the characters, but that yields failed launch:

[canvas video](https://sydney.instructuremedia.com/lti/launch?custom_arc_display_download=true&custom_arc_launch_type=embed&custom_arc_media_id=83d5fa8f-2601-4cde-8500-16b22da451f4-79254)

This doesn't work either:
[Canvas video](https://sydney.instructuremedia.com/embed/83d5fa8f-2601-4cde-8500-16b22da451f4-79254)
-->
<!-- CANVAS quizzes - I can't see any way to make external links work, even for a Canvas Commons quiz, it takes you to a bizarro Canvas login https://lor.instructure.com/resources/76da8b14c91a40d885c6fe0452bf33f4?shared -->

<!--Wordcount
From R environment, execute the following after eliminating the references
wordcountaddin::word_count('tracking-review.Rmd')
Approximately 27,500 words without references
-->

<!--Exporting to Word: Looked less fucked-up if I first imported the PDF into Google Docs and then clicked Open in->Microsoft Word.app-->

<!-- Speed limits and temporal limits graph fails in PDF version. Is that because of “Warning: LaTeX Warning: Float too large for page by 59.24739pt on input line 584.”?  I think I fixed it by making it smaller.

In PDF, plot of results fails to render the special plot symbols.--> 

<!--
```{theorem, name="Pythagorean"}
For a right triangle, if $c$ denotes the length of the hypotenuse
```
-->

<!--chapter:end:index.Rmd-->


# Objects that move!

Placeholder



<!--chapter:end:01-outline.Rmd-->


# Bottlenecks, resources, and capacity {#bottlenecks}

Placeholder



<!--chapter:end:bottlenecks.Rmd-->


# The biggest myth of object tracking {#biggestMyth}

Placeholder


## Different tasks, same limit?

<!--chapter:end:theBiggestMyth.Rmd-->

# Which aspect(s) of tracking determine performance? {#whichAspects}

While Pylyshyn theorized that tracking is accomplished by a fixed and discrete set of pointers, the dependence on display characteristics of the number of objects one can track hints that the underlying process may be continuous and flexible rather than determined by a fixed, discrete set. Based on the flexible resource metaphor, a person might be able to apply more resource to particular targets to reduce the deleterious influence of object speed or another factor. There is good evidence for this [e.g. @chenResourceDemandsObject2013], which will be discussed later, but here I would like to explain the resource concept more, and make an important distinction.

To understand why we can track several objects in some circumstances, but only a few in others, we must distinguish between display factors that impose *data* limitations on tracking, and display factors that impose *resource* limitations. <!--We've already covered C=1 processing, grouping, and the nature of the objects themselves, in Chapters \@ref(objects) and \@ref(grouping).-->

The "data" in data limitation refers to sensory data [@normanDatalimitedResourcelimitedProcesses1975]. If a target moving on an unpredictable trajectory moves outside the edge of our visual field, it is the absence of data that prevents it from being tracked. No amount of mental resources can overcome having no data, at least for an unpredictable stimulus. Data limitations may also occur when sensory signals are impoverished, even if not entirely absent. For example, it is a data limitation that prevents tracking when an object travels at such a fast rate that our neurons hardly register it. So, by data here we are referring not to the raw activation pattern of our photoreceptors, but rather the visual signals available after additional preattentive sensory processing.

People with poor visual acuity may perform less well on a task than people with high visual acuity, due to differences in the sensory data that they have to work with. Thus, some individual differences are almost certainly due to data limitations rather than variation in tracking processes between people. When performance is data-limited, bringing more mental resources to bear provides little to no benefit. The most popular way of investigating this is by varying the number of stimuli one needs to process, as in visual search studies. If the number of stimuli one must evaluate does not affect how well a person can perform a task, this suggests that the task is data-limited rather than resource-limited, because performance is evidently the same regardless of the proportion of the putative resource can be devoted to it. <!-- More reflections on the relation of the resource concept to underlying mechanisms is in Chapter \@ref(spatialInterference). --> 

Resource-limited processing is typically more interesting for those interested in visual attention and the capacity limits on mental processing. If response time or error rate increases with the number of distractors presented in a visual search task, that is classically interpreted as meaning that a resource-limited process is required for success at the task. However, science is hard - an elevation in e.g. error rate can also occur even if there is no resource limitation, if each additional distractor has a non-zero probability of being mistaken for a distractor, yielding more errors with more distractors even if the probability of successfully evaluating each individual stimulus remains unchanged [@palmerAttentionVisualSearch1995]. 

The particular number of objects that can be tracked with reasonable accuracy is thus highly dependent on stimulus conditions, and some of these conditions may reflect data limitations rather than a resource limitation. Still, even in ideal conditions it seems clear that the number of objects that can be tracked is much less than the number of objects that are simultaneously processed by early visual areas. In other words, there is some sort of resource limitation.

We'd like to know what factors consume the resource. I'll also be using the term "resource-intensive" - if a deleterious stimulus factor is resource-intensive, that means that increasing the amount of resource devoted to the stimulus can compensate for that stimulus factor. One example is speed of the moving targets. An increase in targets' speed can hinder performance, but reducing the number of targets, which provides more resource to the remaining targets, can make up for that. Moreover, if one object moves faster than another, it consumes more resource. The evidence for that is that the addition of a fast-moving target hurts tracking performance for a first target more than does the addition of a slow-moving target 

Speed, then, appears to be resource-intensive. Speed also can result in a data-limitation, at very high speeds, but long before such speeds are reached, speed is resource-intensive.

One should not assume, however, that when one manipulates something about a display, that something is the only thing that changes. Increasing the speed of the objects in a display can also result in more close encounters between targets and distractors, unless one shortens the duration of the trial to equate the total distance the objects travel. Thus, it could be that dealing with spatial interference is what consumes resource, rather than speed.  This brings us to the next chapter, which is all about spatial interference.

<!--chapter:end:whichAspects.Rmd-->


# Spatial interference {#spatialInterference}

Placeholder


## Spatial interference does not explain why tracking many targets is more difficult than tracking only a few
## The mechanisms that cause spatial interference
## Spatial selection of multiple locations

<!--chapter:end:spatialInterference.Rmd-->

# Unitary cognition (C = 1 processes) {#Cequals1}

Successful performance of a multiple object tracking task may be assisted by two resources. This worries me greatly.

One resource is what researchers *believe* they are studying. It can process multiple targets simultaneously, even if it processes them more poorly than it processes a lone target. This is what most researchers are interested in. However, the mind also has a resource that in some ways is more powerful.

The processes that support our ability to explicitly reason, referred to as System 1 in some contexts in cognitive psychology, can assist performance in many tasks. But they are very limited in capacity - some cognitive researchers think they can only operate on one thing at a time [@oberauerAccessInformationWorking2002]. This may be what prevents us from doing more than one 2-digit mental multiplication problem at a time. When applied to tracking, it means you can apply your powers of reasoning to tracking that target, for example to use what you've learned about object trajectories to predict future positions. I will refer to this as a C=1 process because its processing capacity may be only one object.

## An inconvenient possibility
 
<!---This reflects a unitary focus of attention that has an approximate capacity of only one.-->
A lot of the results trumpeted by tracking papers are rendered uninteresting because they could be due to our cognitive abilities operating on a single target, rather than the results speaking to the tracking resource that we can distribute to multiple targets. Many researchers that come out of the experimental psychology tradition content themselves with showing that a factor makes *some* difference to performance, p < 0.05. Never mind *how much* the factor matters. But in a task involving tracking several targets, a factor that has only a small effect could be explained by the unitary C=1 resource working on just one target. As an example of evidence that such processes may contribute to visual cognition, for a multi-colored shape, @xuCapacityVisualFeatures2015 found that participants could only mentally rotate a single part.

Let's say that a paper finds that people track multiple objects more accurately if they move on predictable trajectories than on unpredictable trajectories. I have to think that may simply be due to our central thought processes operating on just one target. Ruling this out requires sophisticated methods, such as showing that the predictable-trajectory advantage applies independently in each hemifield, as we will see in Chapter \@ref(twoBrains), or that the effect shows some other idiosyncrasy of tracking, such as inability to work with individual locations within a moving object, as described in Chapter \@ref(objects).

<!--(as opposed to psychophysics, which is more quantitative) -->
In case you are not entirely clear about my point, another way to put it is that by using our capacity for reasoning and symbol manipulation, we can perform a wide array of arbitrary tasks. We therefore should not be surprised by our ability to track a *single* target. We know that we have a visual system that makes the position and direction of motion of objects on our retina available to cognition, and that using our ability to think about where an object is going and deliberately move our attention to a future anticipated location, we might muddle through to success at tracking a single object.

Even when participants are asked to track several targets, then, one can expect that C=1 processes are contributing to overall performance, even if they are only involved in the processing of one of the targets. Thus, when researchers contrast tracking performance with different numbers of targets, one reason for the decline in performance may be that C=1 processes are, in each condition, processing only a single target, so performance declines in inverse proportion to the number of targets.

<!-- Unfortunately, researchers frequently neglect the fact that two sorts of mental abilities likely contribute to MOT performance: one or some limited in capacity to just a single target, and others with a greater processing capacity.  -->


<!--chapter:end:Cequals1.Rmd-->


# Objects and attentional spread {#objects}

Placeholder


## Stationary object selection
## The end of the line
## Object creation and object tracking: Distinct processes?
## What tracking sticks to
## Growth, shrinkage, and tracking
## Could tracking work by attentional spreading?

<!--chapter:end:objects.Rmd-->


# Grouping {#grouping}

Placeholder


## Hierarchical relations 
## Eyes to the center

<!--chapter:end:grouping.Rmd-->


# Two brains or one? {#twoBrains}

Placeholder


## The extraordinary hemifield independence of object tracking
## Quantitative estimates of independence
## Some tracking resources are NOT hemifield-specific
## The underlying mechanisms
## What else are hemifield-specific resources used for?
## Hemispheric differences

<!--chapter:end:twoBrainsOrOne.Rmd-->


# Knowing where but not what {#identity}

Placeholder


## The first question: Does position updating benefit from differences in object identities?
### Motion correspondence 
### Feature differences, but not feature conjunction differences, benefit tracking
## The second question: Are we aware of the identities of objects we are tracking?
## Beaten by a bird brain
## Some dissociations between identity and location processing reflect poor visibility in the periphery
## Evidence from two techniques suggests parallel updating of identities
## Eye movements can add a serial component to tracking

<!--chapter:end:identity.Rmd-->


# Abilities and individual differences {#abilities}

Placeholder


## Do people vary much in how many objects they can track?
## Going deeper

<!--chapter:end:abilities.Rmd-->

# Towards the real world

Some of the findings in multiple object tracking are useful for understanding real-world situations. A naive view of visual perception and attention is that we are simultaneously aware of the identities of all the objects in a scene, and some people such as sports coaches may think that unless a player actually disappears or hides behind something or someone, players should know where everyone in front of us on the basketball court, or the soccer field, is at all times. Similarly, during driving many people seem to assume that they are aware of all hazards in their visual field. The fact that this is not accurate has been incorporated into driver education [@fisherCanNoviceDrivers2006].

Change blindness demonstrations can rapidly dispel naive beliefs about visual awareness of change, but still people assume that if they are actively attending to a moving object, they will be aware of its features. As we have seen (Chapter \@ref(identity)), this is not true, although tracking something does make it more likely that a change will be detected. This was supported in a simulated driving study by @lochnerMultipleobjectTrackingDriving2014, who found that changes were found more accurately and rapidly when the change was made to a target vehicle rather than a distractor vehicle.

Few empirical studies, unfortunately, have made strong links between real-world situations nad laboratory MOT tasks, or its underlying abilities. @bowersCanWeImprove2013 found that laboratory MOT performance did not predict driving test performance as well as either the Montreal Cognitive Assessment task, a trail-making task, or a subtest of a useful field-of-view task. The aforementioned driving simulator study by @lochnerMultipleobjectTrackingDriving2014 found that drivers were more accurate at localizing which of multiple lead vehicles braked if it was a tracking target, but there was no advantage in terms of braking response time. 

@mackenzieMultipleObjectAvoidance2021 used a multiple object avoidance task where the user used a mouse to control one of the balls that they had to prevent from colliding with the other balls. The task is reminiscent of the venerable Asteroids game mentioned in the beginning of this book. @mackenzieMultipleObjectAvoidance2021 found strong correlations with performance on a driving simulator and with years of driving experience. In an earlier paper, some of these authors found that the MOA correlated better with driving performance than conventional MOT [@mackenzieLinkAttentionalFunction2017]. 

In sports, some teams of researchers have frequently suggested that MOT performance predicts in-game performance in soccer and other sports, and further reported evidence that training on MOT tasks can enhance skill in sports. Unfortunately, the associated evidence is not strong [@vaterCriticalSystematicReview2021]. Given the poor record of computer-based training tasks (sometimes called "brain training") in improving skills in other real-world domains, one should remain skeptical that MOT training has benefits until rigorous evidence is provided [@simonsBraintrainingProgramsWork2016].


<!--chapter:end:realWorld.Rmd-->


# Progress and recommendations {#recommendations}

Placeholder


## The decline of Pylyshyn's FINST theory
## Topics not covered by this book
## Dual-task OUT OF SCOPE
## Recommendations

<!--chapter:end:misconceptionsAndQuestions.Rmd-->

`r if (knitr:::is_html_output()) '
# References {-}
'`

<!--chapter:end:references.Rmd-->

