--- 
title: "Attending to moving objects"
author: "Alex O. Holcombe"
date: "`r paste0('Updated on ',Sys.Date())`"
site: bookdown::bookdown_site
# The weird thing is that including only the gitbook command below is enough to create the PDF and ePub as well as the html 
output: 
  #gitbook renders html
  bookdown::gitbook:
      lib_dir: assets
      global_numbering: TRUE #Makes figures number from 1 to X rather than 1.1,1.2,2.1,2.2
  #pdfbook includes images but not DiagrammeR output, like for peripheral vision demos
  bookdown::pdf_book:
    includes:
      in_header: preamble.tex
    latex_engine: xelatex
    citation_package: natbib
    number_sections: TRUE #If FALSE, wreaks the chapter cross-references
    #global_numbering: TRUE #Doesn't work for PDF output
    keep_tex: yes
    toc_depth: 1
    lof: yes
  bookdown::epub_book: default
  #bookdown::word_document2
documentclass: book
always_allow_html: true
bibliography: [bibliography/CambridgeElementNewestAdditions.bib,  bibliography/packages.bib]  
#bibliography/CambridgeElement.bib, 
biblio-style: "apalike"
#csl: apa7-single-spaced.csl
link-citations: yes
url: 'https\://tracking.whatanimalssee.com/'
github-repo: alexholcombe/tracking-review
twitter-handle: ceptional
#For the order of chapters, see _bookdown.yml, where they are manually specified
description: "This book reviews some of the literature on multiple object tracking by humans."
#cover-image: "imagesForRmd/threeWiseMonkeys/Three_Wise_Monkeys_640px.jpeg"
---
<!--other titles: Tracking moving objects, How humans track objects, Attending to a moving world -->

# Preface {-}


You can buy the official paperback or ebook versions of this book [here](https://www.cambridge.org/core/elements/attending-to-moving-objects/0914ABF2EF7D03676124F7250874071A) in addition to viewing this HTML version for free. Please cite the book as:

Holcombe, A.O. (2023). Attending to moving objects. [Cambridge University Press](https://www.cambridge.org/core/elements/attending-to-moving-objects/0914ABF2EF7D03676124F7250874071A). DOI: https://doi.org/10.1017/9781009003414. Online ISBN: 9781009003414

I thank Hrag Pailian, Brian Scholl, Lorella Battelli, Christian Merkel, and the three anonymous reviewers for helpful comments. I also thank Hrag Pailian and Brian Scholl for providing images and movies of their work.

<!--This is in press with Cambridge University Press, a part of their [Cambridge Element series](https://www.cambridge.org/core/what-we-publish/elements/elements-in-perception). This book will also remain as an HTML document here at [tracking.whatanimalssee.com](tracking.whatanimalssee.com).-->
<!--https://mc.manuscriptcentral.com/hsselements1?URL_MASK=8f1bd56d44104a8b82eafbb42c3bdb84-->

<!--You can read this [here on the web](https://tracking.whatanimalssee.com/index.html), as a [PDF file](bookdown-demo.pdf), or as an [e-book](bookdown-demo.epub), which you can import into your Kindle or other e-book reader.--> 


Please contact me with comments via email (alex.holcombe@sydney.edu.au) or [Mastodon](https://fediscience.org/@alexh) .

```{r AlexPhoto, echo=FALSE, out.width="15%"}
knitr::include_graphics("imagesForRmd/corellaOnShoulder2020croppedBlurredByAdobeOnline.jpg")
```
© Alex O. Holcombe 2022. Licensed to Cambridge University Press.

## Abstract {-}

Our minds are severely limited in how much information they can extensively process, in spite of being massively parallel at the visual end. When people attempt to track moving objects, only a limited number can be tracked, which varies with display parameters. Associated experiments indicate that spatial selection and updating has higher capacity than selection and updating of features such as color and shape, and is mediated by processes specific to each cerebral hemisphere, such that each hemifield has its own spatial tracking limit. These spatial selection processes act as a bottleneck that gate subsequent processing. To improve our understanding of this bottleneck, future work should strive to avoid contamination of tracking tasks by high-level cognition. While we are far from fully understanding how attention keeps up with multiple moving objects, what we already know illuminates the architecture of visual processing and offers promising directions for new discoveries.

<!--Reviewers: Hyona/Pailian/Saiki for identity chapter; Piers Howe / John Palmer/Daniel Little for serial/parallel; Srimant Tripathy for sensory memory ; Scott Brown at Newcastle for drift diffusion models
-->

<!-- To launch CANVAS VIDEOS, I tried looking at the private hyperlink within the Canvas page and used
https://www.url-encode-decode.com to unescape the characters, but that yields failed launch:

[canvas video](https://sydney.instructuremedia.com/lti/launch?custom_arc_display_download=true&custom_arc_launch_type=embed&custom_arc_media_id=83d5fa8f-2601-4cde-8500-16b22da451f4-79254)

This doesn't work either:
[Canvas video](https://sydney.instructuremedia.com/embed/83d5fa8f-2601-4cde-8500-16b22da451f4-79254)
-->
<!-- CANVAS quizzes - I can't see any way to make external links work, even for a Canvas Commons quiz, it takes you to a bizarro Canvas login https://lor.instructure.com/resources/76da8b14c91a40d885c6fe0452bf33f4?shared -->

<!--Wordcount
From R environment, execute the following after eliminating the references
wordcountaddin::word_count('tracking-review.Rmd')
Approximately 27,500 words without references
-->
<!--Exporting to Word: Looked less fucked-up if I first imported the PDF into Google Docs and then clicked Open in->Microsoft Word.app-->

<!-- Speed limits and temporal limits graph fails in PDF version. Is that because of “Warning: LaTeX Warning: Float too large for page by 59.24739pt on input line 584.”?  I think I fixed it by making it smaller.

In PDF, plot of results fails to render the special plot symbols.--> 

<!--
```{theorem, name="Pythagorean"}
For a right triangle, if $c$ denotes the length of the hypotenuse
```
-->

<!--chapter:end:index.Rmd-->


# Objects that move {#intro}

Placeholder


## What's to come {#summary}

<!--chapter:end:intro.Rmd-->


# Bottlenecks, resources, and capacity {#bottlenecks}

Placeholder



<!--chapter:end:bottlenecks.Rmd-->


# The biggest myth of object tracking {#biggestMyth}

Placeholder


## Claim #3: Different tasks, same limit?

<!--chapter:end:theBiggestMyth.Rmd-->

# Which aspect(s) of tracking determine performance? {#whichAspects}

The number of objects one can track is highly dependent on display characteristics, which hints that the underlying process may be continuous and flexible rather than determined by the fixed, discrete set of pointers hypothesized by Pylyshyn. If so, a person might be able to apply more resource to particular targets to reduce the deleterious influence of a particularly high speed for those targets. There is good evidence for this [e.g. @chenResourceDemandsObject2013], which will be discussed later, but here I would like to explain the resource concept more, and make an important distinction.

To understand why we can track several objects in some circumstances, but only a few in others, we must distinguish between display factors that impose *data* limitations on tracking, and display factors that impose *resource* limitations. <!--We've already covered C=1 processing, grouping, and the nature of the objects themselves, in Chapters \@ref(objects) and \@ref(grouping).-->

The "data" of data limitation refers to sensory data [@normanDatalimitedResourcelimitedProcesses1975]. If a target moving on an unpredictable trajectory moves outside the edge of our visual field, it is the absence of sensory data that prevents tracking. No amount of mental resources can overcome this for an unpredictable stimulus. Data limitations may also occur when sensory signals are impoverished rather than entirely absent. For example, it is a data limitation that prevents tracking when an object travels at such a fast rate that our neurons hardly register it. <!--So, by data here we are referring not to the raw activation pattern of our photoreceptors, but rather the visual signals available after additional preattentive sensory processing.-->

People with poor visual acuity perform less well on many visual tasks than people with high visual acuity, due to differences in the sensory data that they have to work with. Thus, some individual differences are almost certainly due to data limitations rather than variation in tracking processes between people. When performance is data-limited, bringing more mental resources to bear provides little to no benefit. The most popular way of investigating this is by varying the number of stimuli one needs to process, as in visual search studies. If the number of stimuli one must evaluate does not affect how well a person can perform a task, this suggests that the task is data-limited rather than resource-limited, because performance is the same regardless of the proportion of the putative resource can be devoted to it. <!-- More reflections on the relation of the resource concept to underlying mechanisms is in Chapter \@ref(spatialInterference). --> 

Resource-limited processing more interesting for those interested in attention and the capacity limits on mental processing. A classic example is from visual search: if response time or error rate increases with the number of distractors presented, a resource-limited process may be required for success at the task. However, science is hard - an elevation in e.g. error rate can also occur even if there is no resource limitation, if each additional distractor has a non-zero probability of being mistaken for a distractor, yielding more errors with more distractors even if the probability of successfully evaluating each individual stimulus remains unchanged [@palmerAttentionVisualSearch1995]. 

Even in ideal conditions, where data limitations are avoided, it will be clear (see Section \@ref(spatialInterference)) that the number of objects that can be tracked is much less than the number of objects that are simultaneously processed by early visual areas. In other words, there is some sort of resource limitation.

We'd like to know what factors consume the resource. I'll also be using the term "resource-intensive", meaning a deleterious stimulus factor that can be compensated for by increasing the amount of resource available. One example is the speed of the moving targets. An increase in target speed can hinder performance, but reducing the number of targets can make up for that because it provides more resource to the remaining targets. Moreover, if one object moves faster than another, it consumes more resource. The evidence for that is that the addition of a fast-moving target hurts tracking performance for a first target more than does the addition of a slow-moving target [@chenResourceDemandsObject2013].

Speed, then, appears to be resource-intensive. Speed also can result in a data limitation, at very high speeds, but long before such speeds are reached, speed is resource-intensive. One should not assume, however, that when one manipulates something about a display, that something is the only thing that changes. Increasing the speed of the objects in a display can also result in more close encounters between targets and distractors, unless one shortens the duration of the trial to equate the total distance the objects travel. Thus, it could be that addressing spatial interference is what consumes resource, rather than speed per se. This brings us to the next Section, which is all about spatial interference.

<!--chapter:end:whichAspects.Rmd-->


# Spatial interference {#spatialInterference}

Placeholder


## Spatial interference does not explain why tracking many targets is more difficult than tracking only a few
## The mechanisms that cause spatial interference
## Spatial selection of multiple locations

<!--chapter:end:spatialInterference.Rmd-->

# Unitary cognition (System B) {#Cequals1}

Successful performance of a multiple object tracking task may be assisted by two resources. This worries me. One resource is the one that researchers typically believe they are studying. This resource can process multiple targets simultaneously, even if it processes them more poorly than it processes a lone target. This is the resource that most researchers, including myself, use tracking to study. However, the mind also has another resource that likely contributes to tracking performance.

The processes that support our ability to explicitly reason, often referred to as System 2 in cognitive psychology, can assist performance in many tasks. But this system is very limited in capacity - some cognitive researchers think it can only operate on one thing at a time [@oberauerAccessInformationWorking2002]. This may be what prevents us from doing, for example, more than one 2-digit mental multiplication problem at a time. But this also means one can apply System 2 to tracking a single target, for example to use what you've learned about object trajectories to predict future positions. The "System 2" concept was developed within cognitive psychology to distinguish between two types of cognitive processing. As opposed to the lower-level processing thought to allow people to simultaneously track multiple targets, here I want a term that refers to aspects of cognition that have a capacity of approximately one object. Because I know of no existing term, I will refer to it with the phrase "System B". 

## An inconvenient possibility

That tracking performance might reflect a combination of two systems, System B and a more low-level and possibly higher-capacity tracking process, complicates the interpretation of many experiments. Indeed, it makes the results trumpeted by some tracking papers fairly uninteresting, because the results could be caused entirely by our cognitive abilities (System B) operating on a single target, rather than reflecting the tracking resource that we seem to be able to distribute to multiple targets. MOT researchers have sometimes contented themselves with showing that a factor makes some non-zero difference to performance, as if the only criterion for newsworthiness is that the associated p-value is less than 0.05. But in a task involving tracking several targets, a factor that has only a small effect could be explained by System B operating on just one target. As an example of evidence that such a capacity=1 process may contribute to visual cognition, @xuCapacityVisualFeatures2015 found that participants could mentally rotate only a single part of a multi-colored shape.

Imagine that a study finds that people track multiple objects more accurately if they move on predictable trajectories than on unpredictable trajectories. This has in fact been found repeatedly, first by @fencsikRoleLocationMotion2007. Could the result be be due to our System B thought processes operating on just one target, rather than it revealing anything about the multiple-object tracking processes?  Ruling this out requires sophisticated methods, such as showing that the predictable-trajectory advantage applies independently in each hemifield, as we will see in Chapter \@ref(twoBrains), or that the effect shows some other idiosyncrasy of tracking, such as inability to work with individual locations within a moving object, as described in Chapter \@ref(objects). Researchers have typically not done this, unfortunately, but what has been done is to assess the capacity limit of the underlying process. The resulting findings suggest that the use of motion information during tracking may be subject to a more severe capacity limit than the use of position. In conditions where participants can use position information to accurately track four or five targets, they can only use motion information for one or two of the targets [@howeMotionInformationSometimes2012; @luuExtrapolationOccursMultiple2015; @wangRoleKinematicProperties2021]. Perhaps the predictability of trajectories can be taken advantage of only by the extended cognitive processing of an object that System B is capable of. 

My essential point is that even when participants are asked to track several targets, one can expect that System B is contributing to overall performance, even if they are only involved in the processing of one of the targets. By using our capacity for reasoning and symbol manipulation, we can perform a wide array of arbitrary tasks, so we should not be surprised by the ability to track a *single* target. We have a visual system that makes the position and direction of motion of objects on our retina available to cognition, and by using our ability to think about where an object is going and deliberately moving our attention to a future anticipated location, we might muddle through to success at tracking a single object. Thus, when researchers contrast tracking performance with different numbers of targets, one reason for the decline in performance may be that System B type processes are, in each condition, processing only a single target, so performance declines rapidly with target load.

<!-- Unfortunately, researchers frequently neglect the fact that two sorts of mental abilities likely contribute to MOT performance: one or some limited in capacity to just a single target, and others with a greater processing capacity.  -->


<!--chapter:end:Cequals1.Rmd-->


# Objects and attentional spread {#objects}

Placeholder


## Stationary object selection
## The end of the line
## Object creation and object tracking: Distinct processes?
## What tracking sticks to
## Growth, shrinkage, and tracking
## Could tracking work by attentional spreading?

<!--chapter:end:objects.Rmd-->


# Grouping {#grouping}

Placeholder


## Hierarchical relations 
## Eyes to the center

<!--chapter:end:grouping.Rmd-->


# Two brains or one? {#twoBrains}

Placeholder


## The extraordinary hemifield independence of object tracking
## Quantitative estimates of independence
## Some tracking resources are NOT hemifield-specific
## The underlying mechanisms
## What else are hemifield-specific resources used for?
## Hemispheric differences

<!--chapter:end:twoBrainsOrOne.Rmd-->


# Knowing where but not what {#identity}

Placeholder


## The first question: Does position updating benefit from differences in object identities?
### Motion correspondence 
### Feature differences, but not feature conjunction differences, benefit tracking
## The second question: Are we aware of the identities and features of objects we are tracking?
### Feature updating
### Maintenance of target features and identities
### Beaten by a bird brain
### Some dissociations between identity and location processing reflect poor visibility in the periphery
### Evidence from two techniques suggests parallel updating of identities
## Eye movements can add a serial component to tracking

<!--chapter:end:identity.Rmd-->


# Abilities and individual differences {#abilities}

Placeholder


## Do people vary much in how many objects they can track?
## Going deeper

<!--chapter:end:abilities.Rmd-->

# Towards the real world

The change detection literature is an inspiring example of how lessons from a task can inform real-world practice. Without knowledge of change detection results, some practitioners, such as coaches of team sports, likely subscribed to the naive view of visual perception and attention that we are simultaneously aware of the identities of all the objects in a scene, such that unless a player actually disappears or hides behind something or someone, players should know where everyone in front of us on the basketball court, or the soccer field, is at all times [@schollChangeBlindnessBlindness2004]. Similarly, during driving many people seem to assume that they are aware of all hazards in their visual field. <!--The fact that this is not accurate has been incorporated into driver education [@fisherCanNoviceDrivers2006] and, I imagine, sports education.-->

While change blindness demonstrations have dispelled naive beliefs about visual awareness of change, still people assume that if they are actively attending to a moving object, they will be aware of its features. As we have seen (Section \@ref(identity)), this is not true. Tracking does facilitate change detection however, as found in a driving simulator study by  @lochnerMultipleobjectTrackingDriving2014.

Very few empirical studies have established strong links between real-world situations and laboratory MOT tasks or its underlying abilities. @bowersCanWeImprove2013 found that laboratory MOT performance did not predict driving test performance as well as either the Montreal Cognitive Assessment task, a trail-making task, or a useful field-of-view task. The aforementioned driving simulator study by @lochnerMultipleobjectTrackingDriving2014 found that drivers were more accurate at localizing which of multiple lead vehicles braked if it was a tracking target, but there was no advantage in terms of braking response time. 

@mackenzieMultipleObjectAvoidance2021 used a multiple object avoidance (MOA) task where the user, in a task reminiscent of Asteroids (Section \@ref(intro)), controlled one of the balls with a mouse, trying to prevent it from colliding with the other balls. Strong correlations were found with years of driving experience and driving simulator performance. Some of the same authors also found that MOA performance correlated better with driving performance than conventional MOT [@mackenzieLinkAttentionalFunction2017]. This may be because MOA includes motor control, which is necessary for driving, but is not required for MOT.

Some teams of researchers have repeatedly found evidence that MOT performance predicts in-game performance in soccer and other sports, and have also reported evidence that training on MOT tasks can enhance skill in sports. Unfortunately, the evidence is not strong [@vaterCriticalSystematicReview2021]. Given the poor record of computer-based training tasks (sometimes called "brain training") in improving skills in other real-world domains [@simonsBraintrainingProgramsWork2016], we should be skeptical that MOT training has benefits until rigorous evidence is provided.

<!--ADD @jarvisNeuroTrackerMultipleObject2022 NeuroTracker Multiple Object Tracking Ability Predicts Novice Performance on a Simulated Air Traffic Control Task-->

<!--chapter:end:realWorld.Rmd-->


# Progress and recommendations {#recommendations}

Placeholder


## Recommendations for future work
## Omissions
## Dual-task OUT OF SCOPE

<!--chapter:end:misconceptionsAndQuestions.Rmd-->

`r if (knitr:::is_html_output()) '
# References {-}
'`

<!--chapter:end:references.Rmd-->

