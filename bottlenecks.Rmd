# Bottlenecks and capacity {#bottlenecks}

Consider a simple arithmetic problem, for example twenty-seven times thirty-nine You are probably more than capable of answering that problem, but it might take you several seconds to calclulate the answer. And if i set you two problems rather than just one, for example I asked you to also divide thirteen into thirty-seven, you probably would do the two multiplication problems one at a time. Indeed, our minds may be incapable of doing them simultaneously [@oberauerAccessInformationWorking2002; @zylberbergBrainRouterCortical2010a]. These limitations are remarkable given that the human brain contains more than 80 billion neurons. They speak to the importance of the architecture of the mind, in particular its bottlenecks, to understanding our abilities.

Of course, multiplying and dividing two-digit numbers are not something that most of us do every day. Reading, however, is a daily task for most of us. Yet despite our daily practice, and the usefulness of assimilating information from text rapidly, a large body of psychological research suggests that humans can read at most only a few words at a time, and some claim that we can only read one word at a time [@whiteEvidenceSerialProcessing2018; @reichleEncodingMultipleWords2009]. It seems, then, that at least some of the bottlenecks of human information processing are hard-wired.

Yet some parts of the mind can process many things at the same time. Early processing stages in vision and other sensory modalities are massively parallel. Each bit of the retinal image, for example, has its own photoreceptors devoted just to it. In the primary visual cortex, individual neurons continue to respond to small regions, and in parallel process the entire visual field. 

An impressive behavioral manifestation of this parallel processing occurs in visual search. In some circumstances, we can quickly locate targets hidden in a large number of distractors. For example, try searching for the blue objects in the below display.

```{r, echo=FALSE, fig.cap = "", fig.height = 2.0, fig.width=2.5}
#bookdown-demo_files/figure-html/unnamed-chunk-9-1.png ?
library(ggplot2)
library(tibble)
pts<- expand.grid(x = seq(2,16,2), y = seq(2,16,2), type = c("distractor"))
jittr<-.4
pts$x <- pts$x + runif(length(pts$x))*jittr-jittr/2
pts$y <- pts$y + runif(length(pts$y))*jittr-jittr/2
pts$type <- as.character(pts$type)
pts$type[c(1,4,6,8,11,12,13,16,20,25,26,30,33,37,41,44,47,48,52,55,59,60)] <- "distractor2"
pts$type[c(13,26,46)] <- "target"

ymin<-600; ymax<-2000
ggplot(pts,aes(x=x,y=y, color=type)) + geom_point(size=6)  +  theme_void() + theme(legend.position = "none")
#+ ylim(ymin,ymax)
```

Locating the three blue objects should have been easy for you. One reason is that our visual systems process each of the shapes simultaneously, and makes the locations of the blue objects available when you choose to attend to blue. Some brain areas, however, do not have neurons that can recognize objects dedicated to each bit of the visual field. Instead, their simultaneous processing capacity is limited. The processes required to recognize words are an example.

For limited capacity processes, something is needed to pick out, from a crowded scene, just one or a few objects for these areas to recognize. We call this something *selective attention*. Different visual abilities seem to have different capacities, and it is not at all clear that a common selective attention process is responsible for gating all of their inputs.

CROSS-CHECK WITH PSYC2016 TEXT
@duncanSelectiveAttentionOrganization1984 was interested in how many objects we can process at a time. He found that accuracy for making a simple visual judgment about an object was much worse when one needed to simultaneously make a judgment about another. For example, participants were asked to judge whether a briefly-presented rectangle was small or large and also judge whether a simultaneously presented line was dotted or dashed. Performance was worse FOR the two-object condition even in comparison to a single-object condition where two judgments also needed to be made. The participants had to make either two judgments about a single object or one judgment about one object and the second judgment about a different object. To Duncan, his finding that performance was substantially worse in the two-object condition indicated the existence of a bottleneck at a stage that processes objects. He wrote that 

> Findings support a view in which parallel, preattentive processes serve to segment the field into separate objects, followed by a process of focal attention that deals with only one object at a time.

This conclusion was an over-reach. Performance was better than one would expect if only one object were processed, unlike what has been found for word processing. Duncan could explain that by saying that the presentation time was adequate for focal attention to, on *some* trials, process more than one object. Alternatively, however, it may be that the relevant processes *can* handle two objects at a time, but they do so more poorly than for one object. Work that credibly claims that a visual ability is truly limited to one object at a time is hard to find; the reading of words may be an exception.



